{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to cropengine","text":"<p>A Python package for streamlining process-based crop modeling and simulation</p> <ul> <li>GitHub repo: https://github.com/geonextgis/cropengine</li> <li>Documentation: https://geonextgis.github.io/cropengine</li> <li>PyPI: https://pypi.org/project/cropengine</li> <li>Notebooks: https://github.com/geonextgis/cropengine/tree/main/docs/examples</li> <li>License: MIT</li> </ul>"},{"location":"#introduction","title":"Introduction","text":"<p>cropengine is a Python package designed to bridge the gap between geospatial data and process-based crop modeling. It streamlines the complex workflows involved in preparing input data, configuring simulation parameters, and executing crop models for yield prediction and agricultural research.</p> <p>While traditional crop modeling often requires extensive manual data preparation and file manipulation, cropengine automates these tasks. It is built to integrate seamlessly with geospatial workflows (such as those using <code>geeagri</code>), allowing users to easily drive simulations with site-specific weather, soil, and management data.</p> <p>cropengine is ideal for:</p> <ul> <li>Agronomists and researchers running point-based or spatial crop simulations.</li> <li>Data scientists integrating biophysical models with machine learning pipelines.</li> <li>Developers building agricultural decision support systems.</li> </ul> <p>For a complete list of examples and use cases, visit the notebooks section.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Automated Data Preparation \u2014 Streamline the formatting of weather, soil, and management data into model-ready structures.</li> <li>Simulation Management \u2014 Easily configure and run process-based crop simulations with a Pythonic API.</li> <li>Geospatial Integration \u2014 Connect directly with satellite and climate data sources to drive simulations for specific locations (lat/lon) or regions.</li> <li>Scalable Workflows \u2014 specialized tools for running batch simulations across multiple sites or growing seasons efficiently.</li> <li>Result Analysis \u2014 Built-in utilities to parse simulation outputs, calculate yield gaps, and visualize crop growth dynamics over time.</li> <li>Model Agnostic Design \u2014 Designed to support various crop modeling engines and frameworks through a unified interface.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>conda create -n cropengine python=3.10\nconda activate cropengine\npip install cropengine\n# (Optional) Upgrade to the latest version if already installed\npip install --upgrade cropengine\n</code></pre>"},{"location":"agromanagement/","title":"agromanagement module","text":"<p>Module to setup agromanagement</p>"},{"location":"agromanagement/#cropengine.agromanagement.WOFOSTAgroEventBuilder","title":"<code> WOFOSTAgroEventBuilder        </code>","text":"<p>Helper class to build PCSE agromanagement events using a YAML schema for validation.</p> Source code in <code>cropengine/agromanagement.py</code> <pre><code>class WOFOSTAgroEventBuilder:\n    \"\"\"\n    Helper class to build PCSE agromanagement events using a YAML schema for validation.\n    \"\"\"\n\n    def __init__(self):\n        try:\n            with pkg_resources.files(configs).joinpath(\"agromanagement.yaml\").open(\n                \"r\"\n            ) as f:\n                self.schema = yaml.safe_load(f)[\"wofost\"]\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load agromanagement.yaml: {e}\")\n\n    def get_timed_events_info(self):\n        return self.schema[\"TimedEvents\"]\n\n    def get_state_events_info(self):\n        return self.schema[\"StateEvents\"]\n\n    def _convert_date(\n        self, date_val: Union[str, datetime.date, None]\n    ) -&gt; Optional[datetime.date]:\n        \"\"\"Helper to convert string dates to datetime.date objects.\"\"\"\n        if date_val is None:\n            return None\n        if isinstance(date_val, str):\n            return datetime.datetime.strptime(date_val, \"%Y-%m-%d\").date()\n        if isinstance(date_val, (datetime.date, datetime.datetime)):\n            return date_val\n        raise ValueError(\n            f\"Invalid date format: {date_val}. Expected YYYY-MM-DD string or datetime.date object.\"\n        )\n\n    def create_timed_events(self, signal_type: str, events_list: List[Dict]) -&gt; dict:\n        \"\"\"\n        Creates a single TimedEvent dictionary containing a LIST of dates.\n        \"\"\"\n        if signal_type not in self.schema[\"TimedEvents\"]:\n            raise ValueError(f\"Unknown TimedEvent signal: {signal_type}\")\n\n        schema_def = self.schema[\"TimedEvents\"][signal_type]\n        required_params = schema_def[\"events_table\"].keys()\n\n        populated_events_list = []\n\n        for entry in events_list:\n            current_date = self._convert_date(entry[\"event_date\"])\n\n            params = {}\n            for param in required_params:\n                params[param] = entry[param]\n\n            populated_events_list.append({current_date: params})\n\n        return {\n            \"event_signal\": signal_type,\n            \"name\": schema_def.get(\"name\"),\n            \"comment\": schema_def.get(\"comment\"),\n            \"events_table\": populated_events_list,\n        }\n\n    def create_state_events(\n        self,\n        signal_type: str,\n        state_var: str,\n        zero_condition: str,\n        events_list: List[Dict],\n    ) -&gt; dict:\n        \"\"\"\n        Creates a single StateEvent dictionary containing a LIST of thresholds.\n        \"\"\"\n        if signal_type not in self.schema[\"StateEvents\"]:\n            raise ValueError(f\"Unknown StateEvent signal: {signal_type}\")\n\n        schema_def = self.schema[\"StateEvents\"][signal_type]\n        required_params = schema_def[\"events_table\"].keys()\n\n        # Change: Use a LIST for the events table\n        populated_events_list = []\n\n        for entry in events_list:\n            threshold = entry[\"threshold\"]\n\n            params = {}\n            for param in required_params:\n                params[param] = entry[param]\n\n            # Append as a single-key dictionary to the list\n            populated_events_list.append({threshold: params})\n\n        return {\n            \"event_signal\": signal_type,\n            \"event_state\": state_var,\n            \"zero_condition\": zero_condition,\n            \"name\": schema_def.get(\"name\"),\n            \"comment\": schema_def.get(\"comment\"),\n            \"events_table\": populated_events_list,\n        }\n</code></pre>"},{"location":"agromanagement/#cropengine.agromanagement.WOFOSTAgroEventBuilder.create_state_events","title":"<code>create_state_events(self, signal_type, state_var, zero_condition, events_list)</code>","text":"<p>Creates a single StateEvent dictionary containing a LIST of thresholds.</p> Source code in <code>cropengine/agromanagement.py</code> <pre><code>def create_state_events(\n    self,\n    signal_type: str,\n    state_var: str,\n    zero_condition: str,\n    events_list: List[Dict],\n) -&gt; dict:\n    \"\"\"\n    Creates a single StateEvent dictionary containing a LIST of thresholds.\n    \"\"\"\n    if signal_type not in self.schema[\"StateEvents\"]:\n        raise ValueError(f\"Unknown StateEvent signal: {signal_type}\")\n\n    schema_def = self.schema[\"StateEvents\"][signal_type]\n    required_params = schema_def[\"events_table\"].keys()\n\n    # Change: Use a LIST for the events table\n    populated_events_list = []\n\n    for entry in events_list:\n        threshold = entry[\"threshold\"]\n\n        params = {}\n        for param in required_params:\n            params[param] = entry[param]\n\n        # Append as a single-key dictionary to the list\n        populated_events_list.append({threshold: params})\n\n    return {\n        \"event_signal\": signal_type,\n        \"event_state\": state_var,\n        \"zero_condition\": zero_condition,\n        \"name\": schema_def.get(\"name\"),\n        \"comment\": schema_def.get(\"comment\"),\n        \"events_table\": populated_events_list,\n    }\n</code></pre>"},{"location":"agromanagement/#cropengine.agromanagement.WOFOSTAgroEventBuilder.create_timed_events","title":"<code>create_timed_events(self, signal_type, events_list)</code>","text":"<p>Creates a single TimedEvent dictionary containing a LIST of dates.</p> Source code in <code>cropengine/agromanagement.py</code> <pre><code>def create_timed_events(self, signal_type: str, events_list: List[Dict]) -&gt; dict:\n    \"\"\"\n    Creates a single TimedEvent dictionary containing a LIST of dates.\n    \"\"\"\n    if signal_type not in self.schema[\"TimedEvents\"]:\n        raise ValueError(f\"Unknown TimedEvent signal: {signal_type}\")\n\n    schema_def = self.schema[\"TimedEvents\"][signal_type]\n    required_params = schema_def[\"events_table\"].keys()\n\n    populated_events_list = []\n\n    for entry in events_list:\n        current_date = self._convert_date(entry[\"event_date\"])\n\n        params = {}\n        for param in required_params:\n            params[param] = entry[param]\n\n        populated_events_list.append({current_date: params})\n\n    return {\n        \"event_signal\": signal_type,\n        \"name\": schema_def.get(\"name\"),\n        \"comment\": schema_def.get(\"comment\"),\n        \"events_table\": populated_events_list,\n    }\n</code></pre>"},{"location":"agromanagement/#cropengine.agromanagement.WOFOSTAgroManagementProvider","title":"<code> WOFOSTAgroManagementProvider            (list)         </code>","text":"<p>A dynamic provider for WOFOST AgroManagement. Generates a rotation of crops based on start/end dates and handles YAML serialization.</p> Source code in <code>cropengine/agromanagement.py</code> <pre><code>class WOFOSTAgroManagementProvider(list):\n    \"\"\"\n    A dynamic provider for WOFOST AgroManagement.\n    Generates a rotation of crops based on start/end dates and handles YAML serialization.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n    def _convert_date(\n        self, date_val: Union[str, datetime.date, None]\n    ) -&gt; Optional[datetime.date]:\n        \"\"\"Helper to convert string dates to datetime.date objects.\"\"\"\n        if date_val is None:\n            return None\n        if isinstance(date_val, str):\n            return datetime.datetime.strptime(date_val, \"%Y-%m-%d\").date()\n        if isinstance(date_val, (datetime.date, datetime.datetime)):\n            return date_val\n        raise ValueError(\n            f\"Invalid date format: {date_val}. Expected YYYY-MM-DD string or datetime.date object.\"\n        )\n\n    def add_campaign(\n        self,\n        campaign_start_date: Union[str, datetime.date],\n        campaign_end_date: Union[str, datetime.date],\n        crop_name: str,\n        variety_name: str,\n        crop_start_date: Union[str, datetime.date],\n        crop_end_date: Optional[Union[str, datetime.date]] = None,\n        crop_start_type: str = \"sowing\",\n        crop_end_type: str = \"maturity\",\n        max_duration: int = 300,\n        timed_events: List[Dict] = None,\n        state_events: List[Dict] = None,\n    ):\n        \"\"\"\n        Adds a single cropping campaign to the rotation.\n\n        Args:\n            campaign_start_date: Start date of the campaign (str 'YYYY-MM-DD' or date object).\n            campaign_end_date: End date of the campaign (str 'YYYY-MM-DD' or date object).\n            crop_name: Name of the crop (e.g., 'wheat').\n            variety_name: Variety identifier (e.g., 'winter-wheat').\n            crop_start_date: Date of sowing or emergence (str 'YYYY-MM-DD' or date object).\n            crop_end_date: Optional harvest date (str 'YYYY-MM-DD' or date object).\n            crop_start_type: 'sowing' or 'emergence'.\n            crop_end_type: 'maturity', 'harvest', or 'earliest'.\n            max_duration: Maximum duration of the crop cycle in days.\n            timed_events: List of timed event dictionaries (from EventBuilder).\n            state_events: List of state event dictionaries (from EventBuilder).\n        \"\"\"\n        # Convert inputs to ensure they are date objects or valid strings\n        c_start = self._convert_date(campaign_start_date)\n        c_end = self._convert_date(campaign_end_date)\n        crop_start = self._convert_date(crop_start_date)\n        crop_end = self._convert_date(crop_end_date) if crop_end_date else None\n\n        self._last_campaign_end = c_end\n\n        # 1. Define the base CropCalendar\n        crop_calendar = {\n            \"crop_name\": crop_name,\n            \"variety_name\": variety_name,\n            \"crop_start_date\": crop_start,\n            \"crop_start_type\": crop_start_type,\n            \"crop_end_type\": crop_end_type,\n            \"max_duration\": max_duration,\n        }\n\n        # 2. Conditionally add crop_end_date only if it exists\n        if crop_end is not None:\n            crop_calendar[\"crop_end_date\"] = crop_end\n\n        # 3. Build the full config\n        campaign_config = {\n            \"CropCalendar\": crop_calendar,\n            \"TimedEvents\": timed_events if timed_events else None,\n            \"StateEvents\": state_events if state_events else None,\n        }\n\n        # Append the campaign dictionary {start_date: config} to the list\n        self.append({c_start: campaign_config})\n\n    def add_trailing_empty_campaign(self):\n        \"\"\"\n        Adds a final empty campaign to ensure the simulation runs until the very end\n        of the requested period.\n\n        Args:\n            start_date: Start date of the empty period (str 'YYYY-MM-DD' or date object).\n        \"\"\"\n        if self._last_campaign_end is None:\n            raise RuntimeError(\n                \"Cannot add trailing empty campaign before adding at least one campaign.\"\n            )\n\n        self.append({self._last_campaign_end: None})\n\n    def save_to_yaml(self, filename: str):\n        \"\"\"\n        Exports the current agromanagement configuration to a YAML file.\n\n        Structure matches the PCSE requirement:\n        AgroManagement:\n        - Date:\n            CropCalendar: ...\n            TimedEvents: ...\n        \"\"\"\n        # Wrap the list in the root 'AgroManagement' key\n        output_structure = {\"AgroManagement\": list(self)}\n\n        with open(filename, \"w\") as f:\n            yaml.dump(output_structure, f, sort_keys=False)\n</code></pre>"},{"location":"agromanagement/#cropengine.agromanagement.WOFOSTAgroManagementProvider.add_campaign","title":"<code>add_campaign(self, campaign_start_date, campaign_end_date, crop_name, variety_name, crop_start_date, crop_end_date=None, crop_start_type='sowing', crop_end_type='maturity', max_duration=300, timed_events=None, state_events=None)</code>","text":"<p>Adds a single cropping campaign to the rotation.</p> <p>Parameters:</p> Name Type Description Default <code>campaign_start_date</code> <code>Union[str, datetime.date]</code> <p>Start date of the campaign (str 'YYYY-MM-DD' or date object).</p> required <code>campaign_end_date</code> <code>Union[str, datetime.date]</code> <p>End date of the campaign (str 'YYYY-MM-DD' or date object).</p> required <code>crop_name</code> <code>str</code> <p>Name of the crop (e.g., 'wheat').</p> required <code>variety_name</code> <code>str</code> <p>Variety identifier (e.g., 'winter-wheat').</p> required <code>crop_start_date</code> <code>Union[str, datetime.date]</code> <p>Date of sowing or emergence (str 'YYYY-MM-DD' or date object).</p> required <code>crop_end_date</code> <code>Union[str, datetime.date]</code> <p>Optional harvest date (str 'YYYY-MM-DD' or date object).</p> <code>None</code> <code>crop_start_type</code> <code>str</code> <p>'sowing' or 'emergence'.</p> <code>'sowing'</code> <code>crop_end_type</code> <code>str</code> <p>'maturity', 'harvest', or 'earliest'.</p> <code>'maturity'</code> <code>max_duration</code> <code>int</code> <p>Maximum duration of the crop cycle in days.</p> <code>300</code> <code>timed_events</code> <code>List[Dict]</code> <p>List of timed event dictionaries (from EventBuilder).</p> <code>None</code> <code>state_events</code> <code>List[Dict]</code> <p>List of state event dictionaries (from EventBuilder).</p> <code>None</code> Source code in <code>cropengine/agromanagement.py</code> <pre><code>def add_campaign(\n    self,\n    campaign_start_date: Union[str, datetime.date],\n    campaign_end_date: Union[str, datetime.date],\n    crop_name: str,\n    variety_name: str,\n    crop_start_date: Union[str, datetime.date],\n    crop_end_date: Optional[Union[str, datetime.date]] = None,\n    crop_start_type: str = \"sowing\",\n    crop_end_type: str = \"maturity\",\n    max_duration: int = 300,\n    timed_events: List[Dict] = None,\n    state_events: List[Dict] = None,\n):\n    \"\"\"\n    Adds a single cropping campaign to the rotation.\n\n    Args:\n        campaign_start_date: Start date of the campaign (str 'YYYY-MM-DD' or date object).\n        campaign_end_date: End date of the campaign (str 'YYYY-MM-DD' or date object).\n        crop_name: Name of the crop (e.g., 'wheat').\n        variety_name: Variety identifier (e.g., 'winter-wheat').\n        crop_start_date: Date of sowing or emergence (str 'YYYY-MM-DD' or date object).\n        crop_end_date: Optional harvest date (str 'YYYY-MM-DD' or date object).\n        crop_start_type: 'sowing' or 'emergence'.\n        crop_end_type: 'maturity', 'harvest', or 'earliest'.\n        max_duration: Maximum duration of the crop cycle in days.\n        timed_events: List of timed event dictionaries (from EventBuilder).\n        state_events: List of state event dictionaries (from EventBuilder).\n    \"\"\"\n    # Convert inputs to ensure they are date objects or valid strings\n    c_start = self._convert_date(campaign_start_date)\n    c_end = self._convert_date(campaign_end_date)\n    crop_start = self._convert_date(crop_start_date)\n    crop_end = self._convert_date(crop_end_date) if crop_end_date else None\n\n    self._last_campaign_end = c_end\n\n    # 1. Define the base CropCalendar\n    crop_calendar = {\n        \"crop_name\": crop_name,\n        \"variety_name\": variety_name,\n        \"crop_start_date\": crop_start,\n        \"crop_start_type\": crop_start_type,\n        \"crop_end_type\": crop_end_type,\n        \"max_duration\": max_duration,\n    }\n\n    # 2. Conditionally add crop_end_date only if it exists\n    if crop_end is not None:\n        crop_calendar[\"crop_end_date\"] = crop_end\n\n    # 3. Build the full config\n    campaign_config = {\n        \"CropCalendar\": crop_calendar,\n        \"TimedEvents\": timed_events if timed_events else None,\n        \"StateEvents\": state_events if state_events else None,\n    }\n\n    # Append the campaign dictionary {start_date: config} to the list\n    self.append({c_start: campaign_config})\n</code></pre>"},{"location":"agromanagement/#cropengine.agromanagement.WOFOSTAgroManagementProvider.add_trailing_empty_campaign","title":"<code>add_trailing_empty_campaign(self)</code>","text":"<p>Adds a final empty campaign to ensure the simulation runs until the very end of the requested period.</p> <p>Parameters:</p> Name Type Description Default <code>start_date</code> <p>Start date of the empty period (str 'YYYY-MM-DD' or date object).</p> required Source code in <code>cropengine/agromanagement.py</code> <pre><code>def add_trailing_empty_campaign(self):\n    \"\"\"\n    Adds a final empty campaign to ensure the simulation runs until the very end\n    of the requested period.\n\n    Args:\n        start_date: Start date of the empty period (str 'YYYY-MM-DD' or date object).\n    \"\"\"\n    if self._last_campaign_end is None:\n        raise RuntimeError(\n            \"Cannot add trailing empty campaign before adding at least one campaign.\"\n        )\n\n    self.append({self._last_campaign_end: None})\n</code></pre>"},{"location":"agromanagement/#cropengine.agromanagement.WOFOSTAgroManagementProvider.save_to_yaml","title":"<code>save_to_yaml(self, filename)</code>","text":"<p>Exports the current agromanagement configuration to a YAML file.</p> <p>Structure matches the PCSE requirement: AgroManagement: - Date:     CropCalendar: ...     TimedEvents: ...</p> Source code in <code>cropengine/agromanagement.py</code> <pre><code>def save_to_yaml(self, filename: str):\n    \"\"\"\n    Exports the current agromanagement configuration to a YAML file.\n\n    Structure matches the PCSE requirement:\n    AgroManagement:\n    - Date:\n        CropCalendar: ...\n        TimedEvents: ...\n    \"\"\"\n    # Wrap the list in the root 'AgroManagement' key\n    output_structure = {\"AgroManagement\": list(self)}\n\n    with open(filename, \"w\") as f:\n        yaml.dump(output_structure, f, sort_keys=False)\n</code></pre>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#v001-date","title":"v0.0.1 - Date","text":"<p>Improvement:</p> <ul> <li>TBD</li> </ul> <p>New Features:</p> <ul> <li>TBD</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/geonextgis/cropengine/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with <code>bug</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with <code>enhancement</code> and <code>help wanted</code> is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>cropengine could always use more documentation, whether as part of the official cropengine docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/geonextgis/cropengine/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up cropengine for local development.</p> <ol> <li> <p>Fork the cropengine repo on GitHub.</p> </li> <li> <p>Clone your fork locally:</p> <pre><code>$ git clone git@github.com:your_name_here/cropengine.git\n</code></pre> </li> <li> <p>Install your local copy into a virtualenv. Assuming you have     virtualenvwrapper installed, this is how you set up your fork for     local development:</p> <pre><code>$ mkvirtualenv cropengine\n$ cd cropengine/\n$ python setup.py develop\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass flake8     and the tests, including testing other Python versions with tox:</p> <pre><code>$ flake8 cropengine tests\n$ python setup.py test or pytest\n$ tox\n</code></pre> <p>To get flake8 and tox, just pip install them into your virtualenv.</p> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated.     Put your new functionality into a function with a docstring, and add     the feature to the list in README.rst.</li> <li>The pull request should work for Python 3.8 and later, and     for PyPy. Check https://github.com/geonextgis/cropengine/pull_requests and make sure that the tests pass for all     supported Python versions.</li> </ol>"},{"location":"conversions/","title":"conversions module","text":""},{"location":"conversions/#cropengine.conversions.Td_to_VAP","title":"<code>Td_to_VAP(dewpoint_K)</code>","text":"<p>Compute vapour pressure (hPa) from dewpoint temperature (K).</p> Source code in <code>cropengine/conversions.py</code> <pre><code>def Td_to_VAP(dewpoint_K):\n    \"\"\"Compute vapour pressure (hPa) from dewpoint temperature (K).\"\"\"\n    # Handle Series or scalar\n    Td_C = dewpoint_K - 273.15\n    vap_kPa = 0.6108 * np.exp((17.27 * Td_C) / (Td_C + 237.3))\n    return vap_kPa\n</code></pre>"},{"location":"conversions/#cropengine.conversions.uv_to_wind","title":"<code>uv_to_wind(u, v)</code>","text":"<p>Compute wind speed magnitude (m/s).</p> Source code in <code>cropengine/conversions.py</code> <pre><code>def uv_to_wind(u, v):\n    \"\"\"Compute wind speed magnitude (m/s).\"\"\"\n    return np.sqrt(u**2 + v**2)\n</code></pre>"},{"location":"crop/","title":"crop module","text":"<p>Module to prepare crop parameters</p>"},{"location":"crop/#cropengine.crop.WOFOSTCropParametersProvider","title":"<code> WOFOSTCropParametersProvider            (YAMLCropDataProvider)         </code>","text":"<p>A data provider for WOFOST crop parameters. This class extends the standard YAMLCropDataProvider to automatically locate and load crop-specific parameter files.</p> <p>Parameters:</p> Name Type Description Default <code>crop_name</code> <code>str</code> <p>The name of the crop (e.g., 'wheat', 'maize').</p> required <code>variety_name</code> <code>str</code> <p>The specific variety of the crop (e.g., 'Winter_wheat_101').</p> required Source code in <code>cropengine/crop.py</code> <pre><code>class WOFOSTCropParametersProvider(YAMLCropDataProvider):\n    \"\"\"\n    A data provider for WOFOST crop parameters. This class extends the standard YAMLCropDataProvider to automatically\n    locate and load crop-specific parameter files.\n\n    Args:\n        crop_name (str): The name of the crop (e.g., 'wheat', 'maize').\n        variety_name (str): The specific variety of the crop (e.g., 'Winter_wheat_101').\n    \"\"\"\n\n    def __init__(self, crop_name: str, variety_name: str):\n        # 1. Get the directory path directly from the module\n        config_path = list(wofost_crop_params.__path__)[0]\n\n        # 2. Initialize the parent class with the string path\n        super().__init__(fpath=str(config_path))\n\n        # 3. Set the active crop\n        self.set_active_crop(crop_name, variety_name)\n        self.crop_name = crop_name\n        self.variety_name = variety_name\n        self.param_metadata = self._get_param_metadata()\n\n    def _get_param_metadata(self) -&gt; list[dict]:\n        \"\"\"\n        Retrieves metadata for the current crop variety from the YAML configuration.\n        \"\"\"\n        with pkg_resources.files(wofost_crop_params).joinpath(\n            f\"{self.crop_name}.yaml\"\n        ).open(\"r\") as f:\n            crop_config = yaml.safe_load(f)\n            crop_variety_config = crop_config[\"CropParameters\"][\"Varieties\"][\n                self.variety_name\n            ]\n\n            param_metadata = []\n            for param, info in crop_variety_config.items():\n                try:\n                    param_dict = {\n                        \"parameter\": param,\n                        \"description\": info[1],\n                        \"unit\": info[-1][0] if len(info[-1]) == 1 else info[-1],\n                        \"default\": info[0],\n                    }\n                    param_metadata.append(param_dict)\n                except (IndexError, TypeError, KeyError):\n                    continue\n\n            return param_metadata\n</code></pre>"},{"location":"crop/#cropengine.crop.get_available_crop_varieties","title":"<code>get_available_crop_varieties(model, crop)</code>","text":"<p>Retrieves available varieties and their metadata for a specific crop.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The name of the simulation model.</p> required <code>crop</code> <code>str</code> <p>The name of the crop (e.g., 'wheat').</p> required <p>Returns:</p> Type Description <code>dict | None</code> <p>A dictionary where keys are variety identifiers and values are metadata strings (descriptions). Returns None if the model is not supported.</p> Source code in <code>cropengine/crop.py</code> <pre><code>def get_available_crop_varieties(model: str, crop: str) -&gt; dict | None:\n    \"\"\"\n    Retrieves available varieties and their metadata for a specific crop.\n\n    Args:\n        model (str): The name of the simulation model.\n        crop (str): The name of the crop (e.g., 'wheat').\n\n    Returns:\n        dict | None: A dictionary where keys are variety identifiers and values\n        are metadata strings (descriptions). Returns None if the model is not supported.\n    \"\"\"\n    if model.startswith(\"Wofost\"):\n        with pkg_resources.files(wofost_crop_params).joinpath(f\"{crop}.yaml\").open(\n            \"r\"\n        ) as f:\n            crop_config = yaml.safe_load(f)\n\n            all_crop_varieties = crop_config[\"CropParameters\"][\"Varieties\"].keys()\n            crop_varieties = {}\n\n            for v in all_crop_varieties:\n                # Extract the descriptive metadata for the variety\n                meta = crop_config[\"CropParameters\"][\"Varieties\"][v][\"Metadata\"]\n                crop_varieties[v] = meta\n\n        return crop_varieties\n\n    else:\n        return None\n</code></pre>"},{"location":"crop/#cropengine.crop.get_available_crops","title":"<code>get_available_crops(model)</code>","text":"<p>Retrieves a list of supported crops for a specific model type.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The name of the simulation model (e.g., \"Wofost72_PP\").</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of available crop names.</p> Source code in <code>cropengine/crop.py</code> <pre><code>def get_available_crops(model: str) -&gt; list[str]:\n    \"\"\"\n    Retrieves a list of supported crops for a specific model type.\n\n    Args:\n        model (str): The name of the simulation model (e.g., \"Wofost72_PP\").\n\n    Returns:\n        list[str]: A list of available crop names.\n    \"\"\"\n    if model.startswith(\"Wofost\"):\n        with pkg_resources.files(wofost_crop_params).joinpath(\"crops.yaml\").open(\n            \"r\"\n        ) as f:\n            available_crops = yaml.safe_load(f)[\"available_crops\"]\n\n        return available_crops\n\n    else:\n        return []\n</code></pre>"},{"location":"cropengine/","title":"cropengine module","text":"<p>Main cropengine module.</p>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationBatchRunner","title":"<code> WOFOSTCropSimulationBatchRunner            (WOFOSTOptionsMixin)         </code>","text":"Source code in <code>cropengine/cropengine.py</code> <pre><code>class WOFOSTCropSimulationBatchRunner(WOFOSTOptionsMixin):\n    def __init__(self, model_name, locations_csv_path, workspace_dir=\"batch_workspace\"):\n        self.model_name = model_name\n        self.workspace_dir = os.path.abspath(workspace_dir)\n        os.makedirs(self.workspace_dir, exist_ok=True)\n\n        self.locations_csv_path = locations_csv_path\n        self.locations_df = pd.read_csv(locations_csv_path)\n        self.locations_df[\"id\"] = self.locations_df[\"id\"].astype(int)\n\n    # =========================================================================\n    #  UPDATE PARAMETERS IN WORKSPACE\n    # =========================================================================\n    def update_parameters(self, crop_overrides=None, soil_overrides=None, site_overrides=None):\n        \"\"\"\n        Updates parameter files for ALL locations in the batch.\n\n        Args:\n            crop_overrides (dict): Updates for 'params_crop.csv'.\n            soil_overrides (dict): Updates for 'params_soil.csv'.\n            site_overrides (dict): Updates for 'params_site.csv'.\n        \"\"\"\n        print(f\"[BATCH UPDATE] Updating parameters for {len(self.locations_df)} locations...\")\n\n        updated_count = 0\n\n        # Iterate over all point directories\n        for _, row in tqdm(self.locations_df.iterrows(), total=len(self.locations_df), desc=\"Updating Params\"):\n            loc_id = int(row[\"id\"])\n            point_dir = os.path.join(self.workspace_dir, f\"point_{loc_id}\")\n\n            # Use the Single Runner's logic to update this specific folder\n            runner = WOFOSTCropSimulationRunner(model_name=self.model_name, workspace_dir=point_dir)\n\n            if crop_overrides:\n                runner._update_single_file(\"crop_params\", crop_overrides)\n            if soil_overrides:\n                runner._update_single_file(\"soil_params\", soil_overrides)\n            if site_overrides:\n                runner._update_single_file(\"site_params\", site_overrides)\n\n            updated_count += 1\n\n        print(f\"[BATCH UPDATE] Success! Updated parameters in {updated_count} locations.\")\n\n    # =========================================================================\n    # PHASE 1: PARALLEL SYSTEM PREPARATION\n    # =========================================================================\n    def prepare_batch_system(self, max_workers=4, **preparation_args):\n        \"\"\"\n        Runs `prepare_system` for all points in parallel.\n        Downloads data and creates config files for every point.\n        \"\"\"\n        tasks = []\n        print(f\"[BATCH PREP] Preparing tasks for {len(self.locations_df)} locations...\")\n\n        # 1. Build Task List\n        for _, row in self.locations_df.iterrows():\n            # Separate site_kwargs from the main args\n            site_kwargs = {\n                k: v\n                for k, v in preparation_args.items()\n                if k\n                not in [\n                    \"campaign_start\",\n                    \"campaign_end\",\n                    \"crop_start\",\n                    \"crop_end\",\n                    \"crop_name\",\n                    \"variety_name\",\n                    \"force_update\",\n                    \"crop_start_type\",\n                    \"crop_end_type\",\n                    \"max_duration\",\n                    \"timed_events\",\n                    \"state_events\",\n                ]\n            }\n\n            task_payload = {\n                \"id\": int(row[\"id\"]),\n                \"latitude\": row[\"latitude\"],\n                \"longitude\": row[\"longitude\"],\n                \"base_workspace_dir\": self.workspace_dir,\n                \"model_name\": self.model_name,\n                \"site_kwargs\": site_kwargs,\n                **preparation_args,  # Pass rest of args (dates, crop, etc)\n            }\n            tasks.append(task_payload)\n\n        # 2. Execute Parallel Preparation\n        print(f\"[BATCH PREP] Starting preparation with {max_workers} workers...\")\n        success_count = 0\n\n        with multiprocessing.Pool(processes=max_workers, maxtasksperchild=1) as pool:\n            iterator = pool.imap_unordered(_WOFOST_prepare_batch_system, tasks)\n\n            for result in tqdm(iterator, total=len(tasks), desc=\"Preparing Data\"):\n                if result[\"status\"] == \"Success\":\n                    success_count += 1\n                else:\n                    print(f\"FAILED Point {result['id']}: {result.get('error')}\")\n\n        print(f\"[BATCH PREP] Completed. {success_count}/{len(tasks)} locations ready.\")\n\n    # =========================================================================\n    # PHASE 2: PARALLEL EXECUTION\n    # =========================================================================\n    def run_batch_simulation(\n        self,\n        max_workers=4,\n        soil_overrides=None,\n        site_overrides=None,\n        crop_overrides=None,\n        agro_file_path=None,\n        output_vars=None,\n    ):\n        \"\"\"\n        Runs `run_simulation` for all points in parallel.\n        Assumes data is already prepared.\n\n        Args:\n            max_workers (int, optional): Number of CPU cores to use.\n            soil_overrides (dict, optional): Override soil params.\n            site_overrides (dict, optional): Override site params.\n            crop_overrides (dict, optional): Override crop params.\n            agro_file_path (str, optional): Path to a user-provided YAML file. If None, uses the workspace default.\n            output_vars (list, optional): Variables to output.\n        \"\"\"\n        tasks = []\n\n        print(\n            f\"[BATCH RUN] Preparing execution tasks for {len(self.locations_df)} locations...\"\n        )\n\n        # 1. Build Task List\n        for _, row in self.locations_df.iterrows():\n            task_payload = {\n                \"id\": row[\"id\"],\n                \"latitude\": row[\"latitude\"],\n                \"longitude\": row[\"longitude\"],\n                \"base_workspace_dir\": self.workspace_dir,\n                \"model_name\": self.model_name,\n                # Optional overrides passed to all workers\n                \"soil_overrides\": soil_overrides,\n                \"site_overrides\": site_overrides,\n                \"crop_overrides\": crop_overrides,\n                \"agro_file_path\": agro_file_path,\n                \"output_vars\": output_vars,\n            }\n            tasks.append(task_payload)\n\n        # 2. Execute Parallel Simulation\n        results_list = []\n        print(f\"[BATCH RUN] Starting simulation with {max_workers} workers...\")\n\n        with multiprocessing.Pool(processes=max_workers, maxtasksperchild=1) as pool:\n            iterator = pool.imap(_WOFOST_run_batch_task, tasks)\n\n            for res_df in tqdm(iterator, total=len(tasks), desc=\"Simulating\"):\n                if res_df is not None:\n                    results_list.append(res_df)\n\n        # 3. Combine &amp; Save\n        if results_list:\n            final_df = pd.concat(results_list, ignore_index=True)\n            if \"index\" in final_df.columns:\n                final_df.drop(\"index\", axis=1, inplace=True)\n\n            final_df[\"point_id\"] = final_df[\"point_id\"].astype(int)\n\n            output_path = os.path.join(self.workspace_dir, \"batch_results.csv\")\n            final_df.to_csv(output_path, index=False)\n            print(f\"[BATCH RUN] Success! Results saved to {output_path}\")\n            return final_df\n        else:\n            print(\"[BATCH RUN] Failed. No results generated.\")\n            return pd.DataFrame()\n\n    # =========================================================================\n    # OPTIMIZATION\n    # =========================================================================\n    def get_batch_rerunners(self):\n        \"\"\"\n        Initializes a fast re-runner for EVERY location in the batch.\n        Loads all weather/soil data into RAM once.\n\n        Returns:\n            dict: { location_id: fast_runner_function }\n        \"\"\"\n        batch_runners = {}\n        print(\n            f\"[BATCH INIT] Pre-loading data for {len(self.locations_df)} locations...\"\n        )\n\n        for _, row in self.locations_df.iterrows():\n            loc_id = int(row[\"id\"])\n            point_dir = os.path.join(self.workspace_dir, f\"point_{loc_id}\")\n\n            # Initialize the single runner for this specific point\n            runner = WOFOSTCropSimulationRunner(\n                model_name=self.model_name, workspace_dir=point_dir\n            )\n\n            try:\n                engine_object = runner.get_rerunner()\n                batch_runners[loc_id] = engine_object\n            except Exception as e:\n                print(f\"[WARN] Skipping point {loc_id}: {e}\")\n\n        return batch_runners\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationBatchRunner.get_batch_rerunners","title":"<code>get_batch_rerunners(self)</code>","text":"<p>Initializes a fast re-runner for EVERY location in the batch. Loads all weather/soil data into RAM once.</p> <p>Returns:</p> Type Description <code>dict</code> <p>{ location_id: fast_runner_function }</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def get_batch_rerunners(self):\n    \"\"\"\n    Initializes a fast re-runner for EVERY location in the batch.\n    Loads all weather/soil data into RAM once.\n\n    Returns:\n        dict: { location_id: fast_runner_function }\n    \"\"\"\n    batch_runners = {}\n    print(\n        f\"[BATCH INIT] Pre-loading data for {len(self.locations_df)} locations...\"\n    )\n\n    for _, row in self.locations_df.iterrows():\n        loc_id = int(row[\"id\"])\n        point_dir = os.path.join(self.workspace_dir, f\"point_{loc_id}\")\n\n        # Initialize the single runner for this specific point\n        runner = WOFOSTCropSimulationRunner(\n            model_name=self.model_name, workspace_dir=point_dir\n        )\n\n        try:\n            engine_object = runner.get_rerunner()\n            batch_runners[loc_id] = engine_object\n        except Exception as e:\n            print(f\"[WARN] Skipping point {loc_id}: {e}\")\n\n    return batch_runners\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationBatchRunner.prepare_batch_system","title":"<code>prepare_batch_system(self, max_workers=4, **preparation_args)</code>","text":"<p>Runs <code>prepare_system</code> for all points in parallel. Downloads data and creates config files for every point.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def prepare_batch_system(self, max_workers=4, **preparation_args):\n    \"\"\"\n    Runs `prepare_system` for all points in parallel.\n    Downloads data and creates config files for every point.\n    \"\"\"\n    tasks = []\n    print(f\"[BATCH PREP] Preparing tasks for {len(self.locations_df)} locations...\")\n\n    # 1. Build Task List\n    for _, row in self.locations_df.iterrows():\n        # Separate site_kwargs from the main args\n        site_kwargs = {\n            k: v\n            for k, v in preparation_args.items()\n            if k\n            not in [\n                \"campaign_start\",\n                \"campaign_end\",\n                \"crop_start\",\n                \"crop_end\",\n                \"crop_name\",\n                \"variety_name\",\n                \"force_update\",\n                \"crop_start_type\",\n                \"crop_end_type\",\n                \"max_duration\",\n                \"timed_events\",\n                \"state_events\",\n            ]\n        }\n\n        task_payload = {\n            \"id\": int(row[\"id\"]),\n            \"latitude\": row[\"latitude\"],\n            \"longitude\": row[\"longitude\"],\n            \"base_workspace_dir\": self.workspace_dir,\n            \"model_name\": self.model_name,\n            \"site_kwargs\": site_kwargs,\n            **preparation_args,  # Pass rest of args (dates, crop, etc)\n        }\n        tasks.append(task_payload)\n\n    # 2. Execute Parallel Preparation\n    print(f\"[BATCH PREP] Starting preparation with {max_workers} workers...\")\n    success_count = 0\n\n    with multiprocessing.Pool(processes=max_workers, maxtasksperchild=1) as pool:\n        iterator = pool.imap_unordered(_WOFOST_prepare_batch_system, tasks)\n\n        for result in tqdm(iterator, total=len(tasks), desc=\"Preparing Data\"):\n            if result[\"status\"] == \"Success\":\n                success_count += 1\n            else:\n                print(f\"FAILED Point {result['id']}: {result.get('error')}\")\n\n    print(f\"[BATCH PREP] Completed. {success_count}/{len(tasks)} locations ready.\")\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationBatchRunner.run_batch_simulation","title":"<code>run_batch_simulation(self, max_workers=4, soil_overrides=None, site_overrides=None, crop_overrides=None, agro_file_path=None, output_vars=None)</code>","text":"<p>Runs <code>run_simulation</code> for all points in parallel. Assumes data is already prepared.</p> <p>Parameters:</p> Name Type Description Default <code>max_workers</code> <code>int</code> <p>Number of CPU cores to use.</p> <code>4</code> <code>soil_overrides</code> <code>dict</code> <p>Override soil params.</p> <code>None</code> <code>site_overrides</code> <code>dict</code> <p>Override site params.</p> <code>None</code> <code>crop_overrides</code> <code>dict</code> <p>Override crop params.</p> <code>None</code> <code>agro_file_path</code> <code>str</code> <p>Path to a user-provided YAML file. If None, uses the workspace default.</p> <code>None</code> <code>output_vars</code> <code>list</code> <p>Variables to output.</p> <code>None</code> Source code in <code>cropengine/cropengine.py</code> <pre><code>def run_batch_simulation(\n    self,\n    max_workers=4,\n    soil_overrides=None,\n    site_overrides=None,\n    crop_overrides=None,\n    agro_file_path=None,\n    output_vars=None,\n):\n    \"\"\"\n    Runs `run_simulation` for all points in parallel.\n    Assumes data is already prepared.\n\n    Args:\n        max_workers (int, optional): Number of CPU cores to use.\n        soil_overrides (dict, optional): Override soil params.\n        site_overrides (dict, optional): Override site params.\n        crop_overrides (dict, optional): Override crop params.\n        agro_file_path (str, optional): Path to a user-provided YAML file. If None, uses the workspace default.\n        output_vars (list, optional): Variables to output.\n    \"\"\"\n    tasks = []\n\n    print(\n        f\"[BATCH RUN] Preparing execution tasks for {len(self.locations_df)} locations...\"\n    )\n\n    # 1. Build Task List\n    for _, row in self.locations_df.iterrows():\n        task_payload = {\n            \"id\": row[\"id\"],\n            \"latitude\": row[\"latitude\"],\n            \"longitude\": row[\"longitude\"],\n            \"base_workspace_dir\": self.workspace_dir,\n            \"model_name\": self.model_name,\n            # Optional overrides passed to all workers\n            \"soil_overrides\": soil_overrides,\n            \"site_overrides\": site_overrides,\n            \"crop_overrides\": crop_overrides,\n            \"agro_file_path\": agro_file_path,\n            \"output_vars\": output_vars,\n        }\n        tasks.append(task_payload)\n\n    # 2. Execute Parallel Simulation\n    results_list = []\n    print(f\"[BATCH RUN] Starting simulation with {max_workers} workers...\")\n\n    with multiprocessing.Pool(processes=max_workers, maxtasksperchild=1) as pool:\n        iterator = pool.imap(_WOFOST_run_batch_task, tasks)\n\n        for res_df in tqdm(iterator, total=len(tasks), desc=\"Simulating\"):\n            if res_df is not None:\n                results_list.append(res_df)\n\n    # 3. Combine &amp; Save\n    if results_list:\n        final_df = pd.concat(results_list, ignore_index=True)\n        if \"index\" in final_df.columns:\n            final_df.drop(\"index\", axis=1, inplace=True)\n\n        final_df[\"point_id\"] = final_df[\"point_id\"].astype(int)\n\n        output_path = os.path.join(self.workspace_dir, \"batch_results.csv\")\n        final_df.to_csv(output_path, index=False)\n        print(f\"[BATCH RUN] Success! Results saved to {output_path}\")\n        return final_df\n    else:\n        print(\"[BATCH RUN] Failed. No results generated.\")\n        return pd.DataFrame()\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationBatchRunner.update_parameters","title":"<code>update_parameters(self, crop_overrides=None, soil_overrides=None, site_overrides=None)</code>","text":"<p>Updates parameter files for ALL locations in the batch.</p> <p>Parameters:</p> Name Type Description Default <code>crop_overrides</code> <code>dict</code> <p>Updates for 'params_crop.csv'.</p> <code>None</code> <code>soil_overrides</code> <code>dict</code> <p>Updates for 'params_soil.csv'.</p> <code>None</code> <code>site_overrides</code> <code>dict</code> <p>Updates for 'params_site.csv'.</p> <code>None</code> Source code in <code>cropengine/cropengine.py</code> <pre><code>def update_parameters(self, crop_overrides=None, soil_overrides=None, site_overrides=None):\n    \"\"\"\n    Updates parameter files for ALL locations in the batch.\n\n    Args:\n        crop_overrides (dict): Updates for 'params_crop.csv'.\n        soil_overrides (dict): Updates for 'params_soil.csv'.\n        site_overrides (dict): Updates for 'params_site.csv'.\n    \"\"\"\n    print(f\"[BATCH UPDATE] Updating parameters for {len(self.locations_df)} locations...\")\n\n    updated_count = 0\n\n    # Iterate over all point directories\n    for _, row in tqdm(self.locations_df.iterrows(), total=len(self.locations_df), desc=\"Updating Params\"):\n        loc_id = int(row[\"id\"])\n        point_dir = os.path.join(self.workspace_dir, f\"point_{loc_id}\")\n\n        # Use the Single Runner's logic to update this specific folder\n        runner = WOFOSTCropSimulationRunner(model_name=self.model_name, workspace_dir=point_dir)\n\n        if crop_overrides:\n            runner._update_single_file(\"crop_params\", crop_overrides)\n        if soil_overrides:\n            runner._update_single_file(\"soil_params\", soil_overrides)\n        if site_overrides:\n            runner._update_single_file(\"site_params\", site_overrides)\n\n        updated_count += 1\n\n    print(f\"[BATCH UPDATE] Success! Updated parameters in {updated_count} locations.\")\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationRunner","title":"<code> WOFOSTCropSimulationRunner            (WOFOSTOptionsMixin)         </code>","text":"Source code in <code>cropengine/cropengine.py</code> <pre><code>class WOFOSTCropSimulationRunner(WOFOSTOptionsMixin):\n    def __init__(self, model_name, workspace_dir=\"workspace\"):\n        \"\"\"\n        Initialize the runner.\n        Calls update_workspace immediately to set up file paths.\n        \"\"\"\n        self.model_name = model_name\n        self.update_workspace(workspace_dir)\n\n    # =========================================================================\n    # 0. WORKSPACE &amp; PATH MANAGEMENT\n    # =========================================================================\n    def update_workspace(self, new_dir):\n        \"\"\"\n        Updates the workspace directory and refreshes all file paths.\n        Call this method when switching to a new simulation point in a loop.\n        \"\"\"\n        self.workspace_dir = new_dir\n        os.makedirs(self.workspace_dir, exist_ok=True)\n\n        self.files = {\n            \"weather\": os.path.join(self.workspace_dir, \"meteo.xlsx\"),\n            \"soil\": os.path.join(self.workspace_dir, \"soil.csv\"),\n            \"soil_params\": os.path.join(self.workspace_dir, \"params_soil.csv\"),\n            \"site_params\": os.path.join(self.workspace_dir, \"params_site.csv\"),\n            \"crop_params\": os.path.join(self.workspace_dir, \"params_crop.csv\"),\n            \"agro\": os.path.join(self.workspace_dir, \"agro.yaml\"),\n            \"output\": os.path.join(self.workspace_dir, \"simulation_results.csv\"),\n        }\n\n    # =========================================================================\n    # 1. UPDATE PARAMETERS IN WORKSPACE\n    # =========================================================================\n    def update_parameters(self, crop_overrides=None, soil_overrides=None, site_overrides=None):\n        \"\"\"\n        Updates the CSV parameter files in the workspace with new values.\n        Changes are persistent.\n\n        Args:\n            crop_overrides (dict): Updates for 'params_crop.csv'.\n            soil_overrides (dict): Updates for 'params_soil.csv'.\n            site_overrides (dict): Updates for 'params_site.csv'.\n        \"\"\"\n        print(f\"[UPDATE] Updating parameters in {self.workspace_dir}...\")\n        count = 0\n\n        if crop_overrides:\n            self._update_single_file(\"crop_params\", crop_overrides)\n            count += 1\n\n        if soil_overrides:\n            self._update_single_file(\"soil_params\", soil_overrides)\n            count += 1\n\n        if site_overrides:\n            self._update_single_file(\"site_params\", site_overrides)\n            count += 1\n\n        print(f\"[UPDATE] Done. Updated {count} parameter files.\")\n\n    def _update_single_file(self, file_key, overrides):\n        \"\"\"Helper to read, update, and save a parameter CSV.\"\"\"\n        fpath = self.files[file_key]\n        if not os.path.exists(fpath):\n            print(f\"[WARN] Cannot update {file_key}: File not found at {fpath}\")\n            return\n\n        try:\n            df = pd.read_csv(fpath)\n\n            # Ensure 'value' column exists\n            if \"value\" not in df.columns:\n                df[\"value\"] = pd.NA\n\n            for param_name, new_val in overrides.items():\n                # Find row\n                mask = df[\"parameter\"] == param_name\n                if mask.any():\n                    # Handle lists/tables (convert to string representation)\n                    if isinstance(new_val, (list, dict)):\n                        val_to_write = str(new_val)\n                    else:\n                        val_to_write = new_val\n\n                    if file_key == \"crop_params\":\n                        # For crop params, write to 'default' column\n                        df.loc[mask, \"default\"] = val_to_write\n                    else:\n                        # For soil/site params, write to 'value' column     \n                        df.loc[mask, \"value\"] = val_to_write\n\n            df.to_csv(fpath, index=False)\n\n        except Exception as e:\n            print(f\"[ERROR] Failed to update {fpath}: {e}\")\n\n    # =========================================================================\n    # 2. DATA PREPARATION (I/O Bound)\n    #    Downloads data and writes config files. Run this BEFORE the simulation.\n    # =========================================================================\n    def prepare_system(\n        self,\n        latitude,\n        longitude,\n        campaign_start,\n        campaign_end,\n        crop_start,\n        crop_end,\n        crop_name,\n        variety_name,\n        crop_start_type=\"emergence\",\n        crop_end_type=\"harvest\",\n        max_duration=300,\n        timed_events=None,\n        state_events=None,\n        force_update=False,\n        **site_kwargs,\n    ):\n        \"\"\"\n        Prepares the workspace:\n        1. Downloads Weather/Soil if missing.\n        2. Generates and saves Parameter CSVs (Soil, Site, Crop).\n        3. Generates and saves Agromanagement YAML.\n        \"\"\"\n        print(f\"[PREP] Preparing workspace: {self.workspace_dir}\")\n\n        # A. Weather &amp; Soil (Download/Cache)\n        self._ensure_weather(\n            latitude, longitude, campaign_start, campaign_end, force_update\n        )\n        soil_raw_path = self._ensure_soil(latitude, longitude, force_update)\n\n        # B. Soil Params (Check existence before processing)\n        if force_update or not os.path.exists(self.files[\"soil_params\"]):\n            # Only ensure/download raw soil if we actually need to generate params\n            soil_raw_path = self._ensure_soil(latitude, longitude, force_update)\n            soil_df = pd.read_csv(soil_raw_path)\n            self._save_params(WOFOSTSoilParameterProvider(soil_df), \"soil_params\")\n        else:\n            print(\"[PREP] Using existing Soil parameters.\")\n\n        # C. Site Params (Check existence before processing)\n        if force_update or not os.path.exists(self.files[\"site_params\"]):\n            site_provider = WOFOSTSiteParametersProvider(self.model_name, **site_kwargs)\n            # Ensure params are generated inside the provider if needed\n            if hasattr(site_provider, \"get_params\"):\n                site_provider.get_params()\n            self._save_params(site_provider, \"site_params\")\n        else:\n            print(\"[PREP] Using existing Site parameters.\")\n\n        # D. Crop Params (Check existence before processing)\n        if force_update or not os.path.exists(self.files[\"crop_params\"]):\n            self._save_params(\n                WOFOSTCropParametersProvider(crop_name, variety_name), \"crop_params\"\n            )\n        else:\n            print(\"[PREP] Using existing Crop parameters.\")\n\n        # E. Agromanagement Generation (Save to YAML)\n        if force_update or not os.path.exists(self.files[\"agro\"]):\n            self._build_agromanagement(\n                campaign_start,\n                campaign_end,\n                crop_start,\n                crop_end,\n                crop_name,\n                variety_name,\n                crop_start_type,\n                crop_end_type,\n                max_duration,\n                timed_events,\n                state_events,\n            )\n        else:\n            print(\"[PREP] Using existing Agromanagement config.\")\n\n        print(\"[PREP] System Ready.\")\n\n    # =========================================================================\n    # 3. SIMULATION EXECUTION\n    #    Pure logic. Reads prepared files and runs math.\n    # =========================================================================\n    def run_simulation(\n        self,\n        soil_overrides=None,\n        site_overrides=None,\n        crop_overrides=None,\n        agro_file_path=None,\n        output_vars=None,\n    ):\n        \"\"\"\n        Runs the simulation.\n\n        Args:\n            soil_overrides (dict, optional): Override soil params.\n            site_overrides (dict, optional): Override site params.\n            crop_overrides (dict, optional): Override crop params.\n            agro_file_path (str, optional): Path to a user-provided YAML file. If None, uses the workspace default.\n            output_vars (list, optional): Variables to output.\n        \"\"\"\n        print(f\"[RUN] Initializing {self.model_name} in {self.workspace_dir}...\")\n\n        # 1. Resolve Agromanagement File\n        if agro_file_path:\n            if not os.path.exists(agro_file_path):\n                raise FileNotFoundError(\n                    f\"Custom agromanagement file not found: {agro_file_path}\"\n                )\n            agro_path = agro_file_path\n            print(f\"[RUN] Using custom agromanagement: {agro_path}\")\n        else:\n            if not os.path.exists(self.files[\"agro\"]):\n                raise FileNotFoundError(\n                    \"Default agromanagement file missing. Run 'prepare_system' or provide 'custom_agro_file'.\"\n                )\n            agro_path = self.files[\"agro\"]\n\n        # 1. Load Weather (Must exist)\n        if not os.path.exists(self.files[\"weather\"]) or not os.path.exists(agro_path):\n            raise FileNotFoundError(\n                \"Missing weather or agro files. Run 'prepare_system' first.\"\n            )\n\n        weather_provider = ExcelWeatherDataProvider(\n            self.files[\"weather\"], force_reload=True\n        )\n        agromanagement = YAMLAgroManagementReader(agro_path)\n\n        # 2. Load Parameters (Priority: DF Input -&gt; CSV File -&gt; Error)\n        soil_dict = self._load_param_dict(\"soil_params\", \"value\")\n        site_dict = self._load_param_dict(\"site_params\", \"value\")\n        crop_dict = self._load_param_dict(\"crop_params\", \"default\")\n\n        if soil_overrides:\n            soil_dict.update(soil_overrides)\n        if site_overrides:\n            site_dict.update(site_overrides)\n        if crop_overrides:\n            crop_dict.update(crop_overrides)\n\n        parameters = ParameterProvider(\n            cropdata=crop_dict, soildata=soil_dict, sitedata=site_dict\n        )\n\n        # 3. Instantiate &amp; Run\n        try:\n            ModelClass = get_model_class(self.model_name)\n            if output_vars:\n                wofsim = ModelClass(\n                    parameters,\n                    weather_provider,\n                    agromanagement,\n                    output_vars=output_vars,\n                )\n            else:\n                wofsim = ModelClass(parameters, weather_provider, agromanagement)\n            wofsim.run_till_terminate()\n\n            # 4. Save Output\n            df_results = pd.DataFrame(wofsim.get_output())\n            df_results.to_csv(self.files[\"output\"], index=False)\n            return df_results\n\n        except Exception as e:\n            raise RuntimeError(f\"Simulation Failed: {e}\")\n\n    # =========================================================================\n    # 4. INTERNAL HELPERS\n    # =========================================================================\n    def _save_params(self, provider, file_key):\n        \"\"\"Helper to extract metadata from a provider and save to CSV.\"\"\"\n        try:\n            _ = provider.get_params()\n            param_metadata = provider.param_metadata\n        except:\n            param_metadata = provider.param_metadata\n\n        df = pd.DataFrame(param_metadata).sort_values(by=\"parameter\")\n        df.to_csv(self.files[file_key], index=False)\n\n    def _load_param_dict(self, file_key, value_col):\n        \"\"\"\n        Helper to load parameters from disk.\n        \"\"\"\n        # 1. Validate File Existence\n        file_path = self.files[file_key]\n        if not os.path.exists(file_path):\n            raise FileNotFoundError(f\"Missing parameter file: {file_path}\")\n\n        # 2. Load DataFrame from CSV\n        df = pd.read_csv(file_path)\n\n        # 3. Determine Column Name (fallback to 'default' if strict col missing)\n        col = value_col if value_col in df.columns else \"default\"\n\n        # 3. Build Dictionary with Type Conversion\n        params = {}\n\n        # Iterate manually to handle mixed types (floats vs lists) safely\n        for _, row in df.iterrows():\n            key = row[\"parameter\"]\n            raw_val = row[col]\n\n            # Skip if strict value required and missing\n            if col == \"value\" and pd.isna(raw_val):\n                continue\n\n            # If value is already a float/int/list (from DataFrame override), use it directly\n            if not isinstance(raw_val, str):\n                params[key] = raw_val\n                continue\n\n            # TYPE CONVERSION LOGIC (String -&gt; Number/List)\n            raw_val = raw_val.strip()\n            final_val = raw_val  # Default to original string if parsing fails\n\n            # A. Try converting to List (e.g., \"[0.0, 1.5]\")\n            if raw_val.startswith(\"[\") and raw_val.endswith(\"]\"):\n                try:\n                    final_val = ast.literal_eval(raw_val)\n                except (ValueError, SyntaxError):\n                    pass\n\n            # B. Try converting to Number (e.g., \"10.0\")\n            else:\n                try:\n                    final_val = float(raw_val)\n                    if final_val.is_integer():\n                        final_val = int(final_val)\n                except ValueError:\n                    pass\n\n            params[key] = final_val\n\n        return params\n\n    def _ensure_weather(self, lat, lon, start, end, force):\n        if not force and os.path.exists(self.files[\"weather\"]):\n            return self.files[\"weather\"]\n\n        d_end = (\n            datetime.strptime(end, \"%Y-%m-%d\").date() + timedelta(days=1)\n        ).strftime(\"%Y-%m-%d\")\n        meteo = GEEWeatherDataProvider(\n            start_date=start,\n            end_date=d_end,\n            latitude=lat,\n            longitude=lon,\n            filepath=self.files[\"weather\"],\n        )\n        meteo.save_weather_excel()\n\n    def _ensure_soil(self, lat, lon, force):\n        if not force and os.path.exists(self.files[\"soil\"]):\n            return self.files[\"soil\"]\n\n        soil = GEEIsricSoilDataProvider(\n            latitude=lat, longitude=lon, depths=[\"0-5cm\"], filepath=self.files[\"soil\"]\n        )\n        soil.get_data()\n        return self.files[\"soil\"]\n\n    def _build_agromanagement(\n        self,\n        c_start,\n        c_end,\n        start,\n        end,\n        crop,\n        var,\n        st_type,\n        end_type,\n        dur,\n        timed_events,\n        state_events,\n    ):\n        agro = WOFOSTAgroManagementProvider()\n        agro.add_campaign(\n            c_start,\n            c_end,\n            crop,\n            var,\n            start,\n            end,\n            st_type,\n            end_type,\n            dur,\n            timed_events,\n            state_events,\n        )\n        agro.add_trailing_empty_campaign()\n        agro.save_to_yaml(self.files[\"agro\"])\n\n    # =========================================================================\n    # 5. OPTIMIZATION\n    # =========================================================================\n    def get_rerunner(self):\n        \"\"\"\n        Returns a WOFOSTFastEngine instance instead of a closure.\n        \"\"\"\n        # Validation &amp; Pre-loading\n        if not os.path.exists(self.files[\"weather\"]):\n            raise FileNotFoundError(\"Run prepare_system first.\")\n\n        # Load the path\n        weather = self.files[\"weather\"]\n        agro = self.files[\"agro\"]\n\n        # Load Dictionaries\n        base_params = {\n            \"soil\": self._load_param_dict(\"soil_params\", \"value\"),\n            \"site\": self._load_param_dict(\"site_params\", \"value\"),\n            \"crop\": self._load_param_dict(\"crop_params\", \"default\"),\n        }\n\n        # Return the class instance\n        return _WOFOSTLazyEngine(self.model_name, weather, agro, base_params)\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationRunner.__init__","title":"<code>__init__(self, model_name, workspace_dir='workspace')</code>  <code>special</code>","text":"<p>Initialize the runner. Calls update_workspace immediately to set up file paths.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def __init__(self, model_name, workspace_dir=\"workspace\"):\n    \"\"\"\n    Initialize the runner.\n    Calls update_workspace immediately to set up file paths.\n    \"\"\"\n    self.model_name = model_name\n    self.update_workspace(workspace_dir)\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationRunner.get_rerunner","title":"<code>get_rerunner(self)</code>","text":"<p>Returns a WOFOSTFastEngine instance instead of a closure.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def get_rerunner(self):\n    \"\"\"\n    Returns a WOFOSTFastEngine instance instead of a closure.\n    \"\"\"\n    # Validation &amp; Pre-loading\n    if not os.path.exists(self.files[\"weather\"]):\n        raise FileNotFoundError(\"Run prepare_system first.\")\n\n    # Load the path\n    weather = self.files[\"weather\"]\n    agro = self.files[\"agro\"]\n\n    # Load Dictionaries\n    base_params = {\n        \"soil\": self._load_param_dict(\"soil_params\", \"value\"),\n        \"site\": self._load_param_dict(\"site_params\", \"value\"),\n        \"crop\": self._load_param_dict(\"crop_params\", \"default\"),\n    }\n\n    # Return the class instance\n    return _WOFOSTLazyEngine(self.model_name, weather, agro, base_params)\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationRunner.prepare_system","title":"<code>prepare_system(self, latitude, longitude, campaign_start, campaign_end, crop_start, crop_end, crop_name, variety_name, crop_start_type='emergence', crop_end_type='harvest', max_duration=300, timed_events=None, state_events=None, force_update=False, **site_kwargs)</code>","text":"<p>Prepares the workspace: 1. Downloads Weather/Soil if missing. 2. Generates and saves Parameter CSVs (Soil, Site, Crop). 3. Generates and saves Agromanagement YAML.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def prepare_system(\n    self,\n    latitude,\n    longitude,\n    campaign_start,\n    campaign_end,\n    crop_start,\n    crop_end,\n    crop_name,\n    variety_name,\n    crop_start_type=\"emergence\",\n    crop_end_type=\"harvest\",\n    max_duration=300,\n    timed_events=None,\n    state_events=None,\n    force_update=False,\n    **site_kwargs,\n):\n    \"\"\"\n    Prepares the workspace:\n    1. Downloads Weather/Soil if missing.\n    2. Generates and saves Parameter CSVs (Soil, Site, Crop).\n    3. Generates and saves Agromanagement YAML.\n    \"\"\"\n    print(f\"[PREP] Preparing workspace: {self.workspace_dir}\")\n\n    # A. Weather &amp; Soil (Download/Cache)\n    self._ensure_weather(\n        latitude, longitude, campaign_start, campaign_end, force_update\n    )\n    soil_raw_path = self._ensure_soil(latitude, longitude, force_update)\n\n    # B. Soil Params (Check existence before processing)\n    if force_update or not os.path.exists(self.files[\"soil_params\"]):\n        # Only ensure/download raw soil if we actually need to generate params\n        soil_raw_path = self._ensure_soil(latitude, longitude, force_update)\n        soil_df = pd.read_csv(soil_raw_path)\n        self._save_params(WOFOSTSoilParameterProvider(soil_df), \"soil_params\")\n    else:\n        print(\"[PREP] Using existing Soil parameters.\")\n\n    # C. Site Params (Check existence before processing)\n    if force_update or not os.path.exists(self.files[\"site_params\"]):\n        site_provider = WOFOSTSiteParametersProvider(self.model_name, **site_kwargs)\n        # Ensure params are generated inside the provider if needed\n        if hasattr(site_provider, \"get_params\"):\n            site_provider.get_params()\n        self._save_params(site_provider, \"site_params\")\n    else:\n        print(\"[PREP] Using existing Site parameters.\")\n\n    # D. Crop Params (Check existence before processing)\n    if force_update or not os.path.exists(self.files[\"crop_params\"]):\n        self._save_params(\n            WOFOSTCropParametersProvider(crop_name, variety_name), \"crop_params\"\n        )\n    else:\n        print(\"[PREP] Using existing Crop parameters.\")\n\n    # E. Agromanagement Generation (Save to YAML)\n    if force_update or not os.path.exists(self.files[\"agro\"]):\n        self._build_agromanagement(\n            campaign_start,\n            campaign_end,\n            crop_start,\n            crop_end,\n            crop_name,\n            variety_name,\n            crop_start_type,\n            crop_end_type,\n            max_duration,\n            timed_events,\n            state_events,\n        )\n    else:\n        print(\"[PREP] Using existing Agromanagement config.\")\n\n    print(\"[PREP] System Ready.\")\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationRunner.run_simulation","title":"<code>run_simulation(self, soil_overrides=None, site_overrides=None, crop_overrides=None, agro_file_path=None, output_vars=None)</code>","text":"<p>Runs the simulation.</p> <p>Parameters:</p> Name Type Description Default <code>soil_overrides</code> <code>dict</code> <p>Override soil params.</p> <code>None</code> <code>site_overrides</code> <code>dict</code> <p>Override site params.</p> <code>None</code> <code>crop_overrides</code> <code>dict</code> <p>Override crop params.</p> <code>None</code> <code>agro_file_path</code> <code>str</code> <p>Path to a user-provided YAML file. If None, uses the workspace default.</p> <code>None</code> <code>output_vars</code> <code>list</code> <p>Variables to output.</p> <code>None</code> Source code in <code>cropengine/cropengine.py</code> <pre><code>def run_simulation(\n    self,\n    soil_overrides=None,\n    site_overrides=None,\n    crop_overrides=None,\n    agro_file_path=None,\n    output_vars=None,\n):\n    \"\"\"\n    Runs the simulation.\n\n    Args:\n        soil_overrides (dict, optional): Override soil params.\n        site_overrides (dict, optional): Override site params.\n        crop_overrides (dict, optional): Override crop params.\n        agro_file_path (str, optional): Path to a user-provided YAML file. If None, uses the workspace default.\n        output_vars (list, optional): Variables to output.\n    \"\"\"\n    print(f\"[RUN] Initializing {self.model_name} in {self.workspace_dir}...\")\n\n    # 1. Resolve Agromanagement File\n    if agro_file_path:\n        if not os.path.exists(agro_file_path):\n            raise FileNotFoundError(\n                f\"Custom agromanagement file not found: {agro_file_path}\"\n            )\n        agro_path = agro_file_path\n        print(f\"[RUN] Using custom agromanagement: {agro_path}\")\n    else:\n        if not os.path.exists(self.files[\"agro\"]):\n            raise FileNotFoundError(\n                \"Default agromanagement file missing. Run 'prepare_system' or provide 'custom_agro_file'.\"\n            )\n        agro_path = self.files[\"agro\"]\n\n    # 1. Load Weather (Must exist)\n    if not os.path.exists(self.files[\"weather\"]) or not os.path.exists(agro_path):\n        raise FileNotFoundError(\n            \"Missing weather or agro files. Run 'prepare_system' first.\"\n        )\n\n    weather_provider = ExcelWeatherDataProvider(\n        self.files[\"weather\"], force_reload=True\n    )\n    agromanagement = YAMLAgroManagementReader(agro_path)\n\n    # 2. Load Parameters (Priority: DF Input -&gt; CSV File -&gt; Error)\n    soil_dict = self._load_param_dict(\"soil_params\", \"value\")\n    site_dict = self._load_param_dict(\"site_params\", \"value\")\n    crop_dict = self._load_param_dict(\"crop_params\", \"default\")\n\n    if soil_overrides:\n        soil_dict.update(soil_overrides)\n    if site_overrides:\n        site_dict.update(site_overrides)\n    if crop_overrides:\n        crop_dict.update(crop_overrides)\n\n    parameters = ParameterProvider(\n        cropdata=crop_dict, soildata=soil_dict, sitedata=site_dict\n    )\n\n    # 3. Instantiate &amp; Run\n    try:\n        ModelClass = get_model_class(self.model_name)\n        if output_vars:\n            wofsim = ModelClass(\n                parameters,\n                weather_provider,\n                agromanagement,\n                output_vars=output_vars,\n            )\n        else:\n            wofsim = ModelClass(parameters, weather_provider, agromanagement)\n        wofsim.run_till_terminate()\n\n        # 4. Save Output\n        df_results = pd.DataFrame(wofsim.get_output())\n        df_results.to_csv(self.files[\"output\"], index=False)\n        return df_results\n\n    except Exception as e:\n        raise RuntimeError(f\"Simulation Failed: {e}\")\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationRunner.update_parameters","title":"<code>update_parameters(self, crop_overrides=None, soil_overrides=None, site_overrides=None)</code>","text":"<p>Updates the CSV parameter files in the workspace with new values. Changes are persistent.</p> <p>Parameters:</p> Name Type Description Default <code>crop_overrides</code> <code>dict</code> <p>Updates for 'params_crop.csv'.</p> <code>None</code> <code>soil_overrides</code> <code>dict</code> <p>Updates for 'params_soil.csv'.</p> <code>None</code> <code>site_overrides</code> <code>dict</code> <p>Updates for 'params_site.csv'.</p> <code>None</code> Source code in <code>cropengine/cropengine.py</code> <pre><code>def update_parameters(self, crop_overrides=None, soil_overrides=None, site_overrides=None):\n    \"\"\"\n    Updates the CSV parameter files in the workspace with new values.\n    Changes are persistent.\n\n    Args:\n        crop_overrides (dict): Updates for 'params_crop.csv'.\n        soil_overrides (dict): Updates for 'params_soil.csv'.\n        site_overrides (dict): Updates for 'params_site.csv'.\n    \"\"\"\n    print(f\"[UPDATE] Updating parameters in {self.workspace_dir}...\")\n    count = 0\n\n    if crop_overrides:\n        self._update_single_file(\"crop_params\", crop_overrides)\n        count += 1\n\n    if soil_overrides:\n        self._update_single_file(\"soil_params\", soil_overrides)\n        count += 1\n\n    if site_overrides:\n        self._update_single_file(\"site_params\", site_overrides)\n        count += 1\n\n    print(f\"[UPDATE] Done. Updated {count} parameter files.\")\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTCropSimulationRunner.update_workspace","title":"<code>update_workspace(self, new_dir)</code>","text":"<p>Updates the workspace directory and refreshes all file paths. Call this method when switching to a new simulation point in a loop.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def update_workspace(self, new_dir):\n    \"\"\"\n    Updates the workspace directory and refreshes all file paths.\n    Call this method when switching to a new simulation point in a loop.\n    \"\"\"\n    self.workspace_dir = new_dir\n    os.makedirs(self.workspace_dir, exist_ok=True)\n\n    self.files = {\n        \"weather\": os.path.join(self.workspace_dir, \"meteo.xlsx\"),\n        \"soil\": os.path.join(self.workspace_dir, \"soil.csv\"),\n        \"soil_params\": os.path.join(self.workspace_dir, \"params_soil.csv\"),\n        \"site_params\": os.path.join(self.workspace_dir, \"params_site.csv\"),\n        \"crop_params\": os.path.join(self.workspace_dir, \"params_crop.csv\"),\n        \"agro\": os.path.join(self.workspace_dir, \"agro.yaml\"),\n        \"output\": os.path.join(self.workspace_dir, \"simulation_results.csv\"),\n    }\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTOptionsMixin","title":"<code> WOFOSTOptionsMixin        </code>","text":"<p>Mixin class that provides helper methods for UI dropdowns. Inherit from this to give your class access to model/crop options.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>class WOFOSTOptionsMixin:\n    \"\"\"\n    Mixin class that provides helper methods for UI dropdowns.\n    Inherit from this to give your class access to model/crop options.\n    \"\"\"\n\n    def get_model_options(self):\n        \"\"\"Returns list of available models.\"\"\"\n        return get_available_models()\n\n    def get_crop_options(self, model_name):\n        \"\"\"Returns list of crops for the selected model.\"\"\"\n        return get_available_crops(model_name)\n\n    def get_variety_options(self, model_name, crop_name):\n        \"\"\"Returns list of varieties for the selected crop.\"\"\"\n        return get_available_crop_varieties(model_name, crop_name)\n\n    def get_crop_start_end_options(self):\n        \"\"\"Returns dict of crop start and crop end type available in WOFOST.\"\"\"\n        return {\n            \"crop_start_type\": [\"sowing\", \"emergence\"],\n            \"crop_end_type\": [\"maturity\", \"harvest\", \"earliest\"],\n        }\n\n    def get_output_variables(self, model_name):\n        \"\"\"Returns list of output variables for a given simulation model.\"\"\"\n        return get_output_variables(model_name)\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTOptionsMixin.get_crop_options","title":"<code>get_crop_options(self, model_name)</code>","text":"<p>Returns list of crops for the selected model.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def get_crop_options(self, model_name):\n    \"\"\"Returns list of crops for the selected model.\"\"\"\n    return get_available_crops(model_name)\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTOptionsMixin.get_crop_start_end_options","title":"<code>get_crop_start_end_options(self)</code>","text":"<p>Returns dict of crop start and crop end type available in WOFOST.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def get_crop_start_end_options(self):\n    \"\"\"Returns dict of crop start and crop end type available in WOFOST.\"\"\"\n    return {\n        \"crop_start_type\": [\"sowing\", \"emergence\"],\n        \"crop_end_type\": [\"maturity\", \"harvest\", \"earliest\"],\n    }\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTOptionsMixin.get_model_options","title":"<code>get_model_options(self)</code>","text":"<p>Returns list of available models.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def get_model_options(self):\n    \"\"\"Returns list of available models.\"\"\"\n    return get_available_models()\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTOptionsMixin.get_output_variables","title":"<code>get_output_variables(self, model_name)</code>","text":"<p>Returns list of output variables for a given simulation model.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def get_output_variables(self, model_name):\n    \"\"\"Returns list of output variables for a given simulation model.\"\"\"\n    return get_output_variables(model_name)\n</code></pre>"},{"location":"cropengine/#cropengine.cropengine.WOFOSTOptionsMixin.get_variety_options","title":"<code>get_variety_options(self, model_name, crop_name)</code>","text":"<p>Returns list of varieties for the selected crop.</p> Source code in <code>cropengine/cropengine.py</code> <pre><code>def get_variety_options(self, model_name, crop_name):\n    \"\"\"Returns list of varieties for the selected crop.\"\"\"\n    return get_available_crop_varieties(model_name, crop_name)\n</code></pre>"},{"location":"faq/","title":"FAQ","text":""},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install cropengine, run this command in your terminal:</p> <pre><code>pip install cropengine\n</code></pre> <p>This is the preferred method to install cropengine, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-sources","title":"From sources","text":"<p>To install cropengine from sources, run this command in your terminal:</p> <pre><code>pip install git+https://github.com/geonextgis/cropengine\n</code></pre>"},{"location":"models/","title":"models module","text":"<p>Module to fetch information about models</p>"},{"location":"models/#cropengine.models.get_model_class","title":"<code>get_model_class(model_id)</code>","text":"<p>Returns the model class based on the string ID. Raises ValueError if the model ID is not found.</p> Source code in <code>cropengine/models.py</code> <pre><code>def get_model_class(model_id):\n    \"\"\"\n    Returns the model class based on the string ID.\n    Raises ValueError if the model ID is not found.\n    \"\"\"\n    if model_id in MODEL_CLASS_MAPPING:\n        return MODEL_CLASS_MAPPING[model_id]\n    else:\n        valid_keys = list(MODEL_CLASS_MAPPING.keys())\n        raise ValueError(\n            f\"Model ID '{model_id}' not found. Available models: {valid_keys}\"\n        )\n</code></pre>"},{"location":"optimizer/","title":"optimizer module","text":"<p>Module for parameter optimization</p>"},{"location":"optimizer/#cropengine.optimizer.WOFOSTOptimizer","title":"<code> WOFOSTOptimizer        </code>","text":"<p>A generalized optimizer for WOFOST simulations using Optuna.</p> <p>Features: - Parallel Execution: Uses ProcessPoolExecutor to bypass the GIL and utilize all CPU cores. - Memory Efficient: Loads simulation engines (Weather/Soil/Agro) into RAM once and reuses them. - Multi-Objective: Supports optimizing multiple targets simultaneously (Pareto optimization). - Agnostic: Works with both Single-Location Runners and Batch Runners.</p> Source code in <code>cropengine/optimizer.py</code> <pre><code>class WOFOSTOptimizer:\n    \"\"\"\n    A generalized optimizer for WOFOST simulations using Optuna.\n\n    Features:\n    - **Parallel Execution**: Uses ProcessPoolExecutor to bypass the GIL and utilize all CPU cores.\n    - **Memory Efficient**: Loads simulation engines (Weather/Soil/Agro) into RAM once and reuses them.\n    - **Multi-Objective**: Supports optimizing multiple targets simultaneously (Pareto optimization).\n    - **Agnostic**: Works with both Single-Location Runners and Batch Runners.\n    \"\"\"\n\n    def __init__(self, runner, observed_data):\n        \"\"\"\n        Instantiate WOFOSTOptimizer.\n\n        Args:\n        runner: An instance of WOFOSTCropSimulationRunner or WOFOSTCropSimulationBatchRunner.\n        observed_data (pd.DataFrame): Ground truth data used by the loss function.\n        \"\"\"\n        self.runner = runner\n        self.observed_data = observed_data\n        self.is_batch = hasattr(runner, \"get_batch_rerunners\")\n        self.engines = {}\n\n    def _get_sampler(self, sampler_input: Union[str, optuna.samplers.BaseSampler, None]) -&gt; optuna.samplers.BaseSampler:\n        \"\"\"\n        Helper to resolve the sampler from a string name or object.\n        \"\"\"\n        if sampler_input is None:\n            return None  # Let Optuna choose default (usually TPESampler)\n\n        if isinstance(sampler_input, optuna.samplers.BaseSampler):\n            return sampler_input\n\n        if isinstance(sampler_input, str):\n            name = sampler_input.lower().strip()\n\n            try:\n                if name == \"random\":\n                    return optuna.samplers.RandomSampler()\n\n                elif name == \"tpe\":\n                    return optuna.samplers.TPESampler()\n\n                elif name == \"cmaes\":\n                    # Requires 'cma' package\n                    return optuna.samplers.CmaEsSampler()\n\n                elif name == \"nsgaii\":\n                    return optuna.samplers.NSGAIISampler()\n\n                elif name == \"nsgaiii\":\n                    return optuna.samplers.NSGAIIISampler()\n\n                elif name == \"qmc\":\n                    # Quasi-Monte Carlo (requires Scipy)\n                    return optuna.samplers.QMCSampler()\n\n                elif name == \"bruteforce\":\n                    return optuna.samplers.BruteForceSampler()\n\n                elif name == \"grid\":\n                    return optuna.samplers.GridSampler(search_space={}) # Note: GridSampler requires search space passed later or usually managed by study\n\n                elif name == \"botorch\":\n                    # Requires 'botorch' package\n                    from optuna.integration import BoTorchSampler\n                    return BoTorchSampler()\n\n                elif name == \"gp\":\n                    # Gaussian Process Sampler (Requires 'botorch' &amp; 'scipy')\n                    return optuna.samplers.GPSampler()\n\n                else:\n                    raise ValueError(f\"Unknown sampler name: '{sampler_input}'.\")\n\n            except ImportError as e:\n                # Catch missing dependency errors (e.g., missing botorch or cma)\n                raise ImportError(f\"Could not initialize sampler '{name}'. Missing dependency: {e}. Please install the required package (e.g., 'pip install botorch' or 'pip install cma').\")\n\n        raise TypeError(\"Sampler must be a string name or an optuna.samplers.BaseSampler object.\")\n\n    def get_best_params(self, study: optuna.Study, search_space: Callable) -&gt; Dict:\n        \"\"\"\n        Retrieves the optimized parameters from the study, reconstructing any \n        complex structures (lists/tables) defined in the search space.\n\n        Args:\n            study (optuna.Study): The completed optimization study.\n            search_space (callable): The original search space function used for optimization.\n                                     Required to reconstruct complex parameters (lists/tables)\n                                     from the scalar values stored in the study.\n\n        Returns:\n            dict: A dictionary of parameter overrides (e.g., {'crop_params': {...}})\n                  containing the best values found during optimization.\n        \"\"\"        \n        best_overrides = search_space(FixedTrial(study.best_params))\n\n        return best_overrides\n\n    def optimize(\n        self,\n        search_space: Callable[[optuna.Trial], Dict],\n        loss_func: Callable[[pd.DataFrame, pd.DataFrame], Union[float, List[float]]],\n        n_trials: int = 100,\n        n_workers: int = 4,\n        sampler: Optional[optuna.samplers.BaseSampler] = None,\n        directions: Optional[List[str]] = None,\n        output_folder: Optional[str] = None,\n    ) -&gt; optuna.Study:\n        \"\"\"\n        Runs the optimization loop.\n\n        Args:\n            search_space (callable): A function that takes an Optuna `trial` object\n                                     and returns a dictionary of parameter overrides.\n                                     Example structure:\n                                     {'crop_params': {'TSUM1': 1000}, 'soil_params': {...}}\n\n            loss_func (callable): A function that takes (df_simulated, df_observed).\n                                  Returns a float (single-objective) or list of floats (multi-objective).\n\n            n_trials (int): Number of optimization trials to run.\n\n            n_workers (int): Number of parallel processes to spawn.\n\n            sampler (str | optuna.samplers.BaseSampler | None): \n                The optimization strategy. Supported strings:\n\n                **Standard:**\n                - \"TPE\": Tree-structured Parzen Estimator (Default, good general purpose).\n                - \"Random\": Pure random search.\n\n                **Advanced (May require extra packages):**\n                - \"GP\": Gaussian Process Sampler. Excellent for expensive simulations. (Requires `botorch`).\n                - \"CmaEs\": Covariance Matrix Adaptation. Good for continuous global optima. (Requires `cma`).\n                - \"BoTorch\": Bayesian Optimization. (Requires `botorch`).\n\n                **Multi-Objective:**\n                - \"NSGAII\": Standard for Pareto optimization.\n                - \"NSGAIII\": For many-objective problems (3+ targets).\n\n                **Grid/Deterministic:**\n                - \"BruteForce\": Tries ALL combinations.\n                - \"Grid\": Tries specified grid points.\n                - \"QMC\": Quasi-Monte Carlo.\n\n            directions (list[str]): Optimization directions.\n                                    Default is [\"minimize\"].\n                                    For multi-objective, use e.g., [\"minimize\", \"maximize\"].\n\n            output_folder (str, optional): Path to a folder where simulation results\n                                           for EACH trial will be saved (e.g., 'trial_0.csv').\n                                           If None, results are not saved to disk.\n\n        Returns:\n            optuna.Study: The completed study object containing best params and trials.\n        \"\"\"\n        # 1. SETUP OUTPUT FOLDER\n        if output_folder:\n            os.makedirs(output_folder, exist_ok=True)\n            print(f\"[OPT] Saving all trial outputs to: {output_folder}\")\n\n        # 2. RESOLVE SAMPLER\n        optuna_sampler = self._get_sampler(sampler)\n        if optuna_sampler:\n             print(f\"[OPT] Using Sampler: {optuna_sampler.__class__.__name__}\")\n\n        # 3. PRE-LOADING PHASE\n        print(\"[OPT] Loading simulation engines...\")\n        if not self.engines:\n            if self.is_batch:\n                self.engines = self.runner.get_batch_rerunners()\n            else:\n                self.engines = {0: self.runner.get_rerunner()}\n\n        print(f\"[OPT] Ready. Optimized execution for {len(self.engines)} locations.\")\n\n        # 4. DEFINE OBJECTIVE\n        def objective(trial):\n            # A. Get Parameters from Optuna\n            overrides = search_space(trial)\n\n            # B. Prepare Tasks for Parallel Workers\n            tasks = [\n                (loc_id, engine, overrides) for loc_id, engine in self.engines.items()\n            ]\n\n            results = []\n\n            # C. Execute in Parallel using JOBLIB\n            try:\n                # Parallel returns a list of results in order\n                results_raw = Parallel(n_jobs=n_workers, backend=\"loky\")(\n                    delayed(_global_worker_task)(task) for task in tasks\n                )\n\n                # Filter out None values (failed runs)\n                results = [res for res in results_raw if res is not None]\n\n            except Exception as e:\n                logging.error(f\"[OPT] Parallel Execution Error: {e}\")\n                results = []\n\n            # D. Validation\n            if not results:\n                if directions and len(directions) &gt; 1:\n                    return [float(\"inf\")] * len(directions)\n                return float(\"inf\")\n\n            # E. Aggregation &amp; Loss Calculation\n            try:\n                # 1. Merge all location results into one DataFrame\n                df_sim_all = pd.concat(results, ignore_index=True)\n\n                if output_folder:\n                    file_path = os.path.join(output_folder, f\"trial_{trial.number}.csv\")\n                    df_sim_all.to_csv(file_path, index=False)\n\n                # 2. Compute Loss (User Function)\n                loss = loss_func(df_sim_all, self.observed_data)\n                return loss\n\n            except Exception as e:\n                logging.error(f\"[OPT] Loss Calculation Error: {e}\")\n                if directions and len(directions) &gt; 1:\n                    return [float(\"inf\")] * len(directions)\n                return float(\"inf\")\n\n        # 5. CREATE STUDY\n        if directions is None:\n            directions = [\"minimize\"]\n\n        study = optuna.create_study(directions=directions, sampler=optuna_sampler)\n\n        print(\n            f\"[OPT] Starting {len(directions)}-objective optimization with {n_trials} trials...\"\n        )\n        study.optimize(objective, n_trials=n_trials)\n\n        print(\"[OPT] Optimization Finished.\")\n\n        if len(directions) == 1:\n            print(\"Best params:\", study.best_params)\n        else:\n            print(\n                f\"Pareto front found with {len(study.best_trials)} optimal solutions.\"\n            )\n\n        return study\n</code></pre>"},{"location":"optimizer/#cropengine.optimizer.WOFOSTOptimizer.__init__","title":"<code>__init__(self, runner, observed_data)</code>  <code>special</code>","text":"<p>Instantiate WOFOSTOptimizer.</p> <p>observed_data (pd.DataFrame): Ground truth data used by the loss function.</p> Source code in <code>cropengine/optimizer.py</code> <pre><code>def __init__(self, runner, observed_data):\n    \"\"\"\n    Instantiate WOFOSTOptimizer.\n\n    Args:\n    runner: An instance of WOFOSTCropSimulationRunner or WOFOSTCropSimulationBatchRunner.\n    observed_data (pd.DataFrame): Ground truth data used by the loss function.\n    \"\"\"\n    self.runner = runner\n    self.observed_data = observed_data\n    self.is_batch = hasattr(runner, \"get_batch_rerunners\")\n    self.engines = {}\n</code></pre>"},{"location":"optimizer/#cropengine.optimizer.WOFOSTOptimizer.get_best_params","title":"<code>get_best_params(self, study, search_space)</code>","text":"<p>Retrieves the optimized parameters from the study, reconstructing any  complex structures (lists/tables) defined in the search space.</p> <p>Parameters:</p> Name Type Description Default <code>study</code> <code>optuna.Study</code> <p>The completed optimization study.</p> required <code>search_space</code> <code>callable</code> <p>The original search space function used for optimization.                      Required to reconstruct complex parameters (lists/tables)                      from the scalar values stored in the study.</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of parameter overrides (e.g., {'crop_params': {...}})       containing the best values found during optimization.</p> Source code in <code>cropengine/optimizer.py</code> <pre><code>def get_best_params(self, study: optuna.Study, search_space: Callable) -&gt; Dict:\n    \"\"\"\n    Retrieves the optimized parameters from the study, reconstructing any \n    complex structures (lists/tables) defined in the search space.\n\n    Args:\n        study (optuna.Study): The completed optimization study.\n        search_space (callable): The original search space function used for optimization.\n                                 Required to reconstruct complex parameters (lists/tables)\n                                 from the scalar values stored in the study.\n\n    Returns:\n        dict: A dictionary of parameter overrides (e.g., {'crop_params': {...}})\n              containing the best values found during optimization.\n    \"\"\"        \n    best_overrides = search_space(FixedTrial(study.best_params))\n\n    return best_overrides\n</code></pre>"},{"location":"optimizer/#cropengine.optimizer.WOFOSTOptimizer.optimize","title":"<code>optimize(self, search_space, loss_func, n_trials=100, n_workers=4, sampler=None, directions=None, output_folder=None)</code>","text":"<p>Runs the optimization loop.</p> <p>Parameters:</p> Name Type Description Default <code>search_space</code> <code>callable</code> <p>A function that takes an Optuna <code>trial</code> object                      and returns a dictionary of parameter overrides.                      Example structure:                      {'crop_params': {'TSUM1': 1000}, 'soil_params': {...}}</p> required <code>loss_func</code> <code>callable</code> <p>A function that takes (df_simulated, df_observed).                   Returns a float (single-objective) or list of floats (multi-objective).</p> required <code>n_trials</code> <code>int</code> <p>Number of optimization trials to run.</p> <code>100</code> <code>n_workers</code> <code>int</code> <p>Number of parallel processes to spawn.</p> <code>4</code> <code>sampler</code> <code>str | optuna.samplers.BaseSampler | None</code> <p>The optimization strategy. Supported strings:</p> <p>Standard: - \"TPE\": Tree-structured Parzen Estimator (Default, good general purpose). - \"Random\": Pure random search.</p> <p>Advanced (May require extra packages): - \"GP\": Gaussian Process Sampler. Excellent for expensive simulations. (Requires <code>botorch</code>). - \"CmaEs\": Covariance Matrix Adaptation. Good for continuous global optima. (Requires <code>cma</code>). - \"BoTorch\": Bayesian Optimization. (Requires <code>botorch</code>).</p> <p>Multi-Objective: - \"NSGAII\": Standard for Pareto optimization. - \"NSGAIII\": For many-objective problems (3+ targets).</p> <p>Grid/Deterministic: - \"BruteForce\": Tries ALL combinations. - \"Grid\": Tries specified grid points. - \"QMC\": Quasi-Monte Carlo.</p> <code>None</code> <code>directions</code> <code>list[str]</code> <p>Optimization directions.                     Default is [\"minimize\"].                     For multi-objective, use e.g., [\"minimize\", \"maximize\"].</p> <code>None</code> <code>output_folder</code> <code>str</code> <p>Path to a folder where simulation results                            for EACH trial will be saved (e.g., 'trial_0.csv').                            If None, results are not saved to disk.</p> <code>None</code> <p>Returns:</p> Type Description <code>optuna.Study</code> <p>The completed study object containing best params and trials.</p> Source code in <code>cropengine/optimizer.py</code> <pre><code>def optimize(\n    self,\n    search_space: Callable[[optuna.Trial], Dict],\n    loss_func: Callable[[pd.DataFrame, pd.DataFrame], Union[float, List[float]]],\n    n_trials: int = 100,\n    n_workers: int = 4,\n    sampler: Optional[optuna.samplers.BaseSampler] = None,\n    directions: Optional[List[str]] = None,\n    output_folder: Optional[str] = None,\n) -&gt; optuna.Study:\n    \"\"\"\n    Runs the optimization loop.\n\n    Args:\n        search_space (callable): A function that takes an Optuna `trial` object\n                                 and returns a dictionary of parameter overrides.\n                                 Example structure:\n                                 {'crop_params': {'TSUM1': 1000}, 'soil_params': {...}}\n\n        loss_func (callable): A function that takes (df_simulated, df_observed).\n                              Returns a float (single-objective) or list of floats (multi-objective).\n\n        n_trials (int): Number of optimization trials to run.\n\n        n_workers (int): Number of parallel processes to spawn.\n\n        sampler (str | optuna.samplers.BaseSampler | None): \n            The optimization strategy. Supported strings:\n\n            **Standard:**\n            - \"TPE\": Tree-structured Parzen Estimator (Default, good general purpose).\n            - \"Random\": Pure random search.\n\n            **Advanced (May require extra packages):**\n            - \"GP\": Gaussian Process Sampler. Excellent for expensive simulations. (Requires `botorch`).\n            - \"CmaEs\": Covariance Matrix Adaptation. Good for continuous global optima. (Requires `cma`).\n            - \"BoTorch\": Bayesian Optimization. (Requires `botorch`).\n\n            **Multi-Objective:**\n            - \"NSGAII\": Standard for Pareto optimization.\n            - \"NSGAIII\": For many-objective problems (3+ targets).\n\n            **Grid/Deterministic:**\n            - \"BruteForce\": Tries ALL combinations.\n            - \"Grid\": Tries specified grid points.\n            - \"QMC\": Quasi-Monte Carlo.\n\n        directions (list[str]): Optimization directions.\n                                Default is [\"minimize\"].\n                                For multi-objective, use e.g., [\"minimize\", \"maximize\"].\n\n        output_folder (str, optional): Path to a folder where simulation results\n                                       for EACH trial will be saved (e.g., 'trial_0.csv').\n                                       If None, results are not saved to disk.\n\n    Returns:\n        optuna.Study: The completed study object containing best params and trials.\n    \"\"\"\n    # 1. SETUP OUTPUT FOLDER\n    if output_folder:\n        os.makedirs(output_folder, exist_ok=True)\n        print(f\"[OPT] Saving all trial outputs to: {output_folder}\")\n\n    # 2. RESOLVE SAMPLER\n    optuna_sampler = self._get_sampler(sampler)\n    if optuna_sampler:\n         print(f\"[OPT] Using Sampler: {optuna_sampler.__class__.__name__}\")\n\n    # 3. PRE-LOADING PHASE\n    print(\"[OPT] Loading simulation engines...\")\n    if not self.engines:\n        if self.is_batch:\n            self.engines = self.runner.get_batch_rerunners()\n        else:\n            self.engines = {0: self.runner.get_rerunner()}\n\n    print(f\"[OPT] Ready. Optimized execution for {len(self.engines)} locations.\")\n\n    # 4. DEFINE OBJECTIVE\n    def objective(trial):\n        # A. Get Parameters from Optuna\n        overrides = search_space(trial)\n\n        # B. Prepare Tasks for Parallel Workers\n        tasks = [\n            (loc_id, engine, overrides) for loc_id, engine in self.engines.items()\n        ]\n\n        results = []\n\n        # C. Execute in Parallel using JOBLIB\n        try:\n            # Parallel returns a list of results in order\n            results_raw = Parallel(n_jobs=n_workers, backend=\"loky\")(\n                delayed(_global_worker_task)(task) for task in tasks\n            )\n\n            # Filter out None values (failed runs)\n            results = [res for res in results_raw if res is not None]\n\n        except Exception as e:\n            logging.error(f\"[OPT] Parallel Execution Error: {e}\")\n            results = []\n\n        # D. Validation\n        if not results:\n            if directions and len(directions) &gt; 1:\n                return [float(\"inf\")] * len(directions)\n            return float(\"inf\")\n\n        # E. Aggregation &amp; Loss Calculation\n        try:\n            # 1. Merge all location results into one DataFrame\n            df_sim_all = pd.concat(results, ignore_index=True)\n\n            if output_folder:\n                file_path = os.path.join(output_folder, f\"trial_{trial.number}.csv\")\n                df_sim_all.to_csv(file_path, index=False)\n\n            # 2. Compute Loss (User Function)\n            loss = loss_func(df_sim_all, self.observed_data)\n            return loss\n\n        except Exception as e:\n            logging.error(f\"[OPT] Loss Calculation Error: {e}\")\n            if directions and len(directions) &gt; 1:\n                return [float(\"inf\")] * len(directions)\n            return float(\"inf\")\n\n    # 5. CREATE STUDY\n    if directions is None:\n        directions = [\"minimize\"]\n\n    study = optuna.create_study(directions=directions, sampler=optuna_sampler)\n\n    print(\n        f\"[OPT] Starting {len(directions)}-objective optimization with {n_trials} trials...\"\n    )\n    study.optimize(objective, n_trials=n_trials)\n\n    print(\"[OPT] Optimization Finished.\")\n\n    if len(directions) == 1:\n        print(\"Best params:\", study.best_params)\n    else:\n        print(\n            f\"Pareto front found with {len(study.best_trials)} optimal solutions.\"\n        )\n\n    return study\n</code></pre>"},{"location":"output/","title":"output module","text":"<p>Module to get output variables</p>"},{"location":"output/#cropengine.output.get_output_variables","title":"<code>get_output_variables(model)</code>","text":"<p>Retrieve output variable definitions and metadata for a given simulation model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>Name of the simulation model (e.g., a WOFOST variant).</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>A list of dictionaries, each describing an output variable. Each dictionary contains the following keys:</p> Source code in <code>cropengine/output.py</code> <pre><code>def get_output_variables(model: str) -&gt; list[dict]:\n    \"\"\"\n    Retrieve output variable definitions and metadata for a given simulation model.\n\n    Args:\n        model (str): Name of the simulation model (e.g., a WOFOST variant).\n\n    Returns:\n        list[dict]: A list of dictionaries, each describing an output variable.\n        Each dictionary contains the following keys:\n    \"\"\"\n\n    try:\n        with pkg_resources.files(configs).joinpath(\"output.yaml\").open(\"r\") as f:\n            full_config = yaml.safe_load(f)\n    except Exception as e:\n        raise RuntimeError(f\"Failed to load output.yaml: {e}\")\n\n    if model.lower().startswith(\"wofost\"):\n        config = full_config[\"wofost\"]\n\n    # Get the output variable\n    if model in config[\"model_mapping\"]:\n        profile_name = config[\"model_mapping\"][model]\n        variable_names = config[\"profiles\"][profile_name][\"variables\"]\n\n        variable_defs = []\n\n        # Build the Metadata List\n        for var in variable_names:\n            meta = {\n                \"variable\": var,\n                \"description\": config[\"output_vars\"][var][\"description\"],\n                \"unit\": config[\"output_vars\"][var][\"unit\"],\n                \"type\": config[\"output_vars\"][var][\"type\"],\n            }\n            variable_defs.append(meta)\n\n    return variable_defs\n</code></pre>"},{"location":"sensitivity/","title":"sensitivity module","text":"<p>Module for parameter sensitivity</p>"},{"location":"sensitivity/#cropengine.sensitivity.WOFOSTSensitivityAnalyzer","title":"<code> WOFOSTSensitivityAnalyzer        </code>","text":"<p>A robust Sensitivity Analysis (SA) tool for WOFOST simulations.</p> <p>This class integrates SALib with the WOFOST simulation runner to perform global and local sensitivity analyses. It supports parallel execution, spatial aggregation (to filter out weather noise), and multiple SA methods.</p> <p>Attributes:</p> Name Type Description <code>runner</code> <p>An instance of the simulation runner (Batch or Single) capable of     spawning engine instances.</p> <code>engines</code> <code>dict</code> <p>A dictionary mapping location IDs to WOFOST engine instances.</p> Source code in <code>cropengine/sensitivity.py</code> <pre><code>class WOFOSTSensitivityAnalyzer:\n    \"\"\"\n    A robust Sensitivity Analysis (SA) tool for WOFOST simulations.\n\n    This class integrates SALib with the WOFOST simulation runner to perform\n    global and local sensitivity analyses. It supports parallel execution,\n    spatial aggregation (to filter out weather noise), and multiple SA methods.\n\n    Attributes:\n        runner: An instance of the simulation runner (Batch or Single) capable of\n                spawning engine instances.\n        engines (dict): A dictionary mapping location IDs to WOFOST engine instances.\n    \"\"\"\n\n    def __init__(self, runner):\n        \"\"\"\n        Initializes the analyzer and pre-loads simulation engines.\n\n        Args:\n            runner: A WOFOST simulation runner object. Must implement\n                    `get_batch_rerunners()` or `get_rerunner()`.\n        \"\"\"\n        # DISABLE PCSE LOGGING\n        pcse_logger = logging.getLogger(\"pcse\")\n        pcse_logger.handlers = []\n        pcse_logger.setLevel(logging.CRITICAL)\n\n        self.runner = runner\n        self.engines = {}\n\n        print(\"[SA] Loading simulation engines...\")\n        if hasattr(runner, \"get_batch_rerunners\"):\n            self.engines = runner.get_batch_rerunners()\n        else:\n            self.engines = {0: runner.get_rerunner()}\n\n    def run_analysis(\n        self,\n        problem_dict,\n        method=\"sobol\",\n        n_samples=128,\n        n_workers=4,\n        target_variable=\"TWSO\",\n        mode=\"global\",\n        sample_locations=10,\n        num_levels=4,\n    ):\n        \"\"\"\n        Executes the Sensitivity Analysis workflow.\n\n        This method generates parameter samples using SALib, runs simulations across\n        selected locations in parallel, aggregates the results based on the specified\n        mode, and computes sensitivity indices.\n\n        Args:\n            problem_dict (dict): The standard SALib problem definition dictionary.\n                Example:\n                {\n                    'num_vars': 2,\n                    'names': ['TSUM1', 'SPAN'],\n                    'bounds': [[800, 1200], [28, 35]]\n                }\n\n            method (str, optional): The SA method to use. Options:\n                - 'sobol': Variance-based (Best for interactions, computationally expensive).\n                - 'morris': Elementary effects (Good for screening many parameters).\n                - 'fast': Fourier Amplitude Sensitivity Test.\n                Defaults to 'sobol'.\n\n            n_samples (int, optional): The base sample size (N).\n                **Note:** The actual number of simulations depends on the method:\n                - Sobol: N * (2D + 2)\n                - Morris: N * (D + 1)\n                - FAST: N * D\n                Where D is the number of parameters. Defaults to 128.\n\n            n_workers (int, optional): Number of parallel processes to use. Defaults to 4.\n\n            target_variable (str, optional): The output column from the simulation results\n                to analyze (e.g., 'TWSO' for Total Dry Weight Storage Organs).\n                Defaults to 'TWSO'.\n\n            mode (str, optional): The spatial aggregation strategy.\n                - 'global': Runs simulations on `sample_locations` for each parameter set,\n                  averages the results to remove weather noise, and returns a single\n                  sensitivity report for the entire region.\n                - 'local': Performs a full sensitivity analysis for EACH location\n                  individually. Returns a DataFrame containing indices for every location.\n                Defaults to 'global'.\n\n            sample_locations (int, optional): The number of random locations to select\n                from the batch runner to represent the region. If None, uses all available\n                locations (warning: this can be very slow). Defaults to 10.\n\n            num_levels (int, optional): Number of grid levels (specific to 'morris' method).\n                Defaults to 4.\n\n        Returns:\n            pd.DataFrame: A DataFrame containing the sensitivity indices.\n                - For 'sobol': Columns [Parameter, ST, S1, point_id]\n                - For 'morris': Columns [Parameter, mu_star, sigma, point_id]\n                - For 'fast': Columns [Parameter, ST, S1, point_id]\n\n        Raises:\n            ValueError: If an unknown method is specified.\n        \"\"\"\n\n        # 1. GENERATE SAMPLES (Method Specific)\n        if method == \"sobol\":\n            param_values = saltelli.sample(\n                problem_dict, n_samples, calc_second_order=False\n            )\n        elif method == \"morris\":\n            param_values = morris_sampler.sample(\n                problem_dict, n_samples, num_levels=num_levels\n            )\n        elif method == \"fast\":\n            param_values = fast_sampler.sample(problem_dict, n_samples)\n        else:\n            raise ValueError(\n                f\"Unknown method: {method}. Available methods are: {'sobol', 'morris', 'fast'}.\"\n            )\n\n        total_runs_per_loc = len(param_values)\n\n        # 2. SELECT LOCATIONS\n        all_locs = list(self.engines.keys())\n        if sample_locations is None or sample_locations &gt;= len(all_locs):\n            selected_locs = all_locs\n        else:\n            selected_locs = random.sample(all_locs, sample_locations)\n\n        print(\n            f\"[SA] Mode: {mode.upper()} | Params: {total_runs_per_loc} | Locations: {len(selected_locs)}\"\n        )\n        print(f\"[SA] Total Simulations: {total_runs_per_loc * len(selected_locs)}\")\n\n        # 2. PREPARE TASKS\n        tasks = []\n        for run_idx, row in enumerate(param_values):\n            overrides = self._row_to_overrides(row, problem_dict)\n            for loc_id in selected_locs:\n                engine = self.engines[loc_id]\n                # Payload: ( (run_idx, loc_id), engine, overrides )\n                tasks.append(((run_idx, loc_id), engine, overrides, target_variable))\n\n        # 4. EXECUTE SIMULATIONS\n        results_map = {idx: {} for idx in range(total_runs_per_loc)}\n        failure_count = 0\n\n        with ProcessPoolExecutor(max_workers=n_workers) as executor:\n            futures = [executor.submit(_sa_worker_wrapper, task) for task in tasks]\n            iterator = as_completed(futures)\n\n            for future in tqdm(iterator, total=len(futures), desc=\"[SA] Simulating\"):\n                try:\n                    r_idx, l_id, val, err_msg = future.result()\n\n                    results_map[r_idx][l_id] = val\n\n                    if err_msg:\n                        failure_count += 1\n                        logging.debug(f\"Failure: {err_msg}\")\n\n                except Exception as e:\n                    print(f\"Critical Worker Error: {e}\")\n                    failure_count += 1\n\n        if failure_count &gt; 0:\n            print(f\"[SA] Warning: {failure_count} simulations failed.\")\n\n        # 5. AGGREGATE &amp; ANALYZE\n        final_dfs = []\n\n        if mode == \"global\":\n            # Mean across locations for each parameter set\n            y_aggregated = np.zeros(total_runs_per_loc)\n            for idx in range(total_runs_per_loc):\n                vals = list(results_map[idx].values())\n                y_aggregated[idx] = np.mean(vals) if vals else 0.0\n\n            print(f\"[SA] Analyzing global (Mean) sensitivity...\")\n            df = self._analyze_results(problem_dict, param_values, y_aggregated, method)\n            df[\"point_id\"] = \"global\"\n            return df\n\n        elif mode == \"local\":\n            print(f\"[SA] Analyzing local sensitivity...\")\n\n            for loc_id in selected_locs:\n                # Extract vector for this specific location\n                y_local = np.zeros(total_runs_per_loc)\n                for idx in range(total_runs_per_loc):\n                    y_local[idx] = results_map[idx].get(loc_id, 0.0)\n\n                df_loc = self._analyze_results(\n                    problem_dict, param_values, y_local, method\n                )\n                df_loc[\"point_id\"] = loc_id\n                final_dfs.append(df_loc)\n\n            return pd.concat(final_dfs, ignore_index=True)\n\n    def _analyze_results(self, problem, X, Y, method):\n        \"\"\"\n        Internal helper to run the specific SALib analysis function.\n\n        Args:\n            problem (dict): SALib problem dictionary.\n            X (np.ndarray): The matrix of parameter samples used.\n            Y (np.ndarray): The vector of simulation results.\n            method (str): Analysis method ('sobol', 'morris', 'fast').\n\n        Returns:\n            pd.DataFrame: A standardized dataframe of sensitivity indices.\n        \"\"\"\n        if method == \"sobol\":\n            Si = sobol.analyze(problem, Y, calc_second_order=False)\n            return pd.DataFrame(\n                {\"Parameter\": problem[\"names\"], \"ST\": Si[\"ST\"], \"S1\": Si[\"S1\"]}\n            ).sort_values(\"ST\", ascending=False)\n\n        elif method == \"morris\":\n            Si = morris_analyzer.analyze(problem, X, Y, conf_level=0.95)\n            return pd.DataFrame(\n                {\n                    \"Parameter\": problem[\"names\"],\n                    \"mu_star\": Si[\"mu_star\"],\n                    \"sigma\": Si[\"sigma\"],\n                }\n            ).sort_values(\"mu_star\", ascending=False)\n\n        elif method == \"fast\":\n            Si = fast.analyze(problem, Y)\n            return pd.DataFrame(\n                {\"Parameter\": problem[\"names\"], \"ST\": Si[\"ST\"], \"S1\": Si[\"S1\"]}\n            ).sort_values(\"ST\", ascending=False)\n\n    def _row_to_overrides(self, row, problem):\n        \"\"\"\n        Maps a flat row of parameter values to the WOFOST override dictionary structure.\n        \"\"\"\n        crop_params = {}\n        for i, name in enumerate(problem[\"names\"]):\n            crop_params[name] = row[i]\n        return {\"crop_params\": crop_params, \"soil_params\": {}, \"site_params\": {}}\n</code></pre>"},{"location":"sensitivity/#cropengine.sensitivity.WOFOSTSensitivityAnalyzer.__init__","title":"<code>__init__(self, runner)</code>  <code>special</code>","text":"<p>Initializes the analyzer and pre-loads simulation engines.</p> <p>Parameters:</p> Name Type Description Default <code>runner</code> <p>A WOFOST simulation runner object. Must implement     <code>get_batch_rerunners()</code> or <code>get_rerunner()</code>.</p> required Source code in <code>cropengine/sensitivity.py</code> <pre><code>def __init__(self, runner):\n    \"\"\"\n    Initializes the analyzer and pre-loads simulation engines.\n\n    Args:\n        runner: A WOFOST simulation runner object. Must implement\n                `get_batch_rerunners()` or `get_rerunner()`.\n    \"\"\"\n    # DISABLE PCSE LOGGING\n    pcse_logger = logging.getLogger(\"pcse\")\n    pcse_logger.handlers = []\n    pcse_logger.setLevel(logging.CRITICAL)\n\n    self.runner = runner\n    self.engines = {}\n\n    print(\"[SA] Loading simulation engines...\")\n    if hasattr(runner, \"get_batch_rerunners\"):\n        self.engines = runner.get_batch_rerunners()\n    else:\n        self.engines = {0: runner.get_rerunner()}\n</code></pre>"},{"location":"sensitivity/#cropengine.sensitivity.WOFOSTSensitivityAnalyzer.run_analysis","title":"<code>run_analysis(self, problem_dict, method='sobol', n_samples=128, n_workers=4, target_variable='TWSO', mode='global', sample_locations=10, num_levels=4)</code>","text":"<p>Executes the Sensitivity Analysis workflow.</p> <p>This method generates parameter samples using SALib, runs simulations across selected locations in parallel, aggregates the results based on the specified mode, and computes sensitivity indices.</p> <p>Parameters:</p> Name Type Description Default <code>problem_dict</code> <code>dict</code> <p>The standard SALib problem definition dictionary. Example: {     'num_vars': 2,     'names': ['TSUM1', 'SPAN'],     'bounds': [[800, 1200], [28, 35]] }</p> required <code>method</code> <code>str</code> <p>The SA method to use. Options: - 'sobol': Variance-based (Best for interactions, computationally expensive). - 'morris': Elementary effects (Good for screening many parameters). - 'fast': Fourier Amplitude Sensitivity Test. Defaults to 'sobol'.</p> <code>'sobol'</code> <code>n_samples</code> <code>int</code> <p>The base sample size (N). Note: The actual number of simulations depends on the method: - Sobol: N * (2D + 2) - Morris: N * (D + 1) - FAST: N * D Where D is the number of parameters. Defaults to 128.</p> <code>128</code> <code>n_workers</code> <code>int</code> <p>Number of parallel processes to use. Defaults to 4.</p> <code>4</code> <code>target_variable</code> <code>str</code> <p>The output column from the simulation results to analyze (e.g., 'TWSO' for Total Dry Weight Storage Organs). Defaults to 'TWSO'.</p> <code>'TWSO'</code> <code>mode</code> <code>str</code> <p>The spatial aggregation strategy. - 'global': Runs simulations on <code>sample_locations</code> for each parameter set,   averages the results to remove weather noise, and returns a single   sensitivity report for the entire region. - 'local': Performs a full sensitivity analysis for EACH location   individually. Returns a DataFrame containing indices for every location. Defaults to 'global'.</p> <code>'global'</code> <code>sample_locations</code> <code>int</code> <p>The number of random locations to select from the batch runner to represent the region. If None, uses all available locations (warning: this can be very slow). Defaults to 10.</p> <code>10</code> <code>num_levels</code> <code>int</code> <p>Number of grid levels (specific to 'morris' method). Defaults to 4.</p> <code>4</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>A DataFrame containing the sensitivity indices.     - For 'sobol': Columns [Parameter, ST, S1, point_id]     - For 'morris': Columns [Parameter, mu_star, sigma, point_id]     - For 'fast': Columns [Parameter, ST, S1, point_id]</p> <p>Exceptions:</p> Type Description <code>ValueError</code> <p>If an unknown method is specified.</p> Source code in <code>cropengine/sensitivity.py</code> <pre><code>def run_analysis(\n    self,\n    problem_dict,\n    method=\"sobol\",\n    n_samples=128,\n    n_workers=4,\n    target_variable=\"TWSO\",\n    mode=\"global\",\n    sample_locations=10,\n    num_levels=4,\n):\n    \"\"\"\n    Executes the Sensitivity Analysis workflow.\n\n    This method generates parameter samples using SALib, runs simulations across\n    selected locations in parallel, aggregates the results based on the specified\n    mode, and computes sensitivity indices.\n\n    Args:\n        problem_dict (dict): The standard SALib problem definition dictionary.\n            Example:\n            {\n                'num_vars': 2,\n                'names': ['TSUM1', 'SPAN'],\n                'bounds': [[800, 1200], [28, 35]]\n            }\n\n        method (str, optional): The SA method to use. Options:\n            - 'sobol': Variance-based (Best for interactions, computationally expensive).\n            - 'morris': Elementary effects (Good for screening many parameters).\n            - 'fast': Fourier Amplitude Sensitivity Test.\n            Defaults to 'sobol'.\n\n        n_samples (int, optional): The base sample size (N).\n            **Note:** The actual number of simulations depends on the method:\n            - Sobol: N * (2D + 2)\n            - Morris: N * (D + 1)\n            - FAST: N * D\n            Where D is the number of parameters. Defaults to 128.\n\n        n_workers (int, optional): Number of parallel processes to use. Defaults to 4.\n\n        target_variable (str, optional): The output column from the simulation results\n            to analyze (e.g., 'TWSO' for Total Dry Weight Storage Organs).\n            Defaults to 'TWSO'.\n\n        mode (str, optional): The spatial aggregation strategy.\n            - 'global': Runs simulations on `sample_locations` for each parameter set,\n              averages the results to remove weather noise, and returns a single\n              sensitivity report for the entire region.\n            - 'local': Performs a full sensitivity analysis for EACH location\n              individually. Returns a DataFrame containing indices for every location.\n            Defaults to 'global'.\n\n        sample_locations (int, optional): The number of random locations to select\n            from the batch runner to represent the region. If None, uses all available\n            locations (warning: this can be very slow). Defaults to 10.\n\n        num_levels (int, optional): Number of grid levels (specific to 'morris' method).\n            Defaults to 4.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the sensitivity indices.\n            - For 'sobol': Columns [Parameter, ST, S1, point_id]\n            - For 'morris': Columns [Parameter, mu_star, sigma, point_id]\n            - For 'fast': Columns [Parameter, ST, S1, point_id]\n\n    Raises:\n        ValueError: If an unknown method is specified.\n    \"\"\"\n\n    # 1. GENERATE SAMPLES (Method Specific)\n    if method == \"sobol\":\n        param_values = saltelli.sample(\n            problem_dict, n_samples, calc_second_order=False\n        )\n    elif method == \"morris\":\n        param_values = morris_sampler.sample(\n            problem_dict, n_samples, num_levels=num_levels\n        )\n    elif method == \"fast\":\n        param_values = fast_sampler.sample(problem_dict, n_samples)\n    else:\n        raise ValueError(\n            f\"Unknown method: {method}. Available methods are: {'sobol', 'morris', 'fast'}.\"\n        )\n\n    total_runs_per_loc = len(param_values)\n\n    # 2. SELECT LOCATIONS\n    all_locs = list(self.engines.keys())\n    if sample_locations is None or sample_locations &gt;= len(all_locs):\n        selected_locs = all_locs\n    else:\n        selected_locs = random.sample(all_locs, sample_locations)\n\n    print(\n        f\"[SA] Mode: {mode.upper()} | Params: {total_runs_per_loc} | Locations: {len(selected_locs)}\"\n    )\n    print(f\"[SA] Total Simulations: {total_runs_per_loc * len(selected_locs)}\")\n\n    # 2. PREPARE TASKS\n    tasks = []\n    for run_idx, row in enumerate(param_values):\n        overrides = self._row_to_overrides(row, problem_dict)\n        for loc_id in selected_locs:\n            engine = self.engines[loc_id]\n            # Payload: ( (run_idx, loc_id), engine, overrides )\n            tasks.append(((run_idx, loc_id), engine, overrides, target_variable))\n\n    # 4. EXECUTE SIMULATIONS\n    results_map = {idx: {} for idx in range(total_runs_per_loc)}\n    failure_count = 0\n\n    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n        futures = [executor.submit(_sa_worker_wrapper, task) for task in tasks]\n        iterator = as_completed(futures)\n\n        for future in tqdm(iterator, total=len(futures), desc=\"[SA] Simulating\"):\n            try:\n                r_idx, l_id, val, err_msg = future.result()\n\n                results_map[r_idx][l_id] = val\n\n                if err_msg:\n                    failure_count += 1\n                    logging.debug(f\"Failure: {err_msg}\")\n\n            except Exception as e:\n                print(f\"Critical Worker Error: {e}\")\n                failure_count += 1\n\n    if failure_count &gt; 0:\n        print(f\"[SA] Warning: {failure_count} simulations failed.\")\n\n    # 5. AGGREGATE &amp; ANALYZE\n    final_dfs = []\n\n    if mode == \"global\":\n        # Mean across locations for each parameter set\n        y_aggregated = np.zeros(total_runs_per_loc)\n        for idx in range(total_runs_per_loc):\n            vals = list(results_map[idx].values())\n            y_aggregated[idx] = np.mean(vals) if vals else 0.0\n\n        print(f\"[SA] Analyzing global (Mean) sensitivity...\")\n        df = self._analyze_results(problem_dict, param_values, y_aggregated, method)\n        df[\"point_id\"] = \"global\"\n        return df\n\n    elif mode == \"local\":\n        print(f\"[SA] Analyzing local sensitivity...\")\n\n        for loc_id in selected_locs:\n            # Extract vector for this specific location\n            y_local = np.zeros(total_runs_per_loc)\n            for idx in range(total_runs_per_loc):\n                y_local[idx] = results_map[idx].get(loc_id, 0.0)\n\n            df_loc = self._analyze_results(\n                problem_dict, param_values, y_local, method\n            )\n            df_loc[\"point_id\"] = loc_id\n            final_dfs.append(df_loc)\n\n        return pd.concat(final_dfs, ignore_index=True)\n</code></pre>"},{"location":"site/","title":"site module","text":"<p>Module to prepare site data</p>"},{"location":"site/#cropengine.site.SiteParameterError","title":"<code> SiteParameterError            (Exception)         </code>","text":"<p>Custom exception for site parameter validation errors.</p> Source code in <code>cropengine/site.py</code> <pre><code>class SiteParameterError(Exception):\n    \"\"\"Custom exception for site parameter validation errors.\"\"\"\n\n    pass\n</code></pre>"},{"location":"site/#cropengine.site.WOFOSTSiteParametersProvider","title":"<code> WOFOSTSiteParametersProvider        </code>","text":"<p>A unified data provider for WOFOST site-specific parameters.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>str</code> <p>The name of the WOFOST model version to use.</p> required <code>**kwargs</code> <p>Site parameters provided as keyword arguments.</p> <code>{}</code> Source code in <code>cropengine/site.py</code> <pre><code>class WOFOSTSiteParametersProvider:\n    \"\"\"\n    A unified data provider for WOFOST site-specific parameters.\n\n    Args:\n        model (str): The name of the WOFOST model version to use.\n        **kwargs: Site parameters provided as keyword arguments.\n    \"\"\"\n\n    EMERGENCY_DEFAULTS = {\n        \"WAV\": 10.0,\n        \"CO2\": 360.0,\n        \"NAVAILI\": 0.0,\n        \"NH4I\": [0.05],\n        \"NO3I\": [0.05],\n    }\n\n    def __init__(self, model, **kwargs):\n        self.model = model\n        self.raw_kwargs = kwargs\n        self.param_metadata = []\n        self.required_params = set()\n        self.valid_param_names = set()\n\n        # 1. Load configuration\n        try:\n            with pkg_resources.files(configs).joinpath(\"site_params.yaml\").open(\n                \"r\"\n            ) as f:\n                self.full_config = yaml.safe_load(f)\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load site_params.yaml: {e}\")\n\n        config = self.full_config[\"wofost\"]\n\n        # 2. Validate Model and Prepare Metadata\n        if self.model in config[\"model_mapping\"]:\n\n            profile_name = config[\"model_mapping\"][self.model]\n            profile_def = config[\"profiles\"][profile_name]\n\n            self.valid_param_names = set(profile_def[\"parameters\"])\n            self.required_params = set(profile_def.get(\"required\", []))\n\n            all_param_defs = config[\"site_params\"]\n\n            # Build the Metadata List\n            for param in self.valid_param_names:\n                if param in all_param_defs:\n                    meta = {\n                        \"parameter\": param,\n                        \"required\": (param in self.required_params),\n                    }\n                    meta.update(all_param_defs[param].copy())\n                    self.param_metadata.append(meta)\n\n    def get_params(self):\n        \"\"\"\n        Validates inputs against the prepared metadata, applies defaults,\n        and returns the final parameter dictionary.\n        \"\"\"\n        # 1. Re-validate Model Profile\n        if not self.param_metadata:\n            valid_models = list(self.full_config[\"wofost\"][\"model_mapping\"].keys())\n            raise SiteParameterError(\n                f\"Unknown or unconfigured model '{self.model}'. Available models: {valid_models}\"\n            )\n\n        validated_params = {}\n\n        # 2. Process Parameters (Iterating over the LIST now)\n        for meta in self.param_metadata:\n            par_name = meta[\"parameter\"]\n            is_required = meta[\"required\"]\n\n            # Determine value: use provided kwarg or fall back to default\n            if par_name in self.raw_kwargs:\n                value = self.raw_kwargs[par_name]\n            else:\n                value = meta[\"default\"]\n\n                if value is None:\n                    if par_name in self.EMERGENCY_DEFAULTS:\n                        value = self.EMERGENCY_DEFAULTS[par_name]\n                        warnings.warn(\n                            f\"[SiteParams] Parameter '{par_name}' was missing and has no YAML default. \"\n                            f\"Using fallback value: {value}\"\n                        )\n\n                if is_required:\n                    warnings.warn(\n                        f\"[SiteParams] Required parameter '{par_name}' was not provided. \"\n                        f\"Using default value: {value}\"\n                    )\n\n            # Convert types and check valid ranges\n            if value is not None:\n                value = self._convert_and_validate(par_name, value, meta)\n\n            meta[\"value\"] = value\n            validated_params[par_name] = value\n\n        # 3. Check for Unknown Parameters provided by user\n        unknown_keys = [\n            k for k in self.raw_kwargs.keys() if k not in self.valid_param_names\n        ]\n        if unknown_keys:\n            raise SiteParameterError(\n                f\"Unknown parameters provided for profile '{self.model}': {unknown_keys}\"\n            )\n\n        return validated_params\n\n    def _convert_and_validate(self, name, value, definition):\n        \"\"\"\n        Internal helper to cast types and validate ranges.\n        \"\"\"\n        target_type_str = definition[\"type\"]\n\n        # Type Casting\n        try:\n            if target_type_str == \"int\":\n                value = int(value)\n            elif target_type_str == \"float\":\n                value = float(value)\n            elif target_type_str == \"list\":\n                if not isinstance(value, list):\n                    if isinstance(value, str) and \",\" in value:\n                        value = [float(x.strip()) for x in value.split(\",\")]\n                    else:\n                        raise ValueError\n        except (ValueError, TypeError):\n            raise SiteParameterError(\n                f\"Parameter '{name}' must be of type {target_type_str}, got {type(value)}\"\n            )\n\n        # Range Checking\n        valid_range = definition[\"range\"]\n\n        if target_type_str == \"list\":\n            min_val, max_val = valid_range\n            if not all(min_val &lt;= x &lt;= max_val for x in value):\n                raise SiteParameterError(\n                    f\"Elements in list '{name}' must be between {min_val} and {max_val}\"\n                )\n\n        elif target_type_str == \"int\" and valid_range == [0, 1]:\n            if value not in [0, 1]:\n                raise SiteParameterError(f\"Parameter '{name}' must be 0 or 1.\")\n\n        else:\n            min_val, max_val = valid_range\n            if not (min_val &lt;= value &lt;= max_val):\n                raise SiteParameterError(\n                    f\"Value {value} for parameter '{name}' out of range [{min_val}, {max_val}]\"\n                )\n\n        return value\n</code></pre>"},{"location":"site/#cropengine.site.WOFOSTSiteParametersProvider.get_params","title":"<code>get_params(self)</code>","text":"<p>Validates inputs against the prepared metadata, applies defaults, and returns the final parameter dictionary.</p> Source code in <code>cropengine/site.py</code> <pre><code>def get_params(self):\n    \"\"\"\n    Validates inputs against the prepared metadata, applies defaults,\n    and returns the final parameter dictionary.\n    \"\"\"\n    # 1. Re-validate Model Profile\n    if not self.param_metadata:\n        valid_models = list(self.full_config[\"wofost\"][\"model_mapping\"].keys())\n        raise SiteParameterError(\n            f\"Unknown or unconfigured model '{self.model}'. Available models: {valid_models}\"\n        )\n\n    validated_params = {}\n\n    # 2. Process Parameters (Iterating over the LIST now)\n    for meta in self.param_metadata:\n        par_name = meta[\"parameter\"]\n        is_required = meta[\"required\"]\n\n        # Determine value: use provided kwarg or fall back to default\n        if par_name in self.raw_kwargs:\n            value = self.raw_kwargs[par_name]\n        else:\n            value = meta[\"default\"]\n\n            if value is None:\n                if par_name in self.EMERGENCY_DEFAULTS:\n                    value = self.EMERGENCY_DEFAULTS[par_name]\n                    warnings.warn(\n                        f\"[SiteParams] Parameter '{par_name}' was missing and has no YAML default. \"\n                        f\"Using fallback value: {value}\"\n                    )\n\n            if is_required:\n                warnings.warn(\n                    f\"[SiteParams] Required parameter '{par_name}' was not provided. \"\n                    f\"Using default value: {value}\"\n                )\n\n        # Convert types and check valid ranges\n        if value is not None:\n            value = self._convert_and_validate(par_name, value, meta)\n\n        meta[\"value\"] = value\n        validated_params[par_name] = value\n\n    # 3. Check for Unknown Parameters provided by user\n    unknown_keys = [\n        k for k in self.raw_kwargs.keys() if k not in self.valid_param_names\n    ]\n    if unknown_keys:\n        raise SiteParameterError(\n            f\"Unknown parameters provided for profile '{self.model}': {unknown_keys}\"\n        )\n\n    return validated_params\n</code></pre>"},{"location":"soil/","title":"soil module","text":"<p>Module to prepare soil data</p>"},{"location":"soil/#cropengine.soil.GEEIsricSoilDataProvider","title":"<code> GEEIsricSoilDataProvider        </code>","text":"<p>Initialize the ISRIC Soil Data Provider for GEE.</p> <p>Parameters:</p> Name Type Description Default <code>latitude</code> <code>float</code> <p>The latitude of the location.</p> required <code>longitude</code> <code>float</code> <p>The longitude of the location.</p> required <code>properties</code> <code>list</code> <p>List of soil properties to fetch (e.g., ['clay', 'sand']).                          Defaults to common physical/chemical properties.</p> <code>None</code> <code>depths</code> <code>list</code> <p>List of depth ranges (e.g., ['0-5cm', '5-15cm']).                      Defaults to all standard SoilGrids depths.</p> <code>None</code> <code>filepath</code> <code>str</code> <p>Path to save the resulting CSV file. Defaults to None.</p> <code>None</code> <code>ee_project</code> <code>str</code> <p>GEE project ID for initialization (if not already initialized).</p> <code>None</code> Source code in <code>cropengine/soil.py</code> <pre><code>class GEEIsricSoilDataProvider:\n    \"\"\"\n    Initialize the ISRIC Soil Data Provider for GEE.\n\n    Args:\n        latitude (float): The latitude of the location.\n        longitude (float): The longitude of the location.\n        properties (list, optional): List of soil properties to fetch (e.g., ['clay', 'sand']).\n                                     Defaults to common physical/chemical properties.\n        depths (list, optional): List of depth ranges (e.g., ['0-5cm', '5-15cm']).\n                                 Defaults to all standard SoilGrids depths.\n        filepath (str, optional): Path to save the resulting CSV file. Defaults to None.\n        ee_project (str, optional): GEE project ID for initialization (if not already initialized).\n    \"\"\"\n\n    # Configuration for SoilGrids assets in GEE\n    # 'factor': The value to divide by to get the standard unit (e.g. pH is stored as int * 10)\n    ASSET_CONFIG = {\n        \"bdod\": {\n            \"asset\": \"projects/soilgrids-isric/bdod_mean\",\n            \"mapped_unit\": \"cg/cm\u00b3\",\n            \"factor\": 100,\n            \"transformed_unit\": \"kg/dm\u00b3\",\n        },\n        \"cec\": {\n            \"asset\": \"projects/soilgrids-isric/cec_mean\",\n            \"mapped_unit\": \"mmol(c)/kg\",\n            \"factor\": 10,\n            \"transformed_unit\": \"cmol(c)/kg\",\n        },\n        \"cfvo\": {\n            \"asset\": \"projects/soilgrids-isric/cfvo_mean\",\n            \"mapped_unit\": \"cm\u00b3/dm\u00b3\",\n            \"factor\": 10,\n            \"transformed_unit\": \"cm\u00b3/100cm\u00b3\",\n        },\n        \"clay\": {\n            \"asset\": \"projects/soilgrids-isric/clay_mean\",\n            \"mapped_unit\": \"g/kg\",\n            \"factor\": 10,\n            \"transformed_unit\": \"%\",\n        },\n        \"sand\": {\n            \"asset\": \"projects/soilgrids-isric/sand_mean\",\n            \"mapped_unit\": \"g/kg\",\n            \"factor\": 10,\n            \"transformed_unit\": \"%\",\n        },\n        \"silt\": {\n            \"asset\": \"projects/soilgrids-isric/silt_mean\",\n            \"mapped_unit\": \"g/kg\",\n            \"factor\": 10,\n            \"transformed_unit\": \"%\",\n        },\n        \"nitrogen\": {\n            \"asset\": \"projects/soilgrids-isric/nitrogen_mean\",\n            \"mapped_unit\": \"cg/kg\",\n            \"factor\": 100,\n            \"transformed_unit\": \"g/kg\",\n        },\n        \"phh2o\": {\n            \"asset\": \"projects/soilgrids-isric/phh2o_mean\",\n            \"mapped_unit\": \"pH*10\",\n            \"factor\": 10,\n            \"transformed_unit\": \"pH\",\n        },\n        \"soc\": {\n            \"asset\": \"projects/soilgrids-isric/soc_mean\",\n            \"mapped_unit\": \"dg/kg\",\n            \"factor\": 10,\n            \"transformed_unit\": \"g/kg\",\n        },\n        \"ocd\": {\n            \"asset\": \"projects/soilgrids-isric/ocd_mean\",\n            \"mapped_unit\": \"hg/m\u00b3\",\n            \"factor\": 10,\n            \"transformed_unit\": \"kg/m\u00b3\",\n        },\n    }\n\n    ALL_DEPTHS = [\"0-5cm\", \"5-15cm\", \"15-30cm\", \"30-60cm\", \"60-100cm\", \"100-200cm\"]\n\n    def __init__(\n        self,\n        latitude,\n        longitude,\n        properties=None,\n        depths=None,\n        filepath=None,\n        ee_project=None,\n    ):\n        self._check_gee_initialized(ee_project)\n\n        self.latitude = latitude\n        self.longitude = longitude\n        self.filepath = filepath\n        self._cached_df = None\n\n        # If properties is None, use all keys from configuration\n        if properties is None:\n            self.properties = list(self.ASSET_CONFIG.keys())\n        else:\n            # Validate user input\n            self.properties = [p for p in properties if p in self.ASSET_CONFIG]\n            if not self.properties:\n                raise ValueError(\n                    f\"No valid properties found in input. Available: {list(self.ASSET_CONFIG.keys())}\"\n                )\n\n        # If depths is None, use the constant ALL_DEPTHS list\n        if depths is None:\n            self.depths = self.ALL_DEPTHS\n        else:\n            self.depths = [d for d in depths if d in self.ALL_DEPTHS]\n            if not self.depths:\n                raise ValueError(f\"No valid depths found. Available: {self.ALL_DEPTHS}\")\n\n    def _check_gee_initialized(self, project=None):\n        \"\"\"\n        Checks if GEE is initialized. If not, attempts to initialize.\n        \"\"\"\n        try:\n            ee.Image(0).getInfo()\n        except Exception:\n            print(\"GEE not initialized. Attempting initialization...\")\n            try:\n                # Try initializing with specific project if provided, else default\n                if project:\n                    ee.Initialize(project=project)\n                else:\n                    ee.Initialize()\n                print(\"GEE Initialized successfully.\")\n            except Exception as e:\n                raise RuntimeError(\n                    f\"Failed to initialize Earth Engine: {e}.\\n\"\n                    \"Please run 'earthengine authenticate' in your terminal first.\"\n                )\n\n    def _construct_image(self):\n        \"\"\"\n        Constructs a single combined Image from requested properties.\n        Renames bands to a standard format: {property}_{depth}\n        \"\"\"\n        images_to_merge = []\n\n        for prop in self.properties:\n            config = self.ASSET_CONFIG[prop]\n            img = ee.Image(config[\"asset\"])\n\n            bands_to_select = [f\"{prop}_{depth}_mean\" for depth in self.depths]\n\n            try:\n                # Select and rename\n                img_subset = img.select(bands_to_select)\n                images_to_merge.append(img_subset)\n            except Exception:\n                # Handle cases where a specific depth might be missing in a specific asset\n                continue\n\n        if not images_to_merge:\n            raise ValueError(\n                \"Could not construct image from selected properties/depths.\"\n            )\n\n        # Combine all property images into one multi-band image\n        return ee.Image.cat(images_to_merge)\n\n    def _extract_data(self):\n        \"\"\"Internal method to run reduceRegion on GEE.\"\"\"\n        print(f\"Fetching GEE Soil data for {self.latitude}, {self.longitude}...\")\n\n        point = ee.Geometry.Point([self.longitude, self.latitude])\n        image = self._construct_image()\n\n        # Reduce region to get values\n        data = image.reduceRegion(\n            reducer=ee.Reducer.first(), geometry=point, scale=250\n        ).getInfo()\n\n        return data\n\n    def get_data(self):\n        \"\"\"\n        Fetches, parses, and returns soil data.\n        \"\"\"\n        # 1. Check Cache\n        if self._cached_df is not None:\n            return self._cached_df\n\n        # 2. Fetch Data\n        raw_data = self._extract_data()\n\n        if not raw_data:\n            return pd.DataFrame()\n\n        # 3. Parse Data into Rows\n        rows = []\n\n        for key, value in raw_data.items():\n            if value is None:\n                continue\n\n            try:\n                prop_name, depth_range, metric = key.split(\"_\")\n            except ValueError:\n                continue\n\n            config = self.ASSET_CONFIG.get(prop_name, {})\n            factor = config.get(\"factor\", 1)\n            mapped_unit = config.get(\"mapped_unit\", \"\")\n            transformed_unit = config.get(\"transformed_unit\", \"\")\n\n            # Calculate transformed value\n            transformed_val = value / factor if factor != 0 else value\n\n            rows.append(\n                {\n                    \"latitude\": self.latitude,\n                    \"longitude\": self.longitude,\n                    \"property\": prop_name,\n                    \"depth\": depth_range,\n                    \"metric\": metric,\n                    \"value\": value,\n                    \"unit\": mapped_unit,\n                    \"transformed_value\": transformed_val,\n                    \"transformed_unit\": transformed_unit,\n                }\n            )\n\n        df = pd.DataFrame(rows)\n\n        # 4. Update Cache\n        self._cached_df = df\n\n        # 5. Save to File\n        if self.filepath and not df.empty:\n            try:\n                df.to_csv(self.filepath, index=False)\n                print(f\"File saved successfully to {self.filepath}\")\n            except Exception as e:\n                print(f\"Failed to save file: {e}\")\n\n        return df\n</code></pre>"},{"location":"soil/#cropengine.soil.GEEIsricSoilDataProvider.get_data","title":"<code>get_data(self)</code>","text":"<p>Fetches, parses, and returns soil data.</p> Source code in <code>cropengine/soil.py</code> <pre><code>def get_data(self):\n    \"\"\"\n    Fetches, parses, and returns soil data.\n    \"\"\"\n    # 1. Check Cache\n    if self._cached_df is not None:\n        return self._cached_df\n\n    # 2. Fetch Data\n    raw_data = self._extract_data()\n\n    if not raw_data:\n        return pd.DataFrame()\n\n    # 3. Parse Data into Rows\n    rows = []\n\n    for key, value in raw_data.items():\n        if value is None:\n            continue\n\n        try:\n            prop_name, depth_range, metric = key.split(\"_\")\n        except ValueError:\n            continue\n\n        config = self.ASSET_CONFIG.get(prop_name, {})\n        factor = config.get(\"factor\", 1)\n        mapped_unit = config.get(\"mapped_unit\", \"\")\n        transformed_unit = config.get(\"transformed_unit\", \"\")\n\n        # Calculate transformed value\n        transformed_val = value / factor if factor != 0 else value\n\n        rows.append(\n            {\n                \"latitude\": self.latitude,\n                \"longitude\": self.longitude,\n                \"property\": prop_name,\n                \"depth\": depth_range,\n                \"metric\": metric,\n                \"value\": value,\n                \"unit\": mapped_unit,\n                \"transformed_value\": transformed_val,\n                \"transformed_unit\": transformed_unit,\n            }\n        )\n\n    df = pd.DataFrame(rows)\n\n    # 4. Update Cache\n    self._cached_df = df\n\n    # 5. Save to File\n    if self.filepath and not df.empty:\n        try:\n            df.to_csv(self.filepath, index=False)\n            print(f\"File saved successfully to {self.filepath}\")\n        except Exception as e:\n            print(f\"Failed to save file: {e}\")\n\n    return df\n</code></pre>"},{"location":"soil/#cropengine.soil.IsricSoilDataProvider","title":"<code> IsricSoilDataProvider        </code>","text":"<p>Initialize the ISRIC Soil Data Provider.</p> <p>Parameters:</p> Name Type Description Default <code>latitude</code> <code>float</code> <p>The latitude of the location.</p> required <code>longitude</code> <code>float</code> <p>The longitude of the location.</p> required <code>properties</code> <code>list</code> <p>List of soil properties to fetch (e.g., ['clay', 'sand']).                              Defaults to all available in config.</p> <code>None</code> <code>depths</code> <code>list</code> <p>List of depth ranges (e.g., ['0-5cm']).                          Defaults to all available in config.</p> <code>None</code> <code>values</code> <code>list</code> <p>List of statistical values (e.g., ['mean', 'Q0.5']).                          Defaults to all available in config.</p> <code>None</code> <code>filepath</code> <code>str</code> <p>Path to save the resulting CSV file. Defaults to None.</p> <code>None</code> Source code in <code>cropengine/soil.py</code> <pre><code>class IsricSoilDataProvider:\n    \"\"\"\n    Initialize the ISRIC Soil Data Provider.\n\n    Args:\n        latitude (float): The latitude of the location.\n        longitude (float): The longitude of the location.\n        properties (list, optional): List of soil properties to fetch (e.g., ['clay', 'sand']).\n                                         Defaults to all available in config.\n        depths (list, optional): List of depth ranges (e.g., ['0-5cm']).\n                                     Defaults to all available in config.\n        values (list, optional): List of statistical values (e.g., ['mean', 'Q0.5']).\n                                     Defaults to all available in config.\n        filepath (str, optional): Path to save the resulting CSV file. Defaults to None.\n    \"\"\"\n\n    def __init__(\n        self,\n        latitude,\n        longitude,\n        properties=None,\n        depths=None,\n        values=None,\n        filepath=None,\n    ):\n        self.latitude = latitude\n        self.longitude = longitude\n        self.filepath = filepath\n\n        # Internal cache storage\n        self._cached_df = None\n\n        # Load configuration using pkg_resources\n        with pkg_resources.files(configs).joinpath(\"soil.yaml\").open(\"r\") as f:\n            full_config = yaml.safe_load(f)\n\n        self.config = full_config[\"isric_rest_api\"]\n        self.base_url = self.config[\"api\"][\"base_url\"]\n\n        # Validate inputs\n        self.properties = self._validate_input(\n            properties, self.config[\"options\"][\"properties\"], \"Property\"\n        )\n        self.depths = self._validate_input(\n            depths, self.config[\"options\"][\"depths\"], \"Depth\"\n        )\n        self.values = self._validate_input(\n            values, self.config[\"options\"][\"values\"], \"Value\"\n        )\n\n        self.query = {\n            \"lat\": latitude,\n            \"lon\": longitude,\n            \"property\": self.properties,\n            \"depth\": self.depths,\n            \"value\": self.values,\n        }\n\n    def _validate_input(self, user_input, valid_options, category_name):\n        \"\"\"Validates user input against the loaded config options.\"\"\"\n        if user_input is None:\n            return valid_options\n\n        if isinstance(user_input, str):\n            user_input = [user_input]\n\n        # Check for invalid items\n        invalid_items = [item for item in user_input if item not in valid_options]\n\n        if invalid_items:\n            error_msg = (\n                f\"\\nError: Invalid {category_name}(s) provided: {invalid_items}\\n\"\n                f\"Available options in {category_name} are: {valid_options}\"\n            )\n            raise ValueError(error_msg)\n\n        return user_input\n\n    def _extract_data(self):\n        \"\"\"Internal method to hit the API.\"\"\"\n        print(f\"Fetching soil data for {self.latitude}, {self.longitude}...\")\n        try:\n            response = requests.get(self.base_url, params=self.query)\n            response.raise_for_status()\n            print(response)\n            return response.json()\n        except Exception as e:\n            print(f\"Error fetching data: {e}\")\n            return None\n\n    def get_data(self):\n        \"\"\"\n        Fetches, parses, and returns soil data.\n        Uses cached memory if data has already been fetched for this instance.\n        \"\"\"\n        # 1. Check Cache (Optimization)\n        if self._cached_df is not None:\n            print(\"Returning cached data (no API call made).\")\n            return self._cached_df\n\n        # 2. Fetch Data\n        raw_data = self._extract_data()\n\n        if not raw_data:\n            return pd.DataFrame()\n\n        rows = []\n        layers = raw_data.get(\"properties\", {}).get(\"layers\", [])\n\n        # 3. Parse Data\n        for layer in layers:\n            prop_name = layer.get(\"name\")\n\n            # Get Unit Transformation details\n            unit_info = layer.get(\"unit_measure\", {})\n            d_factor = unit_info.get(\"d_factor\", 1)\n\n            # Grab both unit labels\n            mapped_unit = unit_info.get(\"mapped_units\", \"unknown\")  # e.g. \"cg/cm\u00b3\"\n            target_unit = unit_info.get(\"target_units\", \"unknown\")  # e.g. \"kg/dm\u00b3\"\n\n            for depth_record in layer.get(\"depths\", []):\n                depth_range = depth_record.get(\"label\")\n                values_dict = depth_record.get(\"values\", {})\n\n                for metric, raw_val in values_dict.items():\n                    # Calculate transformed value\n                    if isinstance(raw_val, (int, float)) and d_factor != 0:\n                        converted_val = raw_val / d_factor\n                    else:\n                        converted_val = raw_val\n\n                    rows.append(\n                        {\n                            \"latitude\": self.latitude,\n                            \"longitude\": self.longitude,\n                            \"property\": prop_name,\n                            \"depth\": depth_range,\n                            \"metric\": metric,\n                            \"value\": raw_val,\n                            \"unit\": mapped_unit,\n                            \"transformed_value\": converted_val,\n                            \"transformed_unit\": target_unit,\n                        }\n                    )\n\n        df = pd.DataFrame(rows)\n\n        # 4. Update Cache\n        self._cached_df = df\n\n        # 5. Save to File (if requested)\n        if self.filepath and not df.empty:\n            try:\n                df.to_csv(self.filepath, index=False)\n                print(f\"File saved successfully to {self.filepath}\")\n            except Exception as e:\n                print(f\"Failed to save file: {e}\")\n\n        return df\n</code></pre>"},{"location":"soil/#cropengine.soil.IsricSoilDataProvider.get_data","title":"<code>get_data(self)</code>","text":"<p>Fetches, parses, and returns soil data. Uses cached memory if data has already been fetched for this instance.</p> Source code in <code>cropengine/soil.py</code> <pre><code>def get_data(self):\n    \"\"\"\n    Fetches, parses, and returns soil data.\n    Uses cached memory if data has already been fetched for this instance.\n    \"\"\"\n    # 1. Check Cache (Optimization)\n    if self._cached_df is not None:\n        print(\"Returning cached data (no API call made).\")\n        return self._cached_df\n\n    # 2. Fetch Data\n    raw_data = self._extract_data()\n\n    if not raw_data:\n        return pd.DataFrame()\n\n    rows = []\n    layers = raw_data.get(\"properties\", {}).get(\"layers\", [])\n\n    # 3. Parse Data\n    for layer in layers:\n        prop_name = layer.get(\"name\")\n\n        # Get Unit Transformation details\n        unit_info = layer.get(\"unit_measure\", {})\n        d_factor = unit_info.get(\"d_factor\", 1)\n\n        # Grab both unit labels\n        mapped_unit = unit_info.get(\"mapped_units\", \"unknown\")  # e.g. \"cg/cm\u00b3\"\n        target_unit = unit_info.get(\"target_units\", \"unknown\")  # e.g. \"kg/dm\u00b3\"\n\n        for depth_record in layer.get(\"depths\", []):\n            depth_range = depth_record.get(\"label\")\n            values_dict = depth_record.get(\"values\", {})\n\n            for metric, raw_val in values_dict.items():\n                # Calculate transformed value\n                if isinstance(raw_val, (int, float)) and d_factor != 0:\n                    converted_val = raw_val / d_factor\n                else:\n                    converted_val = raw_val\n\n                rows.append(\n                    {\n                        \"latitude\": self.latitude,\n                        \"longitude\": self.longitude,\n                        \"property\": prop_name,\n                        \"depth\": depth_range,\n                        \"metric\": metric,\n                        \"value\": raw_val,\n                        \"unit\": mapped_unit,\n                        \"transformed_value\": converted_val,\n                        \"transformed_unit\": target_unit,\n                    }\n                )\n\n    df = pd.DataFrame(rows)\n\n    # 4. Update Cache\n    self._cached_df = df\n\n    # 5. Save to File (if requested)\n    if self.filepath and not df.empty:\n        try:\n            df.to_csv(self.filepath, index=False)\n            print(f\"File saved successfully to {self.filepath}\")\n        except Exception as e:\n            print(f\"Failed to save file: {e}\")\n\n    return df\n</code></pre>"},{"location":"soil/#cropengine.soil.WOFOSTSoilParameterProvider","title":"<code> WOFOSTSoilParameterProvider        </code>","text":"<p>Calculates soil physics and chemical parameters required for WOFOST crop modeling using ISRIC SoilGrids data.</p> <p>This class extracts soil properties, estimates hydraulic conductivity using Pedotransfer Functions (Cosby), and fits the Van Genuchten equation.</p> <p>Parameters:</p> Name Type Description Default <code>soil_data</code> <code>pd.DataFrame</code> <p>DataFrame containing ISRIC SoilGrids data.</p> required <code>**kwargs</code> <p>Optional overrides for specific soil parameters.</p> <code>{}</code> Source code in <code>cropengine/soil.py</code> <pre><code>class WOFOSTSoilParameterProvider:\n    \"\"\"\n    Calculates soil physics and chemical parameters required for WOFOST\n    crop modeling using ISRIC SoilGrids data.\n\n    This class extracts soil properties, estimates hydraulic conductivity\n    using Pedotransfer Functions (Cosby), and fits the Van Genuchten\n    equation.\n\n    Args:\n        soil_data (pd.DataFrame): DataFrame containing ISRIC SoilGrids data.\n        **kwargs: Optional overrides for specific soil parameters.\n    \"\"\"\n\n    # Default parameters for potential production\n    _defaults = {\n        \"SMFCF\": 0.3,\n        \"SM0\": 0.45,\n        \"SMW\": 0.1,\n        \"RDMSOL\": 120,\n        \"CRAIRC\": 0.06,\n        \"K0\": 10.0,\n        \"SOPE\": 10.0,\n        \"KSUB\": 10.0,\n        \"Soil_pH\": 7.0,\n        \"FSOMI\": 0.01,\n        \"CNRatioSOMI\": 10.0,\n    }\n\n    def __init__(self, soil_data, **kwargs):\n\n        self.df = soil_data\n        self.params = self._defaults.copy()\n        self.overrides = kwargs\n        self.param_metadata = get_wofost_soil_parameters_metadata()\n\n        # Ranges for generating PCSE tables (h in cm, pF = log10(h))\n        self.pf_range = np.array(\n            [-1.000, 1.000, 1.300, 1.491, 2.000, 2.400, 2.700, 3.400, 4.204, 6.000]\n        )\n        self.h_range = 10**self.pf_range\n\n    def _get_val(self, prop_name):\n        \"\"\"Helper to safely extract a specific property value from the DataFrame.\"\"\"\n        try:\n            return self.df.loc[\n                self.df[\"property\"] == prop_name, \"transformed_value\"\n            ].values[0]\n        except IndexError:\n            raise ValueError(f\"Missing required property: {prop_name}\")\n\n    def _calculate_ksat_ptf(self, sand_pct, clay_pct):\n        \"\"\"Estimate Ksat (cm/day) using Cosby (1984) PTF.\"\"\"\n        log_ksat = -0.6 + (0.0126 * sand_pct) - (0.0064 * clay_pct)\n        return max(0.1, min((10**log_ksat) * 24, 500.0))\n\n    def _van_genuchten_theta(self, h, theta_r, alpha, n, theta_s):\n        \"\"\"Mualem-Van Genuchten equation.\"\"\"\n        h = np.maximum(h, 0.0)\n        m = 1 - (1 / n)\n        return theta_r + (theta_s - theta_r) / ((1 + (alpha * h) ** n) ** m)\n\n    def _update_param_metadata(self, calc_params):\n        \"\"\"\n        Update the soil parameters metadata.\n        \"\"\"\n        param_metadata = []\n        for param, info in self.param_metadata.items():\n            param_dict = {\"parameter\": param}\n            param_dict.update(info)\n            if param in calc_params.keys():\n                param_dict[\"value\"] = calc_params[param]\n            else:\n                param_dict[\"value\"] = None\n\n            param_metadata.append(param_dict)\n\n        return param_metadata\n\n    def get_params(self):\n        \"\"\"\n        Calculates parameters, fits curves, applies overrides, and returns dictionary.\n        \"\"\"\n        # 1. Attempt to fetch available variables\n        bdod = self._get_val(\"bdod\")  # kg/dm3\n        sand = self._get_val(\"sand\")  # %\n        clay = self._get_val(\"clay\")  # %\n        soc = self._get_val(\"soc\")  # g/kg\n        nitrogen = self._get_val(\"nitrogen\")  # g/kg\n        ph = self._get_val(\"phh2o\")  # pH\n\n        try:\n            # Variables for curve fitting\n            th_10 = self._get_val(\"wv0010\")\n            th_33 = self._get_val(\"wv0033\")\n            th_1500 = self._get_val(\"wv1500\")\n        except:\n            th_10 = th_33 = th_1500 = None\n\n        # 2. Add pH\n        if ph is not None:\n            self.params[\"Soil_pH\"] = float(ph)\n\n        # 3. Update Bulk Density &amp; Porosity (SM0)\n        if bdod is not None:\n            self.params[\"RHOD\"] = float(bdod)\n            # Porosity = 1 - (Bulk Density / Particle Density 2.65)\n            sm0 = 1 - (bdod / 2.65)\n            self.params[\"SM0\"] = float(round(min(max(sm0, 0.3), 0.8), 3))\n\n        # 4. Update Hydraulic Conductivity (K0)\n        if sand is not None and clay is not None:\n            k0 = self._calculate_ksat_ptf(sand, clay)\n            self.params[\"K0\"] = float(round(k0, 2))\n            self.params[\"SOPE\"] = float(round(k0, 2))\n            self.params[\"KSUB\"] = float(round(k0, 2))\n\n        # 5. Update Chemical Properties (FSOMI, CNRatio)\n        if soc is not None:\n            # Organic Matter Fraction = SOC * 1.724 / 1000\n            fsomi = (soc * 1.724) / 1000.0\n            self.params[\"FSOMI\"] = float(round(fsomi, 4))\n\n            if nitrogen is not None and nitrogen &gt; 0:\n                self.params[\"CNRatioSOMI\"] = float(round(soc / nitrogen, 2))\n\n        depth_str = self.df.iloc[0][\"depth\"]\n        try:\n            top, bottom = depth_str.replace(\"cm\", \"\").split(\"-\")\n            self.params[\"Thickness\"] = float(bottom) - float(top)\n        except:\n            thickness = 10.0\n\n        # 6. Curve Fitting / SMfromPF Generation\n        # Only execute if we have observed water retention points\n        if th_10 is not None and th_33 is not None and th_1500 is not None:\n\n            # Use current SM0 (porosity)\n            current_sm0 = self.params.get(\"SM0\", 0.45)\n\n            h_obs = [0.01, 100.0, 330.0, 15000.0]\n            th_obs = [current_sm0, th_10, th_33, th_1500]\n            bounds = ([0.0, 1e-5, 1.01], [theta_1500, 10.0, 10.0])\n\n            try:\n                # Fit Van Genuchten\n                popt, _ = curve_fit(\n                    lambda h, tr, a, n: self._van_genuchten_theta(\n                        h, tr, a, n, theta_s=current_sm0\n                    ),\n                    np.array(h_obs),\n                    np.array(th_obs),\n                    p0=[0.01, 0.01, 1.5],\n                    bounds=bounds,\n                    method=\"trf\",\n                )\n                theta_r, alpha, n_param = popt\n\n                # Generate Tables using PCSE\n                vg_model = pe.soilmodel.Genuchten(\n                    k_s=self.params.get(\"K0\", 10.0),\n                    theta_s=current_sm0,\n                    theta_r=theta_r,\n                    alpha=alpha,\n                    n=n_param,\n                    l=0.5,\n                )\n                theta_curve = vg_model.theta(self.h_range)\n                k_curve = vg_model.k(self.h_range)\n\n                sm_table = []\n                cond_table = []\n\n                for pf, th, k in zip(self.pf_range, theta_curve, k_curve):\n                    sm_table.extend([float(pf), float(round(th, 4))])\n                    k_safe = max(k, 1e-15)\n                    cond_table.extend([float(pf), float(round(np.log10(k_safe), 4))])\n\n                self.params[\"SMfromPF\"] = sm_table\n                self.params[\"CONDfromPF\"] = cond_table\n\n                # Update Critical Points based on curve\n                self.params[\"SM0\"] = float(round(vg_model.theta(0.01), 3))\n                self.params[\"SMFCF\"] = float(round(vg_model.theta(100.0), 3))\n                self.params[\"SMW\"] = float(round(vg_model.theta(16000.0), 3))\n                self.params[\"CRAIRC\"] = float(\n                    round(max(0.05, self.params[\"SM0\"] - self.params[\"SMFCF\"]), 3)\n                )\n\n            except Exception as e:\n                print(f\"Curve fitting failed or skipped: {e}\")\n        else:\n            pass\n\n        # 7. Apply Validated Overrides\n        if self.overrides:\n            self.params.update(self.overrides)\n\n        # Update the parameters metadata\n        self.param_metadata = self._update_param_metadata(self.params)\n\n        return self.params\n</code></pre>"},{"location":"soil/#cropengine.soil.WOFOSTSoilParameterProvider.get_params","title":"<code>get_params(self)</code>","text":"<p>Calculates parameters, fits curves, applies overrides, and returns dictionary.</p> Source code in <code>cropengine/soil.py</code> <pre><code>def get_params(self):\n    \"\"\"\n    Calculates parameters, fits curves, applies overrides, and returns dictionary.\n    \"\"\"\n    # 1. Attempt to fetch available variables\n    bdod = self._get_val(\"bdod\")  # kg/dm3\n    sand = self._get_val(\"sand\")  # %\n    clay = self._get_val(\"clay\")  # %\n    soc = self._get_val(\"soc\")  # g/kg\n    nitrogen = self._get_val(\"nitrogen\")  # g/kg\n    ph = self._get_val(\"phh2o\")  # pH\n\n    try:\n        # Variables for curve fitting\n        th_10 = self._get_val(\"wv0010\")\n        th_33 = self._get_val(\"wv0033\")\n        th_1500 = self._get_val(\"wv1500\")\n    except:\n        th_10 = th_33 = th_1500 = None\n\n    # 2. Add pH\n    if ph is not None:\n        self.params[\"Soil_pH\"] = float(ph)\n\n    # 3. Update Bulk Density &amp; Porosity (SM0)\n    if bdod is not None:\n        self.params[\"RHOD\"] = float(bdod)\n        # Porosity = 1 - (Bulk Density / Particle Density 2.65)\n        sm0 = 1 - (bdod / 2.65)\n        self.params[\"SM0\"] = float(round(min(max(sm0, 0.3), 0.8), 3))\n\n    # 4. Update Hydraulic Conductivity (K0)\n    if sand is not None and clay is not None:\n        k0 = self._calculate_ksat_ptf(sand, clay)\n        self.params[\"K0\"] = float(round(k0, 2))\n        self.params[\"SOPE\"] = float(round(k0, 2))\n        self.params[\"KSUB\"] = float(round(k0, 2))\n\n    # 5. Update Chemical Properties (FSOMI, CNRatio)\n    if soc is not None:\n        # Organic Matter Fraction = SOC * 1.724 / 1000\n        fsomi = (soc * 1.724) / 1000.0\n        self.params[\"FSOMI\"] = float(round(fsomi, 4))\n\n        if nitrogen is not None and nitrogen &gt; 0:\n            self.params[\"CNRatioSOMI\"] = float(round(soc / nitrogen, 2))\n\n    depth_str = self.df.iloc[0][\"depth\"]\n    try:\n        top, bottom = depth_str.replace(\"cm\", \"\").split(\"-\")\n        self.params[\"Thickness\"] = float(bottom) - float(top)\n    except:\n        thickness = 10.0\n\n    # 6. Curve Fitting / SMfromPF Generation\n    # Only execute if we have observed water retention points\n    if th_10 is not None and th_33 is not None and th_1500 is not None:\n\n        # Use current SM0 (porosity)\n        current_sm0 = self.params.get(\"SM0\", 0.45)\n\n        h_obs = [0.01, 100.0, 330.0, 15000.0]\n        th_obs = [current_sm0, th_10, th_33, th_1500]\n        bounds = ([0.0, 1e-5, 1.01], [theta_1500, 10.0, 10.0])\n\n        try:\n            # Fit Van Genuchten\n            popt, _ = curve_fit(\n                lambda h, tr, a, n: self._van_genuchten_theta(\n                    h, tr, a, n, theta_s=current_sm0\n                ),\n                np.array(h_obs),\n                np.array(th_obs),\n                p0=[0.01, 0.01, 1.5],\n                bounds=bounds,\n                method=\"trf\",\n            )\n            theta_r, alpha, n_param = popt\n\n            # Generate Tables using PCSE\n            vg_model = pe.soilmodel.Genuchten(\n                k_s=self.params.get(\"K0\", 10.0),\n                theta_s=current_sm0,\n                theta_r=theta_r,\n                alpha=alpha,\n                n=n_param,\n                l=0.5,\n            )\n            theta_curve = vg_model.theta(self.h_range)\n            k_curve = vg_model.k(self.h_range)\n\n            sm_table = []\n            cond_table = []\n\n            for pf, th, k in zip(self.pf_range, theta_curve, k_curve):\n                sm_table.extend([float(pf), float(round(th, 4))])\n                k_safe = max(k, 1e-15)\n                cond_table.extend([float(pf), float(round(np.log10(k_safe), 4))])\n\n            self.params[\"SMfromPF\"] = sm_table\n            self.params[\"CONDfromPF\"] = cond_table\n\n            # Update Critical Points based on curve\n            self.params[\"SM0\"] = float(round(vg_model.theta(0.01), 3))\n            self.params[\"SMFCF\"] = float(round(vg_model.theta(100.0), 3))\n            self.params[\"SMW\"] = float(round(vg_model.theta(16000.0), 3))\n            self.params[\"CRAIRC\"] = float(\n                round(max(0.05, self.params[\"SM0\"] - self.params[\"SMFCF\"]), 3)\n            )\n\n        except Exception as e:\n            print(f\"Curve fitting failed or skipped: {e}\")\n    else:\n        pass\n\n    # 7. Apply Validated Overrides\n    if self.overrides:\n        self.params.update(self.overrides)\n\n    # Update the parameters metadata\n    self.param_metadata = self._update_param_metadata(self.params)\n\n    return self.params\n</code></pre>"},{"location":"soil/#cropengine.soil.get_wofost_soil_parameters_metadata","title":"<code>get_wofost_soil_parameters_metadata()</code>","text":"<p>Parses 'configs/soil_params.yaml' to extract soil parameter definitions.</p> <p>Returns:</p> Type Description <code>dict</code> <p>Dictionary of parameters with 'description' and 'unit'.</p> Source code in <code>cropengine/soil.py</code> <pre><code>def get_wofost_soil_parameters_metadata():\n    \"\"\"\n    Parses 'configs/soil_params.yaml' to extract soil parameter definitions.\n\n    Returns:\n        dict: Dictionary of parameters with 'description' and 'unit'.\n    \"\"\"\n    metadata = {}\n\n    try:\n        with pkg_resources.files(configs).joinpath(\"soil_params.yaml\").open(\"r\") as f:\n            full_config = yaml.safe_load(f)\n    except (FileNotFoundError, ModuleNotFoundError) as e:\n        raise ValueError(\n            f\"Could not load 'soil_params.yaml' from 'configs'. Error: {e}\"\n        )\n    except yaml.YAMLError as exc:\n        raise ValueError(f\"Error parsing YAML content: {exc}\")\n\n    # Locate the root soil parameters section\n    soil_section = full_config.get(\"wofost\", {}).get(\"soil_params\", {})\n\n    if not soil_section:\n        if \"WaterbalanceFD\" in full_config or \"WaterBalanceLayered\" in full_config:\n            soil_section = full_config\n        else:\n            return {}\n\n    def _recursive_extract(node):\n        for key, value in node.items():\n            if isinstance(value, dict):\n                if \"description\" in value or \"unit\" in value:\n                    metadata[key] = {\n                        \"description\": value.get(\n                            \"description\", \"No description available\"\n                        ),\n                        \"unit\": value.get(\"unit\", \"-\"),\n                    }\n                else:\n                    _recursive_extract(value)\n\n    _recursive_extract(soil_section)\n\n    # Ensure defaults exist\n    if \"K0\" not in metadata:\n        metadata[\"K0\"] = {\n            \"description\": \"Hydraulic conductivity of saturated soil\",\n            \"unit\": \"cm/day\",\n        }\n    if \"IVINF\" not in metadata:\n        metadata[\"IVINF\"] = {\"description\": \"Infiltration limiter\", \"unit\": \"-\"}\n\n    return metadata\n</code></pre>"},{"location":"usage/","title":"Usage","text":"<p>To use cropengine in a project:</p> <pre><code>import cropengine\n</code></pre>"},{"location":"weather/","title":"weather module","text":"<p>Module to prepare weather data</p>"},{"location":"weather/#cropengine.weather.ClimateConfig","title":"<code> ClimateConfig        </code>","text":"<p>Parses and holds configuration for climate variables.</p> Source code in <code>cropengine/weather.py</code> <pre><code>class ClimateConfig:\n    \"\"\"Parses and holds configuration for climate variables.\"\"\"\n\n    def __init__(self, config_dict):\n        self.raw = config_dict\n        self.variables = config_dict[\"variables\"]\n        self.all_bands = []\n        self.var_to_bands = {}\n        self.var_to_units = {}\n        self.var_to_conversion = {}\n        self.derived = set()\n        self._parse_variables()\n\n    def _parse_variables(self):\n        for var_name, info in self.variables.items():\n            self.var_to_units[var_name] = (\n                info.get(\"native_unit\"),\n                info.get(\"target_unit\"),\n            )\n            self.var_to_conversion[var_name] = info.get(\"conversion\")\n            if info.get(\"derived\", False):\n                self.derived.add(var_name)\n\n            bands = []\n            for key, value in info.items():\n                if key.startswith(\"band\") and value is not None:\n                    bands.append(value)\n                    self.all_bands.append(value)\n            self.var_to_bands[var_name] = bands\n\n    def get_all_bands(self):\n        return list(set(self.all_bands))\n\n    def is_derived(self, var_name):\n        return var_name in self.derived\n</code></pre>"},{"location":"weather/#cropengine.weather.GEEWeatherDataProvider","title":"<code> GEEWeatherDataProvider        </code>","text":"<p>Handles data retrieval, processing, and export of weather data from Google Earth Engine in PCSE format.</p> <p>IMPORTANT: This class strictly handles POINT data. If a Geometry/Polygon is provided, it extracts data for the CENTROID of that geometry only.</p> <p>Parameters:</p> Name Type Description Default <code>start_date</code> <code>str</code> <p>Start date (YYYY-MM-DD).</p> required <code>end_date</code> <code>str</code> <p>End date (YYYY-MM-DD).</p> required <code>latitude</code> <code>float</code> <p>Latitude (if geometry not provided).</p> <code>None</code> <code>longitude</code> <code>float</code> <p>Longitude (if geometry not provided).</p> <code>None</code> <code>geometry</code> <code>ee.Geometry</code> <p>Polygon or geometry object. Will be converted to its Centroid.</p> <code>None</code> <code>source</code> <code>str</code> <p>Key in meteo.yaml (e.g., 'era5_land').</p> <code>'era5_land'</code> <code>filepath</code> <code>str</code> <p>Default output path.</p> <code>None</code> <code>ee_project</code> <code>str</code> <p>GCloud project ID for GEE initialization.</p> <code>None</code> <code>**site_kwargs</code> <p>Extra metadata for the Excel header (e.g., Station, Country).</p> <code>{}</code> Source code in <code>cropengine/weather.py</code> <pre><code>class GEEWeatherDataProvider:\n    \"\"\"\n    Handles data retrieval, processing, and export of weather data from Google Earth Engine in PCSE format.\n\n    IMPORTANT: This class strictly handles POINT data. If a Geometry/Polygon is provided,\n    it extracts data for the CENTROID of that geometry only.\n\n    Args:\n        start_date (str): Start date (YYYY-MM-DD).\n        end_date (str): End date (YYYY-MM-DD).\n        latitude (float, optional): Latitude (if geometry not provided).\n        longitude (float, optional): Longitude (if geometry not provided).\n        geometry (ee.Geometry, optional): Polygon or geometry object. Will be converted to its Centroid.\n        source (str): Key in meteo.yaml (e.g., 'era5_land').\n        filepath (str, optional): Default output path.\n        ee_project (str, optional): GCloud project ID for GEE initialization.\n        **site_kwargs: Extra metadata for the Excel header (e.g., Station, Country).\n    \"\"\"\n\n    def __init__(\n        self,\n        start_date,\n        end_date,\n        latitude=None,\n        longitude=None,\n        geometry=None,\n        source=\"era5_land\",\n        filepath=None,\n        ee_project=None,\n        **site_kwargs,\n    ):\n\n        self._check_gee_initialized(ee_project)\n\n        if geometry:\n            if isinstance(geometry, (ee.Feature, ee.FeatureCollection)):\n                region_geom = geometry.geometry()\n            else:\n                region_geom = ee.Geometry(geometry)\n\n            # Calculate Centroid\n            try:\n                centroid_obj = region_geom.centroid(maxError=1)\n                coords = centroid_obj.coordinates().getInfo()\n            except Exception:\n                centroid_obj = region_geom.bounds(maxError=1).centroid(maxError=1)\n                coords = centroid_obj.coordinates().getInfo()\n\n            self.longitude = coords[0]\n            self.latitude = coords[1]\n\n        elif latitude is not None and longitude is not None:\n            self.latitude = latitude\n            self.longitude = longitude\n        else:\n            raise ValueError(\n                \"Must provide either 'geometry' OR 'latitude' and 'longitude'.\"\n            )\n\n        self.region = ee.Geometry.Point([self.longitude, self.latitude])\n\n        self.start_date = start_date\n        self.end_date = end_date\n        self.source = source.lower()\n        self.filepath = filepath\n        self.site_kwargs = site_kwargs\n\n        self._cached_df = None\n        self._cached_elevation = None\n\n        with pkg_resources.files(configs).joinpath(\"meteo.yaml\").open(\"r\") as f:\n            full_config = yaml.safe_load(f)\n\n        if source.lower() not in full_config:\n            raise ValueError(\n                f\"Source '{source}' not found. Available: {list(full_config.keys())}\"\n            )\n\n        self.weather_config = full_config[source.lower()]\n        self.cfg = ClimateConfig(self.weather_config)\n\n    def _check_gee_initialized(self, project=None):\n        \"\"\"\n        Checks if GEE is initialized. If not, attempts to initialize.\n        \"\"\"\n        try:\n            ee.Image(0).getInfo()\n        except Exception:\n            print(\"GEE not initialized. Attempting initialization...\")\n            try:\n                # Try initializing with specific project if provided, else default\n                if project:\n                    ee.Initialize(project=project)\n                else:\n                    ee.Initialize()\n                print(\"GEE Initialized successfully.\")\n            except Exception as e:\n                raise RuntimeError(\n                    f\"Failed to initialize Earth Engine: {e}.\\n\"\n                    \"Please run 'earthengine authenticate' in your terminal first.\"\n                )\n\n    def _get_elevation(self):\n\n        if self._cached_elevation is not None:\n            return self._cached_elevation\n\n        try:\n            geom = self.region\n            dem_source = self.weather_config.get(\n                \"dem_source\", \"projects/sat-io/open-datasets/GLO-30\"\n            )\n\n            elev = (\n                ee.ImageCollection(dem_source)\n                .filterBounds(geom)\n                .first()\n                .sample(geom, scale=30)\n                .first()\n                .get(\"b1\")\n            )\n\n            val = elev.getInfo()\n            self._cached_elevation = round(float(val), 3) if val is not None else 0.0\n            return self._cached_elevation\n\n        except Exception as e:\n            print(f\"Warning: Could not fetch elevation ({e}). Defaulting to 0.\")\n            self._cached_elevation = 0.0\n            return 0.0\n\n    def _extract_data(self):\n        \"\"\"\n        Extraction of weather data.\n        \"\"\"\n        band_names = self.cfg.get_all_bands()\n        scale = self.weather_config.get(\"default_scale\", 5000)\n        collection_id = self.weather_config.get(\"collection\")\n\n        ic = ee.ImageCollection(collection_id)\n\n        return extract_timeseries_to_point(\n            lat=self.latitude,\n            lon=self.longitude,\n            image_collection=ic,\n            start_date=self.start_date,\n            end_date=self.end_date,\n            band_names=band_names,\n            scale=scale,\n        )\n\n    def get_data(self):\n        if self._cached_df is not None:\n            return self._cached_df\n\n        df_raw = self._extract_data()\n        output = pd.DataFrame(index=df_raw.index)\n        output[\"date\"] = df_raw[\"time\"]\n\n        for var, bands in self.cfg.var_to_bands.items():\n            conversion = self.cfg.var_to_conversion.get(var)\n            converter_func = CONVERSION_FUNCS.get(conversion, lambda x: x)\n\n            inputs = [df_raw[b] for b in bands]\n\n            try:\n                output[var] = converter_func(*inputs)\n            except TypeError as e:\n                raise ValueError(\n                    f\"Error calculating {var}: Function '{conversion}' \"\n                    f\"expected different arguments than provided bands {bands}. \"\n                    f\"Details: {e}\"\n                )\n\n        self._cached_df = output.round(3)\n        return self._cached_df\n\n    def save_weather_excel(self, filepath=None, **override_kwargs):\n        target_path = filepath or self.filepath\n        if not target_path:\n            raise ValueError(\"Invalid filepath.\")\n\n        df = self.get_data()\n\n        meta_defaults = {\n            \"Country\": \"Unknown\",\n            \"Station\": \"Unknown\",\n            \"Description\": self.weather_config.get(\"description\"),\n            \"Source\": self.weather_config.get(\"collection\"),\n            \"Contact\": \"Unknown\",\n            \"Missing values\": -999,\n            \"AngstromA\": 0.25,\n            \"AngstromB\": 0.50,\n            \"HasSunshine\": False,\n        }\n\n        meta = {**meta_defaults, **self.site_kwargs, **override_kwargs}\n\n        excel_rows = []\n\n        excel_rows.append([\"Site Characteristics\"])\n        excel_rows.append([\"Country\", meta[\"Country\"]])\n        excel_rows.append([\"Station\", meta[\"Station\"]])\n        excel_rows.append([\"Description\", meta[\"Description\"]])\n        excel_rows.append([\"Source\", meta[\"Source\"]])\n        excel_rows.append([\"Contact\", meta[\"Contact\"]])\n        excel_rows.append([\"Missing values\", meta[\"Missing values\"]])\n\n        excel_rows.append(\n            [\n                \"Longitude\",\n                \"Latitude\",\n                \"Elevation\",\n                \"AngstromA\",\n                \"AngstromB\",\n                \"HasSunshine\",\n            ]\n        )\n        excel_rows.append(\n            [\n                self.longitude,\n                self.latitude,\n                self._get_elevation(),\n                meta[\"AngstromA\"],\n                meta[\"AngstromB\"],\n                str(meta[\"HasSunshine\"]).upper(),\n            ]\n        )\n\n        excel_rows.append([\"Observed data\"])\n\n        var_order = [\"IRRAD\", \"TMIN\", \"TMAX\", \"VAP\", \"WIND\", \"RAIN\", \"SNOWDEPTH\"]\n        present_vars = [v for v in var_order if v in df.columns]\n\n        header_names = [\"DAY\"] + present_vars\n        excel_rows.append(header_names)\n\n        header_units = [\"date\"]\n        for v in present_vars:\n            if v in self.cfg.var_to_units:\n                header_units.append(self.cfg.var_to_units[v][1])\n            else:\n                header_units.append(\"-\")\n        excel_rows.append(header_units)\n\n        df_export = df.copy()\n        df_export = df_export.fillna(meta[\"Missing values\"])\n        df_export = df_export[[\"date\"] + present_vars]\n\n        with pd.ExcelWriter(target_path, engine=\"openpyxl\") as writer:\n            pd.DataFrame(excel_rows).to_excel(\n                writer, sheet_name=\"Sheet1\", index=False, header=False, startrow=0\n            )\n\n            df_export.to_excel(\n                writer,\n                sheet_name=\"Sheet1\",\n                index=False,\n                header=False,\n                startrow=len(excel_rows),\n            )\n\n        print(f\"File saved successfully to {target_path}\")\n</code></pre>"},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/","title":"Run parameter optimization (wofost)","text":"<p>Uncomment the following line to install the latest version of cropengine if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U cropengine\n</pre> # !pip install -U cropengine In\u00a0[\u00a0]: Copied! <pre>import os\nimport math\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom cropengine import WOFOSTCropSimulationBatchRunner\nfrom cropengine.agromanagement import WOFOSTAgroEventBuilder\nfrom cropengine.optimizer import WOFOSTOptimizer\n\nfrom sklearn.metrics import mean_squared_error\n</pre> import os import math import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns from cropengine import WOFOSTCropSimulationBatchRunner from cropengine.agromanagement import WOFOSTAgroEventBuilder from cropengine.optimizer import WOFOSTOptimizer  from sklearn.metrics import mean_squared_error In\u00a0[\u00a0]: Copied! <pre># Define the model name\nMODEL_NAME = \"Wofost72_WLP_CWB\"\n\n# Define the csv path with 'id', 'latitude', and 'longitude'\nlocations_csv_path = \"test_data/optimizer/location.csv\"\n\n# Initialize Engine\nbatch_runner = WOFOSTCropSimulationBatchRunner(\n    model_name=MODEL_NAME,\n    locations_csv_path=locations_csv_path,\n    workspace_dir=\"test_output/optimizer_workspace\",\n)\n</pre> # Define the model name MODEL_NAME = \"Wofost72_WLP_CWB\"  # Define the csv path with 'id', 'latitude', and 'longitude' locations_csv_path = \"test_data/optimizer/location.csv\"  # Initialize Engine batch_runner = WOFOSTCropSimulationBatchRunner(     model_name=MODEL_NAME,     locations_csv_path=locations_csv_path,     workspace_dir=\"test_output/optimizer_workspace\", ) In\u00a0[\u00a0]: Copied! <pre># Crop Configuration\nmodels = batch_runner.get_model_options()\n\ncrops = batch_runner.get_crop_options(MODEL_NAME)\nCROP_NAME = \"wheat\"\nvarieties = batch_runner.get_variety_options(MODEL_NAME, CROP_NAME)\nCROP_VARIETY = \"Winter_wheat_103\"\n\n# Timing\ncrop_start_end = batch_runner.get_crop_start_end_options()\nCAMPAIGN_START = \"2019-09-01\"\nCROP_START = \"2019-09-25\"\nCROP_START_TYPE = \"sowing\"\nCROP_END_TYPE = \"maturity\"\nCROP_END = None\nCAMPAIGN_END = \"2020-09-30\"\nMAX_DURATION = 365\n</pre> # Crop Configuration models = batch_runner.get_model_options()  crops = batch_runner.get_crop_options(MODEL_NAME) CROP_NAME = \"wheat\" varieties = batch_runner.get_variety_options(MODEL_NAME, CROP_NAME) CROP_VARIETY = \"Winter_wheat_103\"  # Timing crop_start_end = batch_runner.get_crop_start_end_options() CAMPAIGN_START = \"2019-09-01\" CROP_START = \"2019-09-25\" CROP_START_TYPE = \"sowing\" CROP_END_TYPE = \"maturity\" CROP_END = None CAMPAIGN_END = \"2020-09-30\" MAX_DURATION = 365 In\u00a0[\u00a0]: Copied! <pre>agro_event_builder = WOFOSTAgroEventBuilder()\n\n# Note: Use agro_event_builder.get_..._events_info() to see valid values if unsure\ntimed_events_info = agro_event_builder.get_timed_events_info()\nstate_events_info = agro_event_builder.get_state_events_info()\n\n# Build timed events (irrigation)\nirrigation_schedule = [\n    {\"event_date\": \"2020-03-20\", \"amount\": 3.0, \"efficiency\": 0.7},  # stem elongation\n    {\"event_date\": \"2020-04-25\", \"amount\": 2.5, \"efficiency\": 0.7},  # booting/heading\n    {\"event_date\": \"2020-05-20\", \"amount\": 2.0, \"efficiency\": 0.7},  # flowering\n]\n\nirrigation_events = agro_event_builder.create_timed_events(\n    signal_type=\"irrigate\", events_list=irrigation_schedule\n)\n\n# Build state Events (fertilization based on DVS)\nnitrogen_schedule = [\n    {\"threshold\": 0.3, \"N_amount\": 40, \"N_recovery\": 0.7},  # early vegetative\n    {\"threshold\": 0.6, \"N_amount\": 60, \"N_recovery\": 0.7},  # stem elongation\n    {\"threshold\": 1.0, \"N_amount\": 40, \"N_recovery\": 0.7},  # heading\n]\n\nnitrogen_events = agro_event_builder.create_state_events(\n    signal_type=\"apply_n\",\n    state_var=\"DVS\",\n    zero_condition=\"rising\",\n    events_list=nitrogen_schedule,\n)\n</pre> agro_event_builder = WOFOSTAgroEventBuilder()  # Note: Use agro_event_builder.get_..._events_info() to see valid values if unsure timed_events_info = agro_event_builder.get_timed_events_info() state_events_info = agro_event_builder.get_state_events_info()  # Build timed events (irrigation) irrigation_schedule = [     {\"event_date\": \"2020-03-20\", \"amount\": 3.0, \"efficiency\": 0.7},  # stem elongation     {\"event_date\": \"2020-04-25\", \"amount\": 2.5, \"efficiency\": 0.7},  # booting/heading     {\"event_date\": \"2020-05-20\", \"amount\": 2.0, \"efficiency\": 0.7},  # flowering ]  irrigation_events = agro_event_builder.create_timed_events(     signal_type=\"irrigate\", events_list=irrigation_schedule )  # Build state Events (fertilization based on DVS) nitrogen_schedule = [     {\"threshold\": 0.3, \"N_amount\": 40, \"N_recovery\": 0.7},  # early vegetative     {\"threshold\": 0.6, \"N_amount\": 60, \"N_recovery\": 0.7},  # stem elongation     {\"threshold\": 1.0, \"N_amount\": 40, \"N_recovery\": 0.7},  # heading ]  nitrogen_events = agro_event_builder.create_state_events(     signal_type=\"apply_n\",     state_var=\"DVS\",     zero_condition=\"rising\",     events_list=nitrogen_schedule, ) In\u00a0[\u00a0]: Copied! <pre>batch_runner.prepare_batch_system(\n    campaign_start=CAMPAIGN_START,\n    campaign_end=CAMPAIGN_END,\n    crop_start=CROP_START,\n    crop_start_type=CROP_START_TYPE,\n    crop_end_type=CROP_END_TYPE,\n    crop_end=CROP_END,\n    max_duration=MAX_DURATION,\n    crop_name=CROP_NAME,\n    variety_name=CROP_VARIETY,\n    timed_events=[irrigation_events],\n    state_events=[nitrogen_events],\n    force_update=False,\n    WAV=10,  # Extra site params can be passed as a kwargs\n)\n</pre> batch_runner.prepare_batch_system(     campaign_start=CAMPAIGN_START,     campaign_end=CAMPAIGN_END,     crop_start=CROP_START,     crop_start_type=CROP_START_TYPE,     crop_end_type=CROP_END_TYPE,     crop_end=CROP_END,     max_duration=MAX_DURATION,     crop_name=CROP_NAME,     variety_name=CROP_VARIETY,     timed_events=[irrigation_events],     state_events=[nitrogen_events],     force_update=False,     WAV=10,  # Extra site params can be passed as a kwargs ) In\u00a0[\u00a0]: Copied! <pre>results = batch_runner.run_batch_simulation(max_workers=5)\nprint(results.shape)\nresults.head()\n</pre> results = batch_runner.run_batch_simulation(max_workers=5) print(results.shape) results.head() In\u00a0[\u00a0]: Copied! <pre># Ensure 'day' is datetime\nbatch_results = results.copy()\nbatch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])\n\n# Variables to plot (exclude metadata columns)\nvars_to_plot = [\n    col\n    for col in batch_results.columns\n    if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"]\n]\n\n# Layout\ncols = 2\nrows = math.ceil(len(vars_to_plot) / cols)\n\n# Colors for point_id groups\nunique_points = batch_results[\"point_id\"].unique()\npalette = sns.color_palette(\"tab10\", len(unique_points))\ncolor_map = {pid: palette[i] for i, pid in enumerate(unique_points)}\n\nfig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True)\naxes = axes.flatten()\n\nfor i, var in enumerate(vars_to_plot):\n    ax = axes[i]\n\n    for pid in unique_points:\n        df_sub = batch_results[batch_results[\"point_id\"] == pid]\n\n        sns.lineplot(\n            x=df_sub[\"day\"],\n            y=df_sub[var],\n            ax=ax,\n            label=f\"Point {pid}\",\n            color=color_map[pid],\n        )\n\n    ax.set_title(var)\n    ax.legend()\n\n# Hide remaining empty subplots\nfor j in range(len(vars_to_plot), len(axes)):\n    axes[j].axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Ensure 'day' is datetime batch_results = results.copy() batch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])  # Variables to plot (exclude metadata columns) vars_to_plot = [     col     for col in batch_results.columns     if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"] ]  # Layout cols = 2 rows = math.ceil(len(vars_to_plot) / cols)  # Colors for point_id groups unique_points = batch_results[\"point_id\"].unique() palette = sns.color_palette(\"tab10\", len(unique_points)) color_map = {pid: palette[i] for i, pid in enumerate(unique_points)}  fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True) axes = axes.flatten()  for i, var in enumerate(vars_to_plot):     ax = axes[i]      for pid in unique_points:         df_sub = batch_results[batch_results[\"point_id\"] == pid]          sns.lineplot(             x=df_sub[\"day\"],             y=df_sub[var],             ax=ax,             label=f\"Point {pid}\",             color=color_map[pid],         )      ax.set_title(var)     ax.legend()  # Hide remaining empty subplots for j in range(len(vars_to_plot), len(axes)):     axes[j].axis(\"off\")  plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre># Load the observed phenology\nobs_phenology_df = pd.read_csv(\"test_data/optimizer/phenology_observed.csv\")\nphenology_optimizer = WOFOSTOptimizer(\n    runner=batch_runner, observed_data=obs_phenology_df\n)\n\n# Create the loss function for phenology\ndef loss_fn_phenology(sim_df, obs_df):\n    # Process observed data\n    phenology_obs = obs_df[[\"id\", \"flowering_doy\", \"maturity_doy\"]]\n\n    # Process simulated data\n    sim_df[\"day\"] = pd.to_datetime(sim_df[\"day\"])\n    flowering_dates = sim_df[sim_df[\"DVS\"] == 1][[\"point_id\", \"day\"]]\n    flowering_dates[\"flowering_doy_sim\"] = flowering_dates[\"day\"].dt.day_of_year\n    maturity_dates = sim_df[sim_df[\"DVS\"] == 2][[\"point_id\", \"day\"]]\n    maturity_dates[\"maturity_doy_sim\"] = maturity_dates[\"day\"].dt.day_of_year\n    phenology_sim = pd.merge(\n        left=flowering_dates[[\"point_id\", \"flowering_doy_sim\"]],\n        right=maturity_dates[[\"point_id\", \"maturity_doy_sim\"]],\n        on=\"point_id\",\n        how=\"inner\",\n    )\n\n    merged_df = pd.merge(\n        left=phenology_obs, right=phenology_sim, left_on=\"id\", right_on=\"point_id\"\n    )\n\n    flowering_loss = np.sqrt(\n        mean_squared_error(merged_df[\"flowering_doy\"], merged_df[\"flowering_doy_sim\"])\n    )\n    maturity_loss = np.sqrt(\n        mean_squared_error(merged_df[\"maturity_doy\"], merged_df[\"maturity_doy_sim\"])\n    )\n\n    total_loss = np.round((flowering_loss + maturity_loss) / 2, 2)\n\n    return total_loss\n\n# Define the search space\ndef search_space(trial):\n    return {\n        \"crop_params\": {\n            \"TSUM1\": trial.suggest_int(\"TSUM1\", 100, 1200),\n            \"TSUM2\": trial.suggest_int(\"TSUM2\", 100, 1200),\n        }\n    }\n\nstudy = phenology_optimizer.optimize(\n    search_space, loss_fn_phenology, n_trials=100, n_workers=5, directions=[\"minimize\"], sampler='TPE'\n)\n</pre> # Load the observed phenology obs_phenology_df = pd.read_csv(\"test_data/optimizer/phenology_observed.csv\") phenology_optimizer = WOFOSTOptimizer(     runner=batch_runner, observed_data=obs_phenology_df )  # Create the loss function for phenology def loss_fn_phenology(sim_df, obs_df):     # Process observed data     phenology_obs = obs_df[[\"id\", \"flowering_doy\", \"maturity_doy\"]]      # Process simulated data     sim_df[\"day\"] = pd.to_datetime(sim_df[\"day\"])     flowering_dates = sim_df[sim_df[\"DVS\"] == 1][[\"point_id\", \"day\"]]     flowering_dates[\"flowering_doy_sim\"] = flowering_dates[\"day\"].dt.day_of_year     maturity_dates = sim_df[sim_df[\"DVS\"] == 2][[\"point_id\", \"day\"]]     maturity_dates[\"maturity_doy_sim\"] = maturity_dates[\"day\"].dt.day_of_year     phenology_sim = pd.merge(         left=flowering_dates[[\"point_id\", \"flowering_doy_sim\"]],         right=maturity_dates[[\"point_id\", \"maturity_doy_sim\"]],         on=\"point_id\",         how=\"inner\",     )      merged_df = pd.merge(         left=phenology_obs, right=phenology_sim, left_on=\"id\", right_on=\"point_id\"     )      flowering_loss = np.sqrt(         mean_squared_error(merged_df[\"flowering_doy\"], merged_df[\"flowering_doy_sim\"])     )     maturity_loss = np.sqrt(         mean_squared_error(merged_df[\"maturity_doy\"], merged_df[\"maturity_doy_sim\"])     )      total_loss = np.round((flowering_loss + maturity_loss) / 2, 2)      return total_loss  # Define the search space def search_space(trial):     return {         \"crop_params\": {             \"TSUM1\": trial.suggest_int(\"TSUM1\", 100, 1200),             \"TSUM2\": trial.suggest_int(\"TSUM2\", 100, 1200),         }     }  study = phenology_optimizer.optimize(     search_space, loss_fn_phenology, n_trials=100, n_workers=5, directions=[\"minimize\"], sampler='TPE' ) In\u00a0[\u00a0]: Copied! <pre># Run the simulation with optimized parameters\nbest_params = phenology_optimizer.get_best_params(study, search_space)\n\n# Update the parameters in the workspace\nbatch_runner.update_parameters(\n    crop_overrides=best_params['crop_params']\n)\n\n# Run the simulations with updated parameters\nresults = batch_runner.run_batch_simulation(max_workers=5)\nprint(results.shape)\nresults.head()\n</pre> # Run the simulation with optimized parameters best_params = phenology_optimizer.get_best_params(study, search_space)  # Update the parameters in the workspace batch_runner.update_parameters(     crop_overrides=best_params['crop_params'] )  # Run the simulations with updated parameters results = batch_runner.run_batch_simulation(max_workers=5) print(results.shape) results.head() In\u00a0[\u00a0]: Copied! <pre># Ensure 'day' is datetime\nbatch_results = results.copy()\nbatch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])\n\n# Variables to plot (exclude metadata columns)\nvars_to_plot = [\n    col\n    for col in batch_results.columns\n    if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"]\n]\n\n# Layout\ncols = 2\nrows = math.ceil(len(vars_to_plot) / cols)\n\n# Colors for point_id groups\nunique_points = batch_results[\"point_id\"].unique()\npalette = sns.color_palette(\"tab10\", len(unique_points))\ncolor_map = {pid: palette[i] for i, pid in enumerate(unique_points)}\n\nfig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True)\naxes = axes.flatten()\n\nfor i, var in enumerate(vars_to_plot):\n    ax = axes[i]\n\n    for pid in unique_points:\n        df_sub = batch_results[batch_results[\"point_id\"] == pid]\n\n        sns.lineplot(\n            x=df_sub[\"day\"],\n            y=df_sub[var],\n            ax=ax,\n            label=f\"Point {pid}\",\n            color=color_map[pid],\n        )\n\n    ax.set_title(var)\n    ax.legend()\n\n# Hide remaining empty subplots\nfor j in range(len(vars_to_plot), len(axes)):\n    axes[j].axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Ensure 'day' is datetime batch_results = results.copy() batch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])  # Variables to plot (exclude metadata columns) vars_to_plot = [     col     for col in batch_results.columns     if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"] ]  # Layout cols = 2 rows = math.ceil(len(vars_to_plot) / cols)  # Colors for point_id groups unique_points = batch_results[\"point_id\"].unique() palette = sns.color_palette(\"tab10\", len(unique_points)) color_map = {pid: palette[i] for i, pid in enumerate(unique_points)}  fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True) axes = axes.flatten()  for i, var in enumerate(vars_to_plot):     ax = axes[i]      for pid in unique_points:         df_sub = batch_results[batch_results[\"point_id\"] == pid]          sns.lineplot(             x=df_sub[\"day\"],             y=df_sub[var],             ax=ax,             label=f\"Point {pid}\",             color=color_map[pid],         )      ax.set_title(var)     ax.legend()  # Hide remaining empty subplots for j in range(len(vars_to_plot), len(axes)):     axes[j].axis(\"off\")  plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre># Load the observed yield\nobs_yield_df = pd.read_csv(\"test_data/optimizer/yield_observed.csv\")\nyield_optimizer = WOFOSTOptimizer(\n    runner=batch_runner, observed_data=obs_yield_df\n)\n\n# Create the loss function for yield\ndef loss_fn_yield(sim_df, obs_df):\n    # Process observed data\n    obs_df = obs_df[[\"id\", \"yield\"]].copy()\n    obs_df['yield'] = obs_df['yield']*1000 # t/ha -&gt; kg/ha\n\n    # Process simulated data\n    sim_df[\"day\"] = pd.to_datetime(sim_df[\"day\"])\n    sim_df = sim_df[sim_df['DVS']&gt;=2]\n    sim_df = sim_df.groupby(by='point_id').first()\n    sim_df = sim_df[['TWSO']].reset_index()\n    \n    merged_df = pd.merge(\n        left=obs_df, right=sim_df, left_on=\"id\", right_on=\"point_id\"\n    )\n\n    yield_loss = np.sqrt(\n        mean_squared_error(merged_df[\"yield\"], merged_df[\"TWSO\"])\n    )\n\n    return np.round(yield_loss, 2)\n\n# Define the search space\ndef search_space(trial):\n    # 1. Define a scaling factor for Photosynthesis (AMAX)\n    # This allows Optuna to shift the entire curve up or down by +/- 20%\n    amax_factor = trial.suggest_float(\"amax_factor\", 0.8, 1.2)\n    \n    # 2. Define a scaling factor for Leaf Thickness (SLA)\n    sla_factor = trial.suggest_float(\"sla_factor\", 0.8, 1.2)\n\n    return {\n        \"crop_params\": {\n            # LEAF DYNAMICS (Source capacity)\n            # SPAN: Leaf lifespan. Higher = longer green canopy duration.\n            \"SPAN\": trial.suggest_float(\"SPAN\", 25.0, 40.0),\n            \n            # SLATB (Specific Leaf Area): Controls how much leaf area is built per kg biomass.\n            # We scale the entire table by a factor (0.8x to 1.2x).\n            \"SLATB\": [\n                0.0, 0.00212 * sla_factor,\n                0.5, 0.00212 * sla_factor,\n                2.0, 0.00212 * sla_factor\n            ],\n\n            # ASSIMILATION &amp; CONVERSION (Biomass production)\n            # AMAXTB: Max CO2 assimilation rate. Highly sensitive.\n            \"AMAXTB\": [\n                0.0, 35.83 * amax_factor,  # Vegetative\n                1.0, 35.83 * amax_factor,  # Flowering\n                1.3, 35.83 * amax_factor,  # Early Grain filling\n                2.0,  4.48 * amax_factor   # Maturity (Senescence)\n            ],\n            # CVT: Efficiency of conversion to storage organs (Harvest Index driver).\n            \"CVO\": trial.suggest_float(\"CVO\", 0.65, 0.75),\n\n            # ROOTING (Water access)\n            # RDMCR: Max rooting depth. Critical for drought resistance.\n            \"RDMCR\": trial.suggest_int(\"RDMCR\", 80, 150),\n        }\n    }\n\nstudy = yield_optimizer.optimize(\n    search_space, loss_fn_yield, n_trials=1000, n_workers=5, directions=[\"minimize\"], sampler='TPE'\n)\n</pre> # Load the observed yield obs_yield_df = pd.read_csv(\"test_data/optimizer/yield_observed.csv\") yield_optimizer = WOFOSTOptimizer(     runner=batch_runner, observed_data=obs_yield_df )  # Create the loss function for yield def loss_fn_yield(sim_df, obs_df):     # Process observed data     obs_df = obs_df[[\"id\", \"yield\"]].copy()     obs_df['yield'] = obs_df['yield']*1000 # t/ha -&gt; kg/ha      # Process simulated data     sim_df[\"day\"] = pd.to_datetime(sim_df[\"day\"])     sim_df = sim_df[sim_df['DVS']&gt;=2]     sim_df = sim_df.groupby(by='point_id').first()     sim_df = sim_df[['TWSO']].reset_index()          merged_df = pd.merge(         left=obs_df, right=sim_df, left_on=\"id\", right_on=\"point_id\"     )      yield_loss = np.sqrt(         mean_squared_error(merged_df[\"yield\"], merged_df[\"TWSO\"])     )      return np.round(yield_loss, 2)  # Define the search space def search_space(trial):     # 1. Define a scaling factor for Photosynthesis (AMAX)     # This allows Optuna to shift the entire curve up or down by +/- 20%     amax_factor = trial.suggest_float(\"amax_factor\", 0.8, 1.2)          # 2. Define a scaling factor for Leaf Thickness (SLA)     sla_factor = trial.suggest_float(\"sla_factor\", 0.8, 1.2)      return {         \"crop_params\": {             # LEAF DYNAMICS (Source capacity)             # SPAN: Leaf lifespan. Higher = longer green canopy duration.             \"SPAN\": trial.suggest_float(\"SPAN\", 25.0, 40.0),                          # SLATB (Specific Leaf Area): Controls how much leaf area is built per kg biomass.             # We scale the entire table by a factor (0.8x to 1.2x).             \"SLATB\": [                 0.0, 0.00212 * sla_factor,                 0.5, 0.00212 * sla_factor,                 2.0, 0.00212 * sla_factor             ],              # ASSIMILATION &amp; CONVERSION (Biomass production)             # AMAXTB: Max CO2 assimilation rate. Highly sensitive.             \"AMAXTB\": [                 0.0, 35.83 * amax_factor,  # Vegetative                 1.0, 35.83 * amax_factor,  # Flowering                 1.3, 35.83 * amax_factor,  # Early Grain filling                 2.0,  4.48 * amax_factor   # Maturity (Senescence)             ],             # CVT: Efficiency of conversion to storage organs (Harvest Index driver).             \"CVO\": trial.suggest_float(\"CVO\", 0.65, 0.75),              # ROOTING (Water access)             # RDMCR: Max rooting depth. Critical for drought resistance.             \"RDMCR\": trial.suggest_int(\"RDMCR\", 80, 150),         }     }  study = yield_optimizer.optimize(     search_space, loss_fn_yield, n_trials=1000, n_workers=5, directions=[\"minimize\"], sampler='TPE' ) In\u00a0[\u00a0]: Copied! <pre># Run the simulation with optimized parameters\nbest_params = yield_optimizer.get_best_params(study, search_space)\n\n# Update the parameters in the workspace\nbatch_runner.update_parameters(\n    crop_overrides=best_params['crop_params']\n)\n\n# Run the simulations with updated parameters\nresults = batch_runner.run_batch_simulation(max_workers=5)\nprint(results.shape)\nresults.head()\n</pre> # Run the simulation with optimized parameters best_params = yield_optimizer.get_best_params(study, search_space)  # Update the parameters in the workspace batch_runner.update_parameters(     crop_overrides=best_params['crop_params'] )  # Run the simulations with updated parameters results = batch_runner.run_batch_simulation(max_workers=5) print(results.shape) results.head() In\u00a0[\u00a0]: Copied! <pre># Ensure 'day' is datetime\nbatch_results = results.copy()\nbatch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])\n\n# Variables to plot (exclude metadata columns)\nvars_to_plot = [\n    col\n    for col in batch_results.columns\n    if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"]\n]\n\n# Layout\ncols = 2\nrows = math.ceil(len(vars_to_plot) / cols)\n\n# Colors for point_id groups\nunique_points = batch_results[\"point_id\"].unique()\npalette = sns.color_palette(\"tab10\", len(unique_points))\ncolor_map = {pid: palette[i] for i, pid in enumerate(unique_points)}\n\nfig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True)\naxes = axes.flatten()\n\nfor i, var in enumerate(vars_to_plot):\n    ax = axes[i]\n\n    for pid in unique_points:\n        df_sub = batch_results[batch_results[\"point_id\"] == pid]\n\n        sns.lineplot(\n            x=df_sub[\"day\"],\n            y=df_sub[var],\n            ax=ax,\n            label=f\"Point {pid}\",\n            color=color_map[pid],\n        )\n\n    ax.set_title(var)\n    ax.legend()\n\n# Hide remaining empty subplots\nfor j in range(len(vars_to_plot), len(axes)):\n    axes[j].axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Ensure 'day' is datetime batch_results = results.copy() batch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])  # Variables to plot (exclude metadata columns) vars_to_plot = [     col     for col in batch_results.columns     if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"] ]  # Layout cols = 2 rows = math.ceil(len(vars_to_plot) / cols)  # Colors for point_id groups unique_points = batch_results[\"point_id\"].unique() palette = sns.color_palette(\"tab10\", len(unique_points)) color_map = {pid: palette[i] for i, pid in enumerate(unique_points)}  fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True) axes = axes.flatten()  for i, var in enumerate(vars_to_plot):     ax = axes[i]      for pid in unique_points:         df_sub = batch_results[batch_results[\"point_id\"] == pid]          sns.lineplot(             x=df_sub[\"day\"],             y=df_sub[var],             ax=ax,             label=f\"Point {pid}\",             color=color_map[pid],         )      ax.set_title(var)     ax.legend()  # Hide remaining empty subplots for j in range(len(vars_to_plot), len(axes)):     axes[j].axis(\"off\")  plt.tight_layout() plt.show()"},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#instantiate-batch-crop-simulation-engine-for-wofost","title":"Instantiate batch crop simulation engine for WOFOST\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#user-inputs","title":"User inputs\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#create-agromanagements-with-user-inputs","title":"Create agromanagements with user inputs\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#prepare-batch-system","title":"Prepare batch system\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#run-the-simulation-first","title":"Run the simulation first\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#plot-the-results-before-optimization","title":"Plot the results (before optimization)\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#optimize-phenology","title":"Optimize phenology\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#run-the-simulation-with-optimized-parameters","title":"Run the simulation with optimized parameters\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#plot-the-simulation","title":"Plot the simulation\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#optimize-yield-twso","title":"Optimize yield (TWSO)\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#run-the-simulation-with-optimized-parameters","title":"Run the simulation with optimized parameters\u00b6","text":""},{"location":"examples/Run%20parameter%20optimization%20%28wofost%29/#plot-the-simulation","title":"Plot the simulation\u00b6","text":""},{"location":"examples/Run%20sensitivity%20analysis%20%28wofost%29/","title":"Run sensitivity analysis (wofost)","text":"<p>Uncomment the following line to install the latest version of cropengine if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U cropengine\n</pre> # !pip install -U cropengine In\u00a0[\u00a0]: Copied! <pre>import os\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom cropengine import WOFOSTCropSimulationBatchRunner\nfrom cropengine.agromanagement import WOFOSTAgroEventBuilder\nfrom cropengine.sensitivity import WOFOSTSensitivityAnalyzer\n</pre> import os import math import pandas as pd import matplotlib.pyplot as plt import seaborn as sns from cropengine import WOFOSTCropSimulationBatchRunner from cropengine.agromanagement import WOFOSTAgroEventBuilder from cropengine.sensitivity import WOFOSTSensitivityAnalyzer In\u00a0[\u00a0]: Copied! <pre># Define the model name\nMODEL_NAME = \"Wofost72_WLP_CWB\"\n\n# Define the csv path with 'id', 'latitude', and 'longitude'\nlocations_csv_path = \"test_data/sensitivity/location.csv\"\n\n# Initialize Engine\nbatch_runner = WOFOSTCropSimulationBatchRunner(\n    model_name=MODEL_NAME,\n    locations_csv_path=locations_csv_path,\n    workspace_dir=\"test_output/sensitivity_workspace\",\n)\n</pre> # Define the model name MODEL_NAME = \"Wofost72_WLP_CWB\"  # Define the csv path with 'id', 'latitude', and 'longitude' locations_csv_path = \"test_data/sensitivity/location.csv\"  # Initialize Engine batch_runner = WOFOSTCropSimulationBatchRunner(     model_name=MODEL_NAME,     locations_csv_path=locations_csv_path,     workspace_dir=\"test_output/sensitivity_workspace\", ) In\u00a0[\u00a0]: Copied! <pre># Crop Configuration\nmodels = batch_runner.get_model_options()\n\ncrops = batch_runner.get_crop_options(MODEL_NAME)\nCROP_NAME = \"wheat\"\nvarieties = batch_runner.get_variety_options(MODEL_NAME, CROP_NAME)\nCROP_VARIETY = \"Winter_wheat_103\"\n\n# Timing\ncrop_start_end = batch_runner.get_crop_start_end_options()\nCAMPAIGN_START = \"2019-09-01\"\nCROP_START = \"2019-09-25\"\nCROP_START_TYPE = \"sowing\"\nCROP_END_TYPE = \"maturity\"\nCROP_END = None\nCAMPAIGN_END = \"2020-09-30\"\nMAX_DURATION = 365\n</pre> # Crop Configuration models = batch_runner.get_model_options()  crops = batch_runner.get_crop_options(MODEL_NAME) CROP_NAME = \"wheat\" varieties = batch_runner.get_variety_options(MODEL_NAME, CROP_NAME) CROP_VARIETY = \"Winter_wheat_103\"  # Timing crop_start_end = batch_runner.get_crop_start_end_options() CAMPAIGN_START = \"2019-09-01\" CROP_START = \"2019-09-25\" CROP_START_TYPE = \"sowing\" CROP_END_TYPE = \"maturity\" CROP_END = None CAMPAIGN_END = \"2020-09-30\" MAX_DURATION = 365 In\u00a0[\u00a0]: Copied! <pre>agro_event_builder = WOFOSTAgroEventBuilder()\n\n# Note: Use agro_event_builder.get_..._events_info() to see valid values if unsure\ntimed_events_info = agro_event_builder.get_timed_events_info()\nstate_events_info = agro_event_builder.get_state_events_info()\n\n# Build timed events (irrigation)\nirrigation_schedule = [\n    {\"event_date\": \"2020-03-20\", \"amount\": 3.0, \"efficiency\": 0.7},  # stem elongation\n    {\"event_date\": \"2020-04-25\", \"amount\": 2.5, \"efficiency\": 0.7},  # booting/heading\n    {\"event_date\": \"2020-05-20\", \"amount\": 2.0, \"efficiency\": 0.7},  # flowering\n]\n\nirrigation_events = agro_event_builder.create_timed_events(\n    signal_type=\"irrigate\", events_list=irrigation_schedule\n)\n\n# Build state Events (fertilization based on DVS)\nnitrogen_schedule = [\n    {\"threshold\": 0.3, \"N_amount\": 40, \"N_recovery\": 0.7},  # early vegetative\n    {\"threshold\": 0.6, \"N_amount\": 60, \"N_recovery\": 0.7},  # stem elongation\n    {\"threshold\": 1.0, \"N_amount\": 40, \"N_recovery\": 0.7},  # heading\n]\n\nnitrogen_events = agro_event_builder.create_state_events(\n    signal_type=\"apply_n\",\n    state_var=\"DVS\",\n    zero_condition=\"rising\",\n    events_list=nitrogen_schedule,\n)\n</pre> agro_event_builder = WOFOSTAgroEventBuilder()  # Note: Use agro_event_builder.get_..._events_info() to see valid values if unsure timed_events_info = agro_event_builder.get_timed_events_info() state_events_info = agro_event_builder.get_state_events_info()  # Build timed events (irrigation) irrigation_schedule = [     {\"event_date\": \"2020-03-20\", \"amount\": 3.0, \"efficiency\": 0.7},  # stem elongation     {\"event_date\": \"2020-04-25\", \"amount\": 2.5, \"efficiency\": 0.7},  # booting/heading     {\"event_date\": \"2020-05-20\", \"amount\": 2.0, \"efficiency\": 0.7},  # flowering ]  irrigation_events = agro_event_builder.create_timed_events(     signal_type=\"irrigate\", events_list=irrigation_schedule )  # Build state Events (fertilization based on DVS) nitrogen_schedule = [     {\"threshold\": 0.3, \"N_amount\": 40, \"N_recovery\": 0.7},  # early vegetative     {\"threshold\": 0.6, \"N_amount\": 60, \"N_recovery\": 0.7},  # stem elongation     {\"threshold\": 1.0, \"N_amount\": 40, \"N_recovery\": 0.7},  # heading ]  nitrogen_events = agro_event_builder.create_state_events(     signal_type=\"apply_n\",     state_var=\"DVS\",     zero_condition=\"rising\",     events_list=nitrogen_schedule, ) In\u00a0[\u00a0]: Copied! <pre>batch_runner.prepare_batch_system(\n    max_workers=5,\n    campaign_start=CAMPAIGN_START,\n    campaign_end=CAMPAIGN_END,\n    crop_start=CROP_START,\n    crop_start_type=CROP_START_TYPE,\n    crop_end_type=CROP_END_TYPE,\n    crop_end=CROP_END,\n    max_duration=MAX_DURATION,\n    crop_name=CROP_NAME,\n    variety_name=CROP_VARIETY,\n    timed_events=[irrigation_events],\n    state_events=[nitrogen_events],\n    force_update=False,\n    WAV=10,  # Extra site params can be passed as a kwargs\n)\n</pre> batch_runner.prepare_batch_system(     max_workers=5,     campaign_start=CAMPAIGN_START,     campaign_end=CAMPAIGN_END,     crop_start=CROP_START,     crop_start_type=CROP_START_TYPE,     crop_end_type=CROP_END_TYPE,     crop_end=CROP_END,     max_duration=MAX_DURATION,     crop_name=CROP_NAME,     variety_name=CROP_VARIETY,     timed_events=[irrigation_events],     state_events=[nitrogen_events],     force_update=False,     WAV=10,  # Extra site params can be passed as a kwargs ) In\u00a0[\u00a0]: Copied! <pre>results = batch_runner.run_batch_simulation(max_workers=5)\nprint(results.shape)\nresults.head()\n</pre> results = batch_runner.run_batch_simulation(max_workers=5) print(results.shape) results.head() In\u00a0[\u00a0]: Copied! <pre># Ensure 'day' is datetime\nbatch_results = results.copy()\nbatch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])\n\n# Variables to plot (exclude metadata columns)\nvars_to_plot = [\n    col\n    for col in batch_results.columns\n    if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"]\n]\n\n# Layout\ncols = 2\nrows = math.ceil(len(vars_to_plot) / cols)\n\n# Colors for point_id groups\nunique_points = batch_results[\"point_id\"].unique()\npalette = sns.color_palette(\"tab10\", len(unique_points))\ncolor_map = {pid: palette[i] for i, pid in enumerate(unique_points)}\n\nfig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True)\naxes = axes.flatten()\n\nfor i, var in enumerate(vars_to_plot):\n    ax = axes[i]\n\n    for pid in unique_points:\n        df_sub = batch_results[batch_results[\"point_id\"] == pid]\n\n        sns.lineplot(\n            x=df_sub[\"day\"],\n            y=df_sub[var],\n            ax=ax,\n            label=f\"Point {pid}\",\n            color=color_map[pid],\n        )\n\n    ax.set_title(var)\n    ax.legend()\n\n# Hide remaining empty subplots\nfor j in range(len(vars_to_plot), len(axes)):\n    axes[j].axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n</pre> # Ensure 'day' is datetime batch_results = results.copy() batch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])  # Variables to plot (exclude metadata columns) vars_to_plot = [     col     for col in batch_results.columns     if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"] ]  # Layout cols = 2 rows = math.ceil(len(vars_to_plot) / cols)  # Colors for point_id groups unique_points = batch_results[\"point_id\"].unique() palette = sns.color_palette(\"tab10\", len(unique_points)) color_map = {pid: palette[i] for i, pid in enumerate(unique_points)}  fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True) axes = axes.flatten()  for i, var in enumerate(vars_to_plot):     ax = axes[i]      for pid in unique_points:         df_sub = batch_results[batch_results[\"point_id\"] == pid]          sns.lineplot(             x=df_sub[\"day\"],             y=df_sub[var],             ax=ax,             label=f\"Point {pid}\",             color=color_map[pid],         )      ax.set_title(var)     ax.legend()  # Hide remaining empty subplots for j in range(len(vars_to_plot), len(axes)):     axes[j].axis(\"off\")  plt.tight_layout() plt.show() In\u00a0[\u00a0]: Copied! <pre># Instantiate WOFOST Sensitivity Analyzer\nsa = WOFOSTSensitivityAnalyzer(batch_runner)\n\n# Define the problem\nproblem = {\n    \"num_vars\": 3,\n    \"names\": [\"TSUM1\", \"TSUM2\", \"SPAN\"],\n    \"bounds\": [[800, 1200], [900, 1300], [28, 35]],  # TSUM1  # TSUM2  # SPAN\n}\n\nsa_result = sa.run_analysis(\n    problem,\n    method=\"fast\",\n    n_samples=512,\n    target_variable=\"TWSO\",\n    mode=\"local\",\n    n_workers=70,\n)\n</pre> # Instantiate WOFOST Sensitivity Analyzer sa = WOFOSTSensitivityAnalyzer(batch_runner)  # Define the problem problem = {     \"num_vars\": 3,     \"names\": [\"TSUM1\", \"TSUM2\", \"SPAN\"],     \"bounds\": [[800, 1200], [900, 1300], [28, 35]],  # TSUM1  # TSUM2  # SPAN }  sa_result = sa.run_analysis(     problem,     method=\"fast\",     n_samples=512,     target_variable=\"TWSO\",     mode=\"local\",     n_workers=70, ) In\u00a0[\u00a0]: Copied! <pre>def plot_global(df):\n    df_melt = df.melt(\n        id_vars=\"Parameter\",\n        value_vars=[\"S1\", \"ST\"],\n        var_name=\"Index\",\n        value_name=\"Score\",\n    )\n\n    plt.figure(figsize=(8, 5))\n    sns.set_style(\"whitegrid\")\n\n    sns.barplot(\n        data=df_melt,\n        x=\"Score\",\n        y=\"Parameter\",\n        hue=\"Index\",\n        palette={\"ST\": \"#4c72b0\", \"S1\": \"#dd8452\"},\n    )\n\n    plt.title(\"Global Parameter Sensitivity (Aggregated)\", fontsize=14)\n    plt.xlabel(\"Sensitivity Index\", fontsize=12)\n    plt.ylabel(\"\")\n    plt.legend(title=\"Index Type\")\n    plt.tight_layout()\n    plt.show()\n\n\nplot_global(sa_result)\n</pre> def plot_global(df):     df_melt = df.melt(         id_vars=\"Parameter\",         value_vars=[\"S1\", \"ST\"],         var_name=\"Index\",         value_name=\"Score\",     )      plt.figure(figsize=(8, 5))     sns.set_style(\"whitegrid\")      sns.barplot(         data=df_melt,         x=\"Score\",         y=\"Parameter\",         hue=\"Index\",         palette={\"ST\": \"#4c72b0\", \"S1\": \"#dd8452\"},     )      plt.title(\"Global Parameter Sensitivity (Aggregated)\", fontsize=14)     plt.xlabel(\"Sensitivity Index\", fontsize=12)     plt.ylabel(\"\")     plt.legend(title=\"Index Type\")     plt.tight_layout()     plt.show()   plot_global(sa_result) In\u00a0[\u00a0]: Copied! <pre>def plot_local_heatmap(df):\n    pivot_df = df.pivot(index=\"point_id\", columns=\"Parameter\", values=\"ST\")\n\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(pivot_df, annot=True, cmap=\"YlGnBu\", fmt=\".2f\", linewidths=0.5)\n\n    plt.title(\"Spatial Variability of Sensitivity (Total Effect ST)\", fontsize=14)\n    plt.ylabel(\"Location ID\", fontsize=12)\n    plt.xlabel(\"Parameter\", fontsize=12)\n    plt.tight_layout()\n    plt.show()\n\n\nplot_local_heatmap(sa_result)\n</pre> def plot_local_heatmap(df):     pivot_df = df.pivot(index=\"point_id\", columns=\"Parameter\", values=\"ST\")      plt.figure(figsize=(8, 6))     sns.heatmap(pivot_df, annot=True, cmap=\"YlGnBu\", fmt=\".2f\", linewidths=0.5)      plt.title(\"Spatial Variability of Sensitivity (Total Effect ST)\", fontsize=14)     plt.ylabel(\"Location ID\", fontsize=12)     plt.xlabel(\"Parameter\", fontsize=12)     plt.tight_layout()     plt.show()   plot_local_heatmap(sa_result) In\u00a0[\u00a0]: Copied! <pre>def plot_local_distribution(df):\n    plt.figure(figsize=(8, 5))\n    sns.boxplot(data=df, x=\"ST\", y=\"Parameter\", hue=\"Parameter\", palette=\"vlag\")\n    sns.stripplot(data=df, x=\"ST\", y=\"Parameter\", color=\"black\", alpha=0.5, jitter=True)\n\n    plt.title(\"Stability of Parameters Across Locations\", fontsize=14)\n    plt.xlabel(\"Total Sensitivity Index (ST)\")\n    plt.tight_layout()\n    plt.show()\n\n\nplot_local_distribution(sa_result)\n</pre> def plot_local_distribution(df):     plt.figure(figsize=(8, 5))     sns.boxplot(data=df, x=\"ST\", y=\"Parameter\", hue=\"Parameter\", palette=\"vlag\")     sns.stripplot(data=df, x=\"ST\", y=\"Parameter\", color=\"black\", alpha=0.5, jitter=True)      plt.title(\"Stability of Parameters Across Locations\", fontsize=14)     plt.xlabel(\"Total Sensitivity Index (ST)\")     plt.tight_layout()     plt.show()   plot_local_distribution(sa_result)"},{"location":"examples/Run%20sensitivity%20analysis%20%28wofost%29/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"examples/Run%20sensitivity%20analysis%20%28wofost%29/#instantiate-batch-crop-simulation-engine-for-wofost","title":"Instantiate batch crop simulation engine for WOFOST\u00b6","text":""},{"location":"examples/Run%20sensitivity%20analysis%20%28wofost%29/#user-inputs","title":"User inputs\u00b6","text":""},{"location":"examples/Run%20sensitivity%20analysis%20%28wofost%29/#create-agromanagements-with-user-inputs","title":"Create agromanagements with user inputs\u00b6","text":""},{"location":"examples/Run%20sensitivity%20analysis%20%28wofost%29/#prepare-batch-system","title":"Prepare batch system\u00b6","text":""},{"location":"examples/Run%20sensitivity%20analysis%20%28wofost%29/#run-the-simulation-first","title":"Run the simulation first\u00b6","text":""},{"location":"examples/Run%20sensitivity%20analysis%20%28wofost%29/#sensitivity-analysis-using-fast-fourier-amplitude-sensitivity-test-method","title":"Sensitivity analysis using FAST (Fourier Amplitude Sensitivity Test) method\u00b6","text":""},{"location":"examples/Run%20sensitivity%20analysis%20%28wofost%29/#plot-the-data","title":"Plot the data\u00b6","text":""},{"location":"examples/Run%20wofost%20%28multiple%20location%29/","title":"Run wofost (multiple location)","text":"<p>Uncomment the following line to install the latest version of cropengine if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U cropengine\n</pre> # !pip install -U cropengine In\u00a0[\u00a0]: Copied! <pre>import os\nimport pandas as pd\nimport seaborn as sns\nfrom cropengine import WOFOSTCropSimulationBatchRunner\nfrom cropengine.agromanagement import WOFOSTAgroEventBuilder\n</pre> import os import pandas as pd import seaborn as sns from cropengine import WOFOSTCropSimulationBatchRunner from cropengine.agromanagement import WOFOSTAgroEventBuilder In\u00a0[\u00a0]: Copied! <pre># Define the model name\nMODEL_NAME = \"Wofost72_WLP_CWB\"\n\n# Define the csv path with 'id', 'latitude', and 'longitude'\nlocations_csv_path = \"test_data/batch_run/location.csv\"\n\n# Initialize Engine\nbatch_runner = WOFOSTCropSimulationBatchRunner(\n    model_name=MODEL_NAME,\n    locations_csv_path=locations_csv_path,\n    workspace_dir=\"batch_workspace\",\n)\n</pre> # Define the model name MODEL_NAME = \"Wofost72_WLP_CWB\"  # Define the csv path with 'id', 'latitude', and 'longitude' locations_csv_path = \"test_data/batch_run/location.csv\"  # Initialize Engine batch_runner = WOFOSTCropSimulationBatchRunner(     model_name=MODEL_NAME,     locations_csv_path=locations_csv_path,     workspace_dir=\"batch_workspace\", ) In\u00a0[\u00a0]: Copied! <pre># Crop Configuration\n# Note: Use dashboard.get_..._options() to see valid values if unsure\nmodels = batch_runner.get_model_options()\n\ncrops = batch_runner.get_crop_options(MODEL_NAME)\nCROP_NAME = \"sugarbeet\"\nvarieties = batch_runner.get_variety_options(MODEL_NAME, CROP_NAME)\nCROP_VARIETY = \"Sugarbeet_601\"\n\n# Timing\ncrop_start_end = batch_runner.get_crop_start_end_options()\nCAMPAIGN_START = \"2006-01-01\"\nCROP_START = \"2006-04-05\"\nCROP_START_TYPE = \"emergence\"\nCROP_END_TYPE = \"harvest\"\nCROP_END = \"2006-10-20\"\nCAMPAIGN_END = \"2007-01-01\"\nMAX_DURATION = 300\n</pre> # Crop Configuration # Note: Use dashboard.get_..._options() to see valid values if unsure models = batch_runner.get_model_options()  crops = batch_runner.get_crop_options(MODEL_NAME) CROP_NAME = \"sugarbeet\" varieties = batch_runner.get_variety_options(MODEL_NAME, CROP_NAME) CROP_VARIETY = \"Sugarbeet_601\"  # Timing crop_start_end = batch_runner.get_crop_start_end_options() CAMPAIGN_START = \"2006-01-01\" CROP_START = \"2006-04-05\" CROP_START_TYPE = \"emergence\" CROP_END_TYPE = \"harvest\" CROP_END = \"2006-10-20\" CAMPAIGN_END = \"2007-01-01\" MAX_DURATION = 300 In\u00a0[\u00a0]: Copied! <pre>agro_event_builder = WOFOSTAgroEventBuilder()\n\n# Note: Use agro_event_builder.get_..._events_info() to see valid values if unsure\ntimed_events_info = agro_event_builder.get_timed_events_info()\nstate_events_info = agro_event_builder.get_state_events_info()\n\n# Build timed events (irrigation)\nirrigation_schedule = [\n    {\"event_date\": \"2006-05-25\", \"amount\": 3.0, \"efficiency\": 0.7},\n    {\"event_date\": \"2006-06-30\", \"amount\": 2.5, \"efficiency\": 0.7},\n]\n\nirrigation_events = agro_event_builder.create_timed_events(\n    signal_type=\"irrigate\", events_list=irrigation_schedule\n)\n\n# Build state Events (fertilization based on DVS)\nnitrogen_schedule = [\n    {\"threshold\": 0.3, \"N_amount\": 40, \"N_recovery\": 0.7},\n    {\"threshold\": 0.6, \"N_amount\": 60, \"N_recovery\": 0.7},\n    {\"threshold\": 1.12, \"N_amount\": 40, \"N_recovery\": 0.7},\n]\n\nnitrogen_events = agro_event_builder.create_state_events(\n    signal_type=\"apply_n\",\n    state_var=\"DVS\",\n    zero_condition=\"rising\",\n    events_list=nitrogen_schedule,\n)\n</pre> agro_event_builder = WOFOSTAgroEventBuilder()  # Note: Use agro_event_builder.get_..._events_info() to see valid values if unsure timed_events_info = agro_event_builder.get_timed_events_info() state_events_info = agro_event_builder.get_state_events_info()  # Build timed events (irrigation) irrigation_schedule = [     {\"event_date\": \"2006-05-25\", \"amount\": 3.0, \"efficiency\": 0.7},     {\"event_date\": \"2006-06-30\", \"amount\": 2.5, \"efficiency\": 0.7}, ]  irrigation_events = agro_event_builder.create_timed_events(     signal_type=\"irrigate\", events_list=irrigation_schedule )  # Build state Events (fertilization based on DVS) nitrogen_schedule = [     {\"threshold\": 0.3, \"N_amount\": 40, \"N_recovery\": 0.7},     {\"threshold\": 0.6, \"N_amount\": 60, \"N_recovery\": 0.7},     {\"threshold\": 1.12, \"N_amount\": 40, \"N_recovery\": 0.7}, ]  nitrogen_events = agro_event_builder.create_state_events(     signal_type=\"apply_n\",     state_var=\"DVS\",     zero_condition=\"rising\",     events_list=nitrogen_schedule, ) In\u00a0[\u00a0]: Copied! <pre>batch_runner.prepare_batch_system(\n    campaign_start=CAMPAIGN_START,\n    campaign_end=CAMPAIGN_END,\n    crop_start=CROP_START,\n    crop_start_type=CROP_START_TYPE,\n    crop_end_type=CROP_END_TYPE,\n    crop_end=CROP_END,\n    max_duration=MAX_DURATION,\n    crop_name=CROP_NAME,\n    variety_name=CROP_VARIETY,\n    timed_events=[irrigation_events],\n    state_events=[nitrogen_events],\n    force_update=False,\n    WAV=10,  # Extra site params can be passed as a kwargs\n)\n</pre> batch_runner.prepare_batch_system(     campaign_start=CAMPAIGN_START,     campaign_end=CAMPAIGN_END,     crop_start=CROP_START,     crop_start_type=CROP_START_TYPE,     crop_end_type=CROP_END_TYPE,     crop_end=CROP_END,     max_duration=MAX_DURATION,     crop_name=CROP_NAME,     variety_name=CROP_VARIETY,     timed_events=[irrigation_events],     state_events=[nitrogen_events],     force_update=False,     WAV=10,  # Extra site params can be passed as a kwargs ) In\u00a0[\u00a0]: Copied! <pre>results = batch_runner.run_batch_simulation(max_workers=3)\nprint(results.shape)\nresults.head()\n</pre> results = batch_runner.run_batch_simulation(max_workers=3) print(results.shape) results.head() In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport math\n\n# Ensure 'day' is datetime\nbatch_results = results.copy()\nbatch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])\n\n# Variables to plot (exclude metadata columns)\nvars_to_plot = [\n    col\n    for col in batch_results.columns\n    if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"]\n]\n\n# Layout\ncols = 2\nrows = math.ceil(len(vars_to_plot) / cols)\n\n# Colors for point_id groups\nunique_points = batch_results[\"point_id\"].unique()\npalette = sns.color_palette(\"tab10\", len(unique_points))\ncolor_map = {pid: palette[i] for i, pid in enumerate(unique_points)}\n\nfig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True)\naxes = axes.flatten()\n\nfor i, var in enumerate(vars_to_plot):\n    ax = axes[i]\n\n    for pid in unique_points:\n        df_sub = batch_results[batch_results[\"point_id\"] == pid]\n\n        sns.lineplot(\n            x=df_sub[\"day\"],\n            y=df_sub[var],\n            ax=ax,\n            label=f\"Point {pid}\",\n            color=color_map[pid],\n        )\n\n    ax.set_title(var)\n    ax.legend()\n\n# Hide remaining empty subplots\nfor j in range(len(vars_to_plot), len(axes)):\n    axes[j].axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt import seaborn as sns import numpy as np import math  # Ensure 'day' is datetime batch_results = results.copy() batch_results[\"day\"] = pd.to_datetime(batch_results[\"day\"])  # Variables to plot (exclude metadata columns) vars_to_plot = [     col     for col in batch_results.columns     if col not in [\"point_id\", \"latitude\", \"longitude\", \"day\"] ]  # Layout cols = 2 rows = math.ceil(len(vars_to_plot) / cols)  # Colors for point_id groups unique_points = batch_results[\"point_id\"].unique() palette = sns.color_palette(\"tab10\", len(unique_points)) color_map = {pid: palette[i] for i, pid in enumerate(unique_points)}  fig, axes = plt.subplots(rows, cols, figsize=(14, 3 * rows), sharex=True) axes = axes.flatten()  for i, var in enumerate(vars_to_plot):     ax = axes[i]      for pid in unique_points:         df_sub = batch_results[batch_results[\"point_id\"] == pid]          sns.lineplot(             x=df_sub[\"day\"],             y=df_sub[var],             ax=ax,             label=f\"Point {pid}\",             color=color_map[pid],         )      ax.set_title(var)     ax.legend()  # Hide remaining empty subplots for j in range(len(vars_to_plot), len(axes)):     axes[j].axis(\"off\")  plt.tight_layout() plt.show()"},{"location":"examples/Run%20wofost%20%28multiple%20location%29/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"examples/Run%20wofost%20%28multiple%20location%29/#instantiate-batch-crop-simulation-engine-for-wofost","title":"Instantiate batch crop simulation engine for WOFOST\u00b6","text":""},{"location":"examples/Run%20wofost%20%28multiple%20location%29/#user-inputs","title":"User inputs\u00b6","text":""},{"location":"examples/Run%20wofost%20%28multiple%20location%29/#create-agromanagements-with-user-inputs","title":"Create agromanagements with user inputs\u00b6","text":""},{"location":"examples/Run%20wofost%20%28multiple%20location%29/#prepare-batch-system-must-be-implemented-before-running-the-batch-simulation","title":"Prepare batch system (must be implemented before running the batch simulation)\u00b6","text":""},{"location":"examples/Run%20wofost%20%28multiple%20location%29/#run-the-simulation","title":"Run the simulation\u00b6","text":""},{"location":"examples/Run%20wofost%20%28multiple%20location%29/#plot-the-batch-results","title":"Plot the batch results\u00b6","text":""},{"location":"examples/Run%20wofost%20%28single%20location%29/","title":"Run wofost (single location)","text":"<p>Uncomment the following line to install the latest version of cropengine if needed.</p> In\u00a0[\u00a0]: Copied! <pre># !pip install -U cropengine\n</pre> # !pip install -U cropengine In\u00a0[\u00a0]: Copied! <pre>import os\nimport pandas as pd\nimport seaborn as sns\nfrom cropengine import WOFOSTCropSimulationRunner\nfrom cropengine.agromanagement import WOFOSTAgroEventBuilder\n</pre> import os import pandas as pd import seaborn as sns from cropengine import WOFOSTCropSimulationRunner from cropengine.agromanagement import WOFOSTAgroEventBuilder In\u00a0[\u00a0]: Copied! <pre># Define the model name\nMODEL_NAME = \"Wofost72_WLP_CWB\"\n\n# Initialize Engine\nrunner = WOFOSTCropSimulationRunner(\n    model_name=MODEL_NAME, workspace_dir=\"test_output/location_workspace\"\n)\n</pre> # Define the model name MODEL_NAME = \"Wofost72_WLP_CWB\"  # Initialize Engine runner = WOFOSTCropSimulationRunner(     model_name=MODEL_NAME, workspace_dir=\"test_output/location_workspace\" ) In\u00a0[\u00a0]: Copied! <pre># Location\nLATITUDE = 53.3721\nLONGITUDE = 13.82299\n\n# Crop Configuration\n# Note: Use runner.get_..._options() to see valid values if unsure\nmodels = runner.get_model_options()\ncrops = runner.get_crop_options(MODEL_NAME)\nCROP_NAME = \"sugarbeet\"\nvarieties = runner.get_variety_options(MODEL_NAME, CROP_NAME)\nCROP_VARIETY = \"Sugarbeet_601\"\n\n# Timing\ncrop_start_end = runner.get_crop_start_end_options()\nCAMPAIGN_START = \"2006-01-01\"\nCROP_START = \"2006-04-05\"\nCROP_START_TYPE = \"emergence\"\nCROP_END_TYPE = \"harvest\"\nCROP_END = \"2006-10-20\"\nCAMPAIGN_END = \"2007-01-01\"\nMAX_DURATION = 300\n</pre> # Location LATITUDE = 53.3721 LONGITUDE = 13.82299  # Crop Configuration # Note: Use runner.get_..._options() to see valid values if unsure models = runner.get_model_options() crops = runner.get_crop_options(MODEL_NAME) CROP_NAME = \"sugarbeet\" varieties = runner.get_variety_options(MODEL_NAME, CROP_NAME) CROP_VARIETY = \"Sugarbeet_601\"  # Timing crop_start_end = runner.get_crop_start_end_options() CAMPAIGN_START = \"2006-01-01\" CROP_START = \"2006-04-05\" CROP_START_TYPE = \"emergence\" CROP_END_TYPE = \"harvest\" CROP_END = \"2006-10-20\" CAMPAIGN_END = \"2007-01-01\" MAX_DURATION = 300 In\u00a0[\u00a0]: Copied! <pre>agro_event_builder = WOFOSTAgroEventBuilder()\n\n# Note: Use agro_event_builder.get_..._events_info() to see valid values if unsure\ntimed_events_info = agro_event_builder.get_timed_events_info()\nstate_events_info = agro_event_builder.get_state_events_info()\n\n# Build timed events (irrigation)\nirrigation_schedule = [\n    {\"event_date\": \"2006-05-25\", \"amount\": 3.0, \"efficiency\": 0.7},\n    {\"event_date\": \"2006-06-30\", \"amount\": 2.5, \"efficiency\": 0.7},\n]\n\nirrigation_events = agro_event_builder.create_timed_events(\n    signal_type=\"irrigate\", events_list=irrigation_schedule\n)\n\n# Build state Events (fertilization based on DVS)\nnitrogen_schedule = [\n    {\"threshold\": 0.3, \"N_amount\": 40, \"N_recovery\": 0.7},\n    {\"threshold\": 0.6, \"N_amount\": 60, \"N_recovery\": 0.7},\n    {\"threshold\": 1.12, \"N_amount\": 40, \"N_recovery\": 0.7},\n]\n\nnitrogen_events = agro_event_builder.create_state_events(\n    signal_type=\"apply_n\",\n    state_var=\"DVS\",\n    zero_condition=\"rising\",\n    events_list=nitrogen_schedule,\n)\n</pre> agro_event_builder = WOFOSTAgroEventBuilder()  # Note: Use agro_event_builder.get_..._events_info() to see valid values if unsure timed_events_info = agro_event_builder.get_timed_events_info() state_events_info = agro_event_builder.get_state_events_info()  # Build timed events (irrigation) irrigation_schedule = [     {\"event_date\": \"2006-05-25\", \"amount\": 3.0, \"efficiency\": 0.7},     {\"event_date\": \"2006-06-30\", \"amount\": 2.5, \"efficiency\": 0.7}, ]  irrigation_events = agro_event_builder.create_timed_events(     signal_type=\"irrigate\", events_list=irrigation_schedule )  # Build state Events (fertilization based on DVS) nitrogen_schedule = [     {\"threshold\": 0.3, \"N_amount\": 40, \"N_recovery\": 0.7},     {\"threshold\": 0.6, \"N_amount\": 60, \"N_recovery\": 0.7},     {\"threshold\": 1.12, \"N_amount\": 40, \"N_recovery\": 0.7}, ]  nitrogen_events = agro_event_builder.create_state_events(     signal_type=\"apply_n\",     state_var=\"DVS\",     zero_condition=\"rising\",     events_list=nitrogen_schedule, ) In\u00a0[\u00a0]: Copied! <pre>runner.prepare_system(\n    latitude=LATITUDE,\n    longitude=LONGITUDE,\n    campaign_start=CAMPAIGN_START,\n    campaign_end=CAMPAIGN_END,\n    crop_start=CROP_START,\n    crop_start_type=CROP_START_TYPE,\n    crop_end_type=CROP_END_TYPE,\n    crop_end=CROP_END,\n    max_duration=MAX_DURATION,\n    crop_name=CROP_NAME,\n    variety_name=CROP_VARIETY,\n    timed_events=[irrigation_events],\n    state_events=[nitrogen_events],\n    force_update=False,\n    WAV=10,  # Extra site params can be passed as a kwargs\n)\n</pre> runner.prepare_system(     latitude=LATITUDE,     longitude=LONGITUDE,     campaign_start=CAMPAIGN_START,     campaign_end=CAMPAIGN_END,     crop_start=CROP_START,     crop_start_type=CROP_START_TYPE,     crop_end_type=CROP_END_TYPE,     crop_end=CROP_END,     max_duration=MAX_DURATION,     crop_name=CROP_NAME,     variety_name=CROP_VARIETY,     timed_events=[irrigation_events],     state_events=[nitrogen_events],     force_update=False,     WAV=10,  # Extra site params can be passed as a kwargs ) In\u00a0[\u00a0]: Copied! <pre>soil_params = pd.read_csv(\n    runner.files[\"soil_params\"]\n)  # To be displayed in the dashboard's 'soil parameters' table\nprint(soil_params.shape)\nsoil_params.head()\n</pre> soil_params = pd.read_csv(     runner.files[\"soil_params\"] )  # To be displayed in the dashboard's 'soil parameters' table print(soil_params.shape) soil_params.head() In\u00a0[\u00a0]: Copied! <pre>site_params = pd.read_csv(\n    runner.files[\"site_params\"]\n)  # To be displayed in the dashboard's 'site parameters' table\nprint(site_params.shape)\nsite_params.head()\n</pre> site_params = pd.read_csv(     runner.files[\"site_params\"] )  # To be displayed in the dashboard's 'site parameters' table print(site_params.shape) site_params.head() In\u00a0[\u00a0]: Copied! <pre>crop_params = pd.read_csv(\n    runner.files[\"crop_params\"]\n)  # To be displayed in the dashboard's 'crop parameters' table\nprint(crop_params.shape)\ncrop_params.head()\n</pre> crop_params = pd.read_csv(     runner.files[\"crop_params\"] )  # To be displayed in the dashboard's 'crop parameters' table print(crop_params.shape) crop_params.head() In\u00a0[\u00a0]: Copied! <pre>simulation_output = runner.run_simulation(\n    soil_overrides=None,  # Pass the user-edited soil parameters in a dictionary\n    site_overrides=None,  # Pass the user-edited site parameters in a dictionary\n    crop_overrides=None,  # Pass the user-edited crop parameters in a dictionary\n    agro_file_path=None,  # Pass the user-uploaded agro_file_path if any.\n)\n\n# Set day as index\nsimulation_output = simulation_output.set_index(\"day\")\nprint(simulation_output.shape)\nsimulation_output.head()\n</pre> simulation_output = runner.run_simulation(     soil_overrides=None,  # Pass the user-edited soil parameters in a dictionary     site_overrides=None,  # Pass the user-edited site parameters in a dictionary     crop_overrides=None,  # Pass the user-edited crop parameters in a dictionary     agro_file_path=None,  # Pass the user-uploaded agro_file_path if any. )  # Set day as index simulation_output = simulation_output.set_index(\"day\") print(simulation_output.shape) simulation_output.head() In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport math\n\n# Variables\ncols = 2\nn_vars = len(simulation_output.columns)\nrows = math.ceil(n_vars / cols)\n\n# Use a categorical color palette large enough\npalette = sns.color_palette(\"tab20\", n_vars)\n\nfig, axes = plt.subplots(rows, cols, figsize=(14, 2 * rows), sharex=True)\naxes = np.array(axes).reshape(-1)\n\nfor i, var in enumerate(simulation_output.columns):\n    sns.lineplot(\n        x=simulation_output.index,\n        y=simulation_output[var],\n        ax=axes[i],\n        color=palette[i],\n    )\n\n# Hide unused axes\nfor j in range(i + 1, len(axes)):\n    axes[j].axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt import seaborn as sns import numpy as np import math  # Variables cols = 2 n_vars = len(simulation_output.columns) rows = math.ceil(n_vars / cols)  # Use a categorical color palette large enough palette = sns.color_palette(\"tab20\", n_vars)  fig, axes = plt.subplots(rows, cols, figsize=(14, 2 * rows), sharex=True) axes = np.array(axes).reshape(-1)  for i, var in enumerate(simulation_output.columns):     sns.lineplot(         x=simulation_output.index,         y=simulation_output[var],         ax=axes[i],         color=palette[i],     )  # Hide unused axes for j in range(i + 1, len(axes)):     axes[j].axis(\"off\")  plt.tight_layout() plt.show()"},{"location":"examples/Run%20wofost%20%28single%20location%29/#import-libraries","title":"Import libraries\u00b6","text":""},{"location":"examples/Run%20wofost%20%28single%20location%29/#user-inputs","title":"User inputs\u00b6","text":""},{"location":"examples/Run%20wofost%20%28single%20location%29/#instantiate-crop-simulation-engine-for-wofost","title":"Instantiate crop simulation engine for WOFOST\u00b6","text":""},{"location":"examples/Run%20wofost%20%28single%20location%29/#create-agromanagements-with-user-inputs","title":"Create agromanagements with user inputs\u00b6","text":""},{"location":"examples/Run%20wofost%20%28single%20location%29/#prepare-system-must-be-implemented-before-running-the-simulation","title":"Prepare system (must be implemented before running the simulation)\u00b6","text":""},{"location":"examples/Run%20wofost%20%28single%20location%29/#get-the-parameters-table-to-be-displayed-in-the-dashboard","title":"Get the parameters table to be displayed in the dashboard\u00b6","text":""},{"location":"examples/Run%20wofost%20%28single%20location%29/#soil-parameters","title":"Soil parameters\u00b6","text":""},{"location":"examples/Run%20wofost%20%28single%20location%29/#run-the-simulation","title":"Run the Simulation\u00b6","text":""},{"location":"examples/Run%20wofost%20%28single%20location%29/#plot-the-simulation-output","title":"Plot the simulation output\u00b6","text":""}]}